[{"content":"はじめに Dashはインタラクティブなグラフを表示できる、PythonのWebアプリケーションフレームワークである。flaskをバックエンドに使用している。\n本記事では、Dashで作成したWebアプリケーションをPythonAnywhere上で公開する手順を簡単にまとめた。大きく分けて、以下の手順で行う。\n PythonAnywhereのアカウント作成 flaskアプリの作成 ソースコードをflaskからdashに変更 仮想環境の構築 WSGIの設定  WSGI (Web Server Gateway Interface) とは、PythonアプリケーションとWebサーバのインタフェースを定めた仕様である。\nWSGI について — Webアプリケーションフレームワークの作り方 in Python\nHeroku上で公開する記事についてはこちら。\n可視化ツールDashで作成したWebアプリをHerokuで公開する\nPythonAnywhereアカウントとflaskアプリの作成 まず、PythonAnywhereのアカウントを作成し、flaskアプリを作成する。方法については以下の記事を参照（ただし、flaskアプリを作成するところまででよい）。\n【無料サーバーのご紹介】Pythonanywhere | CodeCampus\n注意点は以下の通り。\n 無料プランの\u0026quot;Beginner\u0026quot;で構わない アカウント作成時のユーザ名と、flaskアプリ作成時のPythonバージョンを覚えておく ファイルのパスはデフォルト(/home/（ユーザ名）/mysite/flask_app.py)  flaskアプリを作成したら、\nhttp://（ユーザ名）.pythonanywhere.com/\nにアクセスし、\u0026ldquo;Hello from Flask!\u0026ldquo;と表示されることを確認する。\nソースコードをflaskからdashに変更 次に、flaskのサンプルソースコードをDashのコードに変更する。\n\u0026ldquo;Files\u0026quot;タブを押し、左側の\u0026quot;Directories\u0026quot;の\u0026quot;mysite/\u0026ldquo;をクリックする。\u0026ldquo;mysite\u0026quot;ディレクトリに移動するので、右側の\u0026quot;flask_app.py\u0026quot;を押すと、ブラウザ上でスクリプトを編集する画面が開く。中身を全て削除し、以下のソースコードを貼り付けて、右上の\u0026quot;Save\u0026quot;を押す。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import dash import dash_core_components as dcc import dash_html_components as html # for deployment, pass app.server (which is the actual flask app) to WSGI etc app = dash.Dash() app.layout = html.Div(children=[ html.H1(children=\u0026#39;Hello Dash\u0026#39;), html.Div(children=\u0026#39;\u0026#39;\u0026#39; Dash: A web application framework for Python. \u0026#39;\u0026#39;\u0026#39;), dcc.Graph( id=\u0026#39;example-graph\u0026#39;, figure={ \u0026#39;data\u0026#39;: [ {\u0026#39;x\u0026#39;: [1, 2, 3], \u0026#39;y\u0026#39;: [4, 1, 2], \u0026#39;type\u0026#39;: \u0026#39;bar\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;SF\u0026#39;}, {\u0026#39;x\u0026#39;: [1, 2, 3], \u0026#39;y\u0026#39;: [2, 4, 5], \u0026#39;type\u0026#39;: \u0026#39;bar\u0026#39;, \u0026#39;name\u0026#39;: u\u0026#39;Montréal\u0026#39;}, ], \u0026#39;layout\u0026#39;: { \u0026#39;title\u0026#39;: \u0026#39;Dash Data Visualization\u0026#39; } } ) ])   仮想環境の構築 PythonAnywhere上で必要なライブラリをインストールする。インストール方法には、以下のページのように3つの方法があるが、ここでは2の仮想環境を使用する方法を採用する。\nInstalling new modules | PythonAnywhere help\nPythonAnywhereで\u0026quot;Consoles\u0026quot;タブからBashターミナルを開く。以下を実行して、仮想環境を作成する。\n$ mkvirtualenv dashappenv --python=/usr/bin/python3.6\rdashappenvは仮想環境の名前である。適当な名前に変更してよい。\nまた、最後のPythonのバージョンは、flaskアプリを構築したPythonのバージョンに合わせる。後者のバージョンは、\u0026ldquo;Webタブ\u0026quot;の\u0026quot;Code\u0026quot;→\u0026quot;Python version\u0026quot;から確認できる。\n次に、以下を実行して仮想環境を起動する。\n$ workon dashappenv\rさらに、pip3 installでDashをインストールする。他に必要なライブラリがあれば、同様にインストールする。\n(dashappenv)$ pip3 install dash\r最後にコンソールを閉じる。\n(dashappenv)$ exit\rWSGIの設定 最後に、WSGIを設定する。Webタブを開き、\u0026ldquo;Code\u0026quot;の\u0026quot;WSGI configuration file\u0026quot;を開く。\n1  from flask_app import app as application   をコメントアウトし、その後ろに以下を貼り付けて、保存して閉じる。\n1 2  from flask_app import app application = app.server   Webタブに戻り、\u0026ldquo;Virtualenv\u0026quot;に以下を入力する。\n/home/（ユーザ名）/.virtualenvs/dashappenv\r最後にReloadボタンを押し、再び以下のアドレスを開くと、Dashの画面が表示される。\nhttp://（ユーザ名）.pythonanywhere.com/\n参考 DashアプリをPythonAnywhereでデプロイする方法を紹介した記事（英語）\nThe Easiest Way to Deploy Your Dash App for Free | by Elsa Scola | Towards Data Science\n仮想環境 (mkvirtualenv) の使い方\nコマンドリファレンス — virtualenvwrapper 3.5 documentation\nVirtualenvwrapperの導入 - Qiita\n","description":"Pythonの可視化ツールDashで作成したWebアプリを、Webアプリケーション公開用プラットフォームであるPythonAnywhere上で公開する手順をまとめた。","id":0,"section":"posts","tags":["PythonAnywhere","Python","Dash"],"title":"可視化ツールDashで作成したWebアプリをPythonAnywhere上で公開する","uri":"https://helve2017.github.io/posts/web-technology/pythonanywhere-dash-deploy/"},{"content":"はじめに Dashはインタラクティブなグラフを表示できる、PythonのWebアプリケーションフレームワークである。flaskをバックエンドに使用している。\n本記事では、Dashで作成したWebアプリケーションをHeroku上で公開する手順を簡単にまとめた。大きく分けて、以下の手順で行う。\n ローカルでDashを使ったWebアプリを作成する WebアプリをHerokuにアップロードする  バージョンは以下の通り。\n    バージョン     Python 3.7.4   NumPy 1.16.5   Pandas 0.25.1   Dash 1.16.3   plotly 4.11.0   Git 2.27.0.windows.1    開発環境はWindows 10 Homeである。また、未検証だがLinuxでも動作するはずである。\nDashを使ったWebアプリの作成 Gitのインストール Heroku上でWebアプリを公開するためには、Gitを使用してソースコードをherokuサーバにアップロードする必要があるため、以下のページからGitをインストールする。ただし、Githubなどを利用する必要はなく、ローカルリポジトリを作るだけでよい。\nGit\nDashのソースコード作成 Dashの公式サイトのサンプルコードを少し改変した、以下のソースコードにindex.pyと名前を付けて保存する。\nPart 2. Layout | Dash for Python Documentation | Plotly\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  import dash import dash_core_components as dcc import dash_html_components as html import plotly.express as px import pandas as pd external_stylesheets = [\u0026#39;https://codepen.io/chriddyp/pen/bWLwgP.css\u0026#39;] app = dash.Dash(__name__, external_stylesheets=external_stylesheets) server = app.server df = pd.DataFrame({ \u0026#34;Fruit\u0026#34;: [\u0026#34;Apples\u0026#34;, \u0026#34;Oranges\u0026#34;, \u0026#34;Bananas\u0026#34;, \u0026#34;Apples\u0026#34;, \u0026#34;Oranges\u0026#34;, \u0026#34;Bananas\u0026#34;], \u0026#34;Amount\u0026#34;: [4, 1, 2, 2, 4, 5], \u0026#34;City\u0026#34;: [\u0026#34;SF\u0026#34;, \u0026#34;SF\u0026#34;, \u0026#34;SF\u0026#34;, \u0026#34;Montreal\u0026#34;, \u0026#34;Montreal\u0026#34;, \u0026#34;Montreal\u0026#34;] }) fig = px.bar(df, x=\u0026#34;Fruit\u0026#34;, y=\u0026#34;Amount\u0026#34;, color=\u0026#34;City\u0026#34;, barmode=\u0026#34;group\u0026#34;) app.layout = html.Div(children=[ html.H1(children=\u0026#39;Hello Dash\u0026#39;), html.Div(children=\u0026#39;\u0026#39;\u0026#39; Dash: A web application framework for Python. \u0026#39;\u0026#39;\u0026#39;), dcc.Graph( id=\u0026#39;example-graph\u0026#39;, figure=fig ) ]) if __name__ == \u0026#39;__main__\u0026#39;: app.run_server()   改変個所は以下の2点である。\n server = app.server app.run_server()  Dashアプリをローカルで起動 コンソールを立ち上げ、以下を実行してローカルでWebアプリを立ち上げる。\n\u0026gt; cd (index.pyのあるフォルダ) \u0026gt; python index.py Dash is running on http://127.0.0.1:8050/ * Serving Flask app \u0026quot;index\u0026quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit) 次に、Webブラウザを起動し、http://127.0.0.1:8050/を開いて、以下のような画面が表示されることを確認する。\nアプリを停止するには、コンソール上でCtrl+Cを押す。\nHeroku用のファイルの準備 Heroku用に以下のテキスト形式のファイルを作成する。\n Procfile Procfile.windows (開発環境がWindowsの場合のみ) requirements.txt runtime.txt  各ファイルの内容は以下の通り。\nProcfile Heroku上でWebアプリを起動するためのコマンドを定義したファイル\nweb: gunicorn index:server Procfile.windows 開発環境がWindowsの場合に、Herokuを使ってローカルでWebアプリを起動するためのコマンドを定義したファイル。\nweb: python index.py runserver 0.0.0.0:5000 requirements.txt Webアプリの実行に必要なライブラリを定義したファイル。上記のサンプルコードで必要なライブラリは以下の通り。\ndash dash_core_components dash_html_components plotly pandas numpy gunicorn runtime.txt 実行するPythonのバージョンを定義する。\npython-3.7.8 Gitリポジトリの作成 次に、Gitリポジトリを作成し、ファイルをコミットする。\n\u0026gt; git init \u0026gt; git add . \u0026gt; git commit -m \u0026quot;Make dash app for Heroku\u0026quot; Herokuでの公開 Herokuに登録し、heroku toolbeltというソフトウェアをインストールする。詳細は以下のページを参照。\nherokuを使ってWebアプリケーションを公開しよう\nインストールが完了したら、ターミナルからheroku toolbeltを呼び出せるようになっている。ターミナルを起動し、以下を入力する。\n\u0026gt; heroku login heroku: Press any key to open up the browser to login or q to exit: 適当なキーを押すと、Heroku用のログイン用Webページに接続されるので\u0026quot;Log In\u0026quot;を押す（環境によってはWebページに接続されないようなので、その場合はHerokuに登録したメールアドレスとパスワードを入力する）。\n次に、以下を実行してHeroku用アプリケーションを作成する。\n\u0026gt; heroku create \u0026lt;application-name\u0026gt; \u0026lt;application-name\u0026gt;は公開時のURLに反映される。以下のようにアプリケーション名は省略可能だが、その場合はランダムな名前が付けられる。\n\u0026gt; heroku create 以上でHerokuアプリケーションが作成された。\nここで、Herokuにファイルをアップロードする前に、ローカルで実行できることを確認する。\nWindowsの場合は以下を実行する。\n\u0026gt; heroku local web -f Procfile.windows Linuxの場合は以下。\n$ heroku local web 実行すると以下が表示されるので、表示されたURL（ここではhttp://127.0.0.1:5000/）をブラウザで開く。先ほどの画面が表示されれば成功である。\n17:34:24 web.1 | Dash is running on http://127.0.0.1:5000/ 17:34:24 web.1 | * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 17:34:24 web.1 | * Serving Flask app \u0026quot;index\u0026quot; (lazy loading) 17:34:24 web.1 | * Environment: production 17:34:24 web.1 | WARNING: This is a development server. Do not use it in a production deployment. 17:34:24 web.1 | Use a production WSGI server instead. 17:34:24 web.1 | * Debug mode: off 17:34:46 web.1 | 127.0.0.1 - - [11/Oct/2020 17:34:46] \u0026quot;GET / HTTP/1.1\u0026quot; 200 - 17:34:48 web.1 | 127.0.0.1 - - [11/Oct/2020 17:34:48] \u0026quot;GET /_dash-layout HTTP/1.1\u0026quot; 200 - 17:34:48 web.1 | 127.0.0.1 - - [11/Oct/2020 17:34:48] \u0026quot;GET /_dash-dependencies HTTP/1.1\u0026quot; 200 - 17:34:48 web.1 | 127.0.0.1 - - [11/Oct/2020 17:34:48] \u0026quot;GET /_favicon.ico?v=1.16.3 HTTP/1.1\u0026quot; 200 - 最後に、以下を実行してHerokuサーバにGitリポジトリのファイルをアップロードする（少し時間が掛かる）。\n\u0026gt; git push heroku master 処理の完了後、以下を実行すると公開されたWebアプリがブラウザで開かれる。先ほどの画面が表示されれば成功である。\n\u0026gt; heroku open 参考  Introduction | Dash for Python Documentation | Plotly Getting Started on Heroku with Python | Heroku Dev Center Herokuにデプロイしよう · Django Girls Tutorial: Extensions  ","description":"Pythonの可視化ツールDashで作成したWebアプリを、Webアプリケーション公開用プラットフォームであるHeroku上で公開する手順をまとめた。","id":1,"section":"posts","tags":["Heroku","Python","Dash"],"title":"可視化ツールDashで作成したWebアプリをHerokuで公開する","uri":"https://helve2017.github.io/posts/web-technology/heroku-dash-deploy/"},{"content":"はじめに 本記事ではリストおよび辞書をコピーする4つの方法について説明する。\nPythonでネストされたリストや辞書をコピーするとき、一方に加えた変更が他方に反映されないようにしたい場合は、copyモジュールのdeepcopy()関数を用いる。deepcopy()関数によって、リスト・辞書の参照先でなく、実体が全てコピーされる。\n検証環境は以下の通り。\n    バージョン     Python 3.7.4    リスト・辞書をコピーする方法 Pythonでリスト・辞書をコピーする場合、以下の4つの方法がある（以降ではcopyモジュールのインポートを省略する）。\n1 2 3 4 5 6 7 8  import copy list0 = [0, 1, 2] list1 = list0 # 1. 直接代入する list2 = list0.copy() # 2. copy()メソッド list3 = copy.copy(list0) # 3. copy()関数 list4 = copy.deepcopy(list0) # 4. deepcopy()関数   方法1. はデータの参照先のみがコピーされるため、ネストの有無に関わらず、片方へ変更を加えると他方に反映される。\n方法2. と3. は等価であり、浅いコピー(shallow copy)と呼ばれる。浅いコピーでは、数値や文字列といったデータ型の実体はコピーされるが、一方、ネストの内側のリスト等は参照先のみコピーされる。（詳細は「ミュータブル」の概念を理解する必要があるが、本記事では扱わない）\nそのため、リストまたは辞書がネストされていない場合、片方の変更は他方へ反映されない。しかし、ネストされている場合は、片方の変更が他方へ反映されていまう。\n方法4. は深いコピー(deep copy)と呼ばれ、ネストの有無に関わらず、データの実体を全てコピーする。そのため、片方の変更は他方に反映されない。しかし、当然ながら実行速度は遅くなってしまうため、処理速度が重要な場合には浅いコピーで代用できないか考慮する必要がある。\nネストされた配列・辞書のコピー ネストされた配列・辞書に対して、\n 浅いコピー 深いコピー  でそれぞれコピーを作成する。深いコピーであれば、片方の変更が他方に反映されないことを示す。\n浅いコピー 既に上で述べたように、浅いコピーはcopyモジュールのcopy()関数や、copy()メソッドを使って行う。浅いコピーでPythonのネストされたリストや辞書をコピーする場合、一方のリスト（または辞書）に加えた変更が他方にも反映されてしまう。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  list1 = [[0, 1], [2, 3]] list2 = copy.copy(list1) list1[0][0] = 4 # 0を4に変更 print(list1) # [[4, 1], [2, 3]] print(list2) # [[4, 1], [2, 3]] # list2の0も4に変更される dict1 = {\u0026#34;k0\u0026#34;: {\u0026#34;k00\u0026#34;: \u0026#34;v00\u0026#34;, \u0026#34;k01\u0026#34;: \u0026#34;v01\u0026#34;}, \u0026#34;k1\u0026#34;: {\u0026#34;k10\u0026#34;: \u0026#34;v10\u0026#34;, \u0026#34;k11\u0026#34;: \u0026#34;v11\u0026#34;}} dict2 = dict1.copy() dict1[\u0026#34;k0\u0026#34;][\u0026#34;k00\u0026#34;] = \u0026#34;v22\u0026#34; # \u0026#34;v00\u0026#34;を変更 print(dict1) # {\u0026#39;k0\u0026#39;: {\u0026#39;k00\u0026#39;: \u0026#39;v22\u0026#39;, \u0026#39;k01\u0026#39;: \u0026#39;v01\u0026#39;}, \u0026#39;k1\u0026#39;: {\u0026#39;k10\u0026#39;: \u0026#39;v10\u0026#39;, \u0026#39;k11\u0026#39;: \u0026#39;v11\u0026#39;}} print(dict2) # {\u0026#39;k0\u0026#39;: {\u0026#39;k00\u0026#39;: \u0026#39;v22\u0026#39;, \u0026#39;k01\u0026#39;: \u0026#39;v01\u0026#39;}, \u0026#39;k1\u0026#39;: {\u0026#39;k10\u0026#39;: \u0026#39;v10\u0026#39;, \u0026#39;k11\u0026#39;: \u0026#39;v11\u0026#39;}} # dict2のv00もv22に変更される   深いコピー 最後に、copyモジュールのdeepcopy()関数を使い、深いコピーでネストされたリストと辞書をコピーする。片方への変更が、他方に反映されないことが分かる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  list1 = [[0, 1], [2, 3]] list2 = copy.deepcopy(list1) list1[0][0] = 4 # 0を4に変更 print(list1) # [[4, 1], [2, 3]] print(list2) # [[0, 1], [2, 3]] # list2は0のまま dict1 = {\u0026#34;k0\u0026#34;: {\u0026#34;k00\u0026#34;: \u0026#34;v00\u0026#34;, \u0026#34;k01\u0026#34;: \u0026#34;v01\u0026#34;}, \u0026#34;k1\u0026#34;: {\u0026#34;k10\u0026#34;: \u0026#34;v10\u0026#34;, \u0026#34;k11\u0026#34;: \u0026#34;v11\u0026#34;}} dict2 = copy.deepcopy(dict1) dict1[\u0026#34;k0\u0026#34;][\u0026#34;k00\u0026#34;] = \u0026#34;v22\u0026#34; # \u0026#34;v00\u0026#34;を変更 print(dict1) # {\u0026#39;k0\u0026#39;: {\u0026#39;k00\u0026#39;: \u0026#39;v22\u0026#39;, \u0026#39;k01\u0026#39;: \u0026#39;v01\u0026#39;}, \u0026#39;k1\u0026#39;: {\u0026#39;k10\u0026#39;: \u0026#39;v10\u0026#39;, \u0026#39;k11\u0026#39;: \u0026#39;v11\u0026#39;}} print(dict2) # {\u0026#39;k0\u0026#39;: {\u0026#39;k00\u0026#39;: \u0026#39;v00\u0026#39;, \u0026#39;k01\u0026#39;: \u0026#39;v01\u0026#39;}, \u0026#39;k1\u0026#39;: {\u0026#39;k10\u0026#39;: \u0026#39;v10\u0026#39;, \u0026#39;k11\u0026#39;: \u0026#39;v11\u0026#39;}} # dict2はv00のまま   参考 以下の記事を参考にさせていただいた。組み込み関数のidを使うことによって、データの実体がコピーされたのか、参照先のみコピーされたのかを確認できる。\nPythonのcopyとdeepcopyについて - Qiita\n","description":"Pythonでネストされたリストや辞書をコピーするとき、一方に加えた変更が他方に反映されないようにしたい場合は、copyモジュールのdeepcopy()関数を用いる。deepcopy()関数によって、リスト・辞書の参照先でなく、実体が全てコピーされる。","id":2,"section":"posts","tags":["Python"],"title":"【Python】ネストされたリスト・辞書とdeepcopy","uri":"https://helve2017.github.io/posts/python/python-deepcopy-nested-list-dictionary/"},{"content":"はじめに 個人的によく使用するGitのコマンドをまとめた。なお、個人利用かつ小規模なソフトウェア開発環境であり、ブランチは作成しないため、それに関連するコマンドは記載していない。\n検証環境：Git for Windows v2.27.0\nリポジトリのクローン (clone) リモートにあるリポジトリをローカルにクローン（コピー）する。\n1  git clone https://github.com/xxxxx/xxxxxxxx.git   リポジトリの状態を確認する (status) 1  git status   ファイルの追加 (add) ファイルをインデックス（ステージングエリア）に登録する。ファイル名をスペースで区切ることで、複数のファイルを追加できる。また、ファイル名は相対パスまたは絶対パスで指定する。\n1  git add \u0026lt;ファイル名\u0026gt;   Gitで管理していないファイルも含めてインデックスに追加する（カレントディレクトリより上のフォルダ階層も含むリポジトリ全体を処理する）。\n1 2 3  $ git add -A or $ git add --all   Gitで管理している全てのファイルの変更内容をインデックスに追加する（カレントディレクトリより上のフォルダ階層も含むリポジトリ全体を処理する）。\n1 2 3  $ git add -u or $ git add --update   コミット (commit) コミット時には、-mオプションの後ろにメッセージを入力する。\n1  $ git commit -m \u0026#34;コミットメッセージ\u0026#34;   複数行のコミットメッセージを入力したい場合は、以下のように複数の-mオプションを付ける。\n1  $ git commit -m \u0026#34;コミットメッセージ1\u0026#34; -m \u0026#34;コミットメッセージ2\u0026#34;   または、以下のようにオプションを付けずに実行するとテキストエディタが起動するので、それに入力する。\n1  $ git commit   プッシュする (push) 1  $ git push   ファイルの差分を確認 (diff) git diffでインデックスと作業ツリー（現在ローカルで作業中のディレクトリ）の差分を表示する。ファイル名を指定しない場合は、全ファイルの差分を表示する。\n1  git diff \u0026lt;ファイル名\u0026gt;   特定のコミットとの差分を表示する場合は、ハッシュ値を追加する（ファイル名はオプション）。\n1  git diff \u0026lt;commit\u0026gt; \u0026lt;ファイル名\u0026gt;   また、コミットとインデックスの差分を表示するには、--cachedオプションを追加する（ファイル名はオプション）。\n1  git diff --cached \u0026lt;ファイル名\u0026gt;   git diffのオプションと差分の関係は以下の通り。\n┌ git diff --cached \u0026lt;commit\u0026gt; ┐ | ┌-- git diff --cached --┐ | HEADコミット インデックス 作業ツリー O-----O----------------------O-------------O | └-- git diff -┘ └------------ git diff \u0026lt;commit\u0026gt; -----------┘ さらに、コミット間の比較も可能（ファイル名はオプション）。\n1  git diff \u0026lt;変更前のcommit\u0026gt; \u0026lt;変更後のcommit\u0026gt; \u0026lt;ファイル名\u0026gt;   単語単位で差分を表示する場合は、--word-diffオプションを追加する。さらに文字の色の違いだけで差分を表示させるには、後ろに=colorを追加する。\n1 2  git diff --word-diff git diff --word-diff=color   操作の取り消し・修正 addの取り消し (reset) git addでファイルの変更がインデックスに登録されるが、その登録を取り消すには以下を実行する。ファイル名を指定しない場合は、全てのファイルのインデックス登録が削除される。なお、以下のコマンドを実行してもファイルの中身は変更されない（HEADコミットの状態には戻らない）。\n1  $ git reset HEAD \u0026lt;ファイル名\u0026gt;   commitの取り消し (reset) 直前のコミットを取り消すには以下を実行する。\n1  $ git reset --hard HEAD^   なお、オプションの意味は次の通り。\n --hard: コミットを取り消した上でワークディレクトリの内容も書き換える。 --soft: ワークディレクトリの内容はそのままでコミットだけを取り消す。  また、HEAD^はHEADコミットの1つ前のコミットを意味する。HEAD^の代わりにコミットのハッシュ値としても良い。\nコミットメッセージの修正 (ammend) 直前のcommitのメッセージを修正したい場合、以下のコマンドを実行する。\n1  $ git commit --amend \u0026#34;修正後のコミットメッセージ\u0026#34;   コミット履歴を確認する (log) 1  $ git log   また、logの後ろにファイル名を追加すると、そのファイルが関連するコミットのみ表示されるようになる。\n主なオプションは以下の通り。\n   オプション 説明     -\u0026lt;n\u0026gt; n回分の最新コミットを表示   --oneline 1コミットを1行で表示    ファイル操作 ファイル削除 (rm) ファイルを削除し、gitの管理からも外す。\n1  $ git rm \u0026lt;ファイル名\u0026gt;   フォルダごと削除し、gitの管理からも外す。\n1  $ git rm -r \u0026lt;フォルダ名\u0026gt;   ファイルをgitの管理から外すが、ファイル自体は作業ツリーに残す。\n1  $ git rm --cached \u0026lt;ファイル名\u0026gt;   ファイル名変更 (mv) 1  $ git mv \u0026lt;元のファイル名\u0026gt; \u0026lt;変更後のファイル名\u0026gt;   ファイルを特定のコミットまで戻す (checkout) 1  $ git checkout \u0026lt;commit\u0026gt; \u0026lt;ファイル名\u0026gt;   最新のコミットに戻したい場合は、ハッシュ値の代わりにHEADでも良い。\nファイル内を検索 (grep) 指定したキーワードが含まれるファイル名と、キーワードを含む行を表示する（大文字小文字は区別される）。また、検索対象はカレントディレクトリ以下のフォルダである。\n1  $ git grep \u0026#34;キーワード\u0026#34;   キーワードにスペースが含まれない場合は、ダブルクォーテーションは不要である。\n主なオプションは以下の通り。\n   オプション 説明     -i 大文字小文字を区別しない   -w 単語単位で検索する   -E 正規表現を使う   -n 行番号を表示する    また、AND, OR検索は--and/--orオプションを使う。以下のように各キーワードの前に-eを置いて、--and/--orを挟む。\n1  $ git grep -e \u0026#34;キーワード1\u0026#34; --and -e \u0026#34;キーワード2\u0026#34;   ただし、キーワード1, キーワード2は、ファイルの同じ行になければ検索にヒットしない。さらに、--notオプションを使うとNOT検索もできる。\n1 2 3 4 5 6  # 例1: ABCと123を両方含む $ git grep -e ABC --and -e 123 # 例1: ABCか123の少なくとも片方を含む $ git grep -e ABC --or -e 123 # 例1: ABCを含むが、123は含まない $ git grep -e ABC --and --not -e 123   コミットの詳細確認 (show) 以下のコマンドで、コミットの日時や、ファイルの差分などが表示される。\n1  $ git show \u0026lt;commit\u0026gt;   なお、\u0026lt;commit\u0026gt;を入力しないと、最新コミットの詳細が表示される（以下と同じ意味）。\n1  $ git show HEAD   エイリアスの登録 エイリアスは「別名」の意味。エイリアスを設定することで、長いコマンド（オプションを含む）を短縮した形で呼び出すことができる。エイリアスを設定するには、Gitの設定ファイルを編集する方法と、コマンドから設定する方法の2つがある。また、エイリアスは下表の3階層で設定可能であり、複数の階層で同じエイリアスが設定されている場合には、数字が大きい階層が優先される。\n   階層 種類 対象範囲     1 system マシン単位   2 global ユーザ単位   3 local リポジトリ単位    設定ファイルを直接編集するには、以下のコマンドを実行する（ユーザ単位の設定ファイルの場合）。\n1  git config --global --edit   マシン単位やリポジトリ単位の設定ファイルを編集するには、--globalを--systemや--localにそれぞれ変更する。\n実行すると設定ファイルがエディタで開かれるので、以下のようにエイリアスを記述する。\n[alias] co = checkout logo = log --oneline ここで、[alias]というセクションを作っており、それより後の行にエイリアスを登録する。=の左側にエイリアスを、右側に短縮前のコマンドをそれぞれ記述する。記述が終了したら、エディタを閉じる。\nまた、コマンドからエイリアスを設定するには、以下のようなコマンドを実行する（ユーザ単位で設定する場合）。\n1 2  git config --global alias.co checkout git config --global alias.logo \u0026#34;log --oneline\u0026#34;   マシン単位やリポジトリ単位で設定するには、--globalを--systemや--localにそれぞれ変更する。コマンドを実行すると、対応する設定ファイルにエイリアスが登録されている。\nヘルプを読む Gitのコマンドのヘルプを表示するには、以下のいずれかを実行する。\n1 2 3  $ git help \u0026lt;verb\u0026gt; $ git \u0026lt;verb\u0026gt; --help $ man git-\u0026lt;verb\u0026gt;   参考文献 Git - Reference\nGitコマンド早見表 - Qiita\n【git】aliasの設定方法 - Qiita\n","description":"個人的によく使用するGitのコマンドをまとめた（ブランチに関連するコマンドを除く）。","id":3,"section":"posts","tags":["Git"],"title":"Gitコマンドの個人的まとめ（ブランチ利用なし）","uri":"https://helve2017.github.io/posts/git/git-commands/"},{"content":"はじめに 最適化問題には、最適な組み合わせを選ぶ問題がある。このような組み合わせ最適化問題は、問題の規模が大きくなると、連続値の中から最適な値を見つける問題と比べて、解きづらくなる性質がある。\n組み合わせ最適化問題を効率的に解く手法として、分枝限定法と呼ばれる手法がある。分枝限定法は、組み合わせの条件を連続値に緩和した問題（緩和問題）を解いて、上界と下界を用いて無駄な探索を省略する手法である。\n本記事では、はじめに組合せ最適化問題の1つである0-1ナップサック問題について簡単に示す。次に、分枝限定法のアルゴリズムを示し、0-1ナップサック問題を対象とした分枝限定法の例題を示す。さらに、分枝限定法を実装した無償ソルバ、および例題を検証するためのPythonソースコードを示す。\nソースコードの検証環境\n    バージョン     Python 3.7.4   Pyomo 5.6.9   GLPK 4.65    ナップサック問題 ナップサック問題とは、次のような組合せ最適化問題である。\n N種類の荷物があり、各荷物は価値$p_i$と容積$c_i$を持つ($i=1,\u0026hellip;,N$)。\nまた、ナップサックの容量を$C$とする。\nナップサックの容量を超えない範囲で荷物を詰めるときに、\n詰める荷物の価値を最大にするには、どのような荷物の組み合わせとすればよいか。\n 同じ種類の荷物は1つまでしか入れられない場合や、いくつでも入れられる場合など、いくつかのバリエーションがある。前者の場合を特に0-1ナップサック問題と呼ぶ。本記事では0-1ナップサック問題を対象に分枝限定法について述べる。\n0-1ナップサック問題を式で表すと、以下のようになる。\n$$ \\begin{array}{ll} \\text{maximize} \\ \u0026amp; \\sum_{i=1}^{N} p_i x_i \\\\ \\text{subject to} \\ \u0026amp; \\sum_{i=1}^{N} c_i x_i \\le C \\\\ \u0026amp; x_i \\in {0, 1}, (i=1, \u0026hellip;, N) \\end{array} $$\nここで、$x_i=0$は荷物$i$がナップサックに詰められていないことを表し、$x_i=1$は荷物$i$がナップサックに詰められていることを表す。\n0-1ナップサック問題の最適解を総当たりで求めようとすると、$2^N$回の計算が必要になり、$N$が大きくなるにつれて計算時間が指数関数的に増加してしまう。\n分枝限定法 分枝限定法 (branch and bound) は、変数$x_i$の整数条件を連続値に緩和した問題（緩和問題）を解いて、上界と下界を用いて無駄な探索を省略する手法である。（緩和問題が単純な線形計画問題である場合、大規模な問題であったとしても比較的容易に最適解が求められることが、分枝限定法の前提にある）\n通常、緩和問題の最適解は元の整数計画問題の最適解と一致しない(0, 1の組み合わせにならない)ので、連続値に緩和した変数を1つずつ0または1に固定して、問題を分割させながら探索する。この分割操作を分枝 (branching) と呼ぶ。\nさらに、分枝限定法の場合、上界 (upper bound) とは緩和問題の最適値であり、元の整数計画問題の最適値か、それより大きいとみなせる値である。また、下界 (lower bound) とは元の整数計画問題の最適値かそれより小さいとみなせる値である。（上界）≥（最適値）≥（下界）の関係が成り立つ。\nしたがって、ある分枝における下界が、別の分枝における上界よりも大きい場合、後者の分枝をそれ以上探索しても、最適解が得られる見込みがないため、探索を打ち切る。この打ち切り操作を限定 (bounding) 操作と呼ぶ。\n分枝限定法の例 次の0-1ナップサック問題(N=4)を対象に、分枝限定法の例を示す。\n$$ \\begin{array}{ll} \\text{maximize} \\ \u0026amp; 2x_1 + 4x_2 + 20x_3 + 24x_4 \\\\ \\text{subject to} \\ \u0026amp; x_1 + 4x_2 + 5x_3 + 8x_4 \\le 9 \\\\ \u0026amp; x_i \\in {0, 1}, (i=1, \u0026hellip;, 4) \\end{array} $$\nまず、$x_i (i=1,\u0026hellip;,4)$を全て連続値とした緩和問題(P0)を考える。緩和問題P0は、$\\boldsymbol{x} =(0, 0, 1, 0.5)$で最適解32をとる。この32という値は整数条件を緩めて得られた解であるから、元の整数計画問題の解は32以下であると考えられる（すなわち、32は上界である）。\n次に、緩和問題P0の最適解において整数でなかった$x_4$が、0の場合と1の場合に分けて考える（分枝）。$x_4=0$で固定として$x_1, x_2, x_3$を連続値とした緩和問題をP1, $x_4=1$で固定として$x_1, x_2, x_3$を連続値とした緩和問題をP2とする。\n緩和問題P1を解くと、$\\boldsymbol{x} =(1, 0.75, 1, 0)$で最適値25をとる。P1の上界は25である。\nまた、緩和問題P2は、$\\boldsymbol{x} =(0, 0, 0.2, 1)$で最適値28をとる。P2の上界は28である。\nP1とP2のどちらを先に探索しても良いが、ここでは上界が大きいP2 (28 \u0026gt; 25) に整数計画問題の最適解がある可能性が高いと考え、P2を先に探索する。この探索方法を最良優先探索と呼ぶ。\nP2の最適解$\\boldsymbol{x} =(0, 0, 0.2, 1)$において、整数でないのは$x_3=0.2$である。P2をさらに分枝して、\n$(x_3, x_4)=(0, 1)$で固定として$x_1, x_2$を連続値とした緩和問題をP3, $(x_3, x_4)=(1, 1)$で固定として$x_1, x_2$を連続値とした緩和問題をP4とする。\nP3を解くと、$\\boldsymbol{x} =(1, 0, 0, 1)$で最適値26をとる。この解は全て整数であるので、元の整数計画問題の解の候補となる。また、元の整数計画問題の解は、P3の最適値26以上と考えられるため、この26は下界である。また、P3において、$x_1, x_2$をさらに0または1に固定したとしても、P3より良い解が得られることはないため、これ以上の分枝は不要である。\nここで、緩和問題P1の上界は25であった。これは、P1の連続値を整数に縛った場合、その最適値は25以下であることを意味する。すなわち、P1を分枝しても、P3の下界26より良い解が得られる可能性がないことを意味するため、P1の探索を打ち切る（限定操作）。\n最後に、緩和問題P4は$(x_3, x_4)=(1, 1)$とした時点で、制約条件$x_1 + 4x_2 + 5x_3 + 8x_4 \\le 9$を満たさず実行可能解を持たないため、これ以上分枝する必要はない。\n以上が分枝限定法の例である。全ての解候補を探索することなく、効率的に大域的最適解を求められることが分かる。\nなお、最良優先探索以外にも様々な探索アルゴリズムがあり、深さ優先探索という手法も良く使われる。深さ優先探索は、上記の例で示すとP1を解いた後、P2より先にP1を分枝して次々解いていく方法であり、以下のメリットがある。\n 実装が簡単 使用メモリが少なくて済む 早く暫定解が得られる  一方、最良優先探索と比べると、計算量が多くなりやすいデメリットがある。\n分枝限定法が実装されている無償ソルバ 分枝限定法が実装されている主な無償ソルバは以下の通り。\n CBC (COIN-OR branch and cut) GLPK (GNU Linear Programming Kit)  GLPKはconda環境でインストールでき、pyomoというモデリングツールとの連携も容易である。\n検証用のPythonコード 上記の分枝限定法の例を検証したPythonのソースコードを以下に示す。PyomoとGLPKを使用した。両者の導入については、以下の記事を参照。\nPyomoで線形計画問題を解く\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  import pyomo.environ as pyo def ObjRule(model): return 2*model.x1 + 4*model.x2 + 20*model.x3 + 24*model.x4 def ConstRule(model): return 1*model.x1 + 4*model.x2 + 5*model.x3 + 8*model.x4 \u0026lt;= 9 model = pyo.ConcreteModel() model.x1 = pyo.Var(domain=pyo.NonNegativeReals, bounds=(0, 1)) model.x2 = pyo.Var(domain=pyo.NonNegativeReals, bounds=(0, 1)) model.x3 = pyo.Var(domain=pyo.NonNegativeReals, bounds=(0, 1)) model.x4 = pyo.Var(domain=pyo.NonNegativeReals, bounds=(0, 1)) # boundsの範囲を(0, 0)や(1, 1)とすれば値を固定できる model.OBJ = pyo.Objective(rule = ObjRule, sense = pyo.maximize) model.Constraint1 = pyo.Constraint(rule = ConstRule) opt = pyo.SolverFactory(\u0026#39;glpk\u0026#39;) res = opt.solve(model, tee=False) # tee=Trueとすればソルバーのメッセージが表示 print(f\u0026#34;評価関数：{model.OBJ()}\u0026#34;) print(f\u0026#34;x1: {model.x1()}\u0026#34;) print(f\u0026#34;x2: {model.x2()}\u0026#34;) print(f\u0026#34;x3: {model.x3()}\u0026#34;) print(f\u0026#34;x4: {model.x4()}\u0026#34;)   また、変数x1, \u0026hellip;, x4を以下のように置き換えれば、整数計画問題としてGLPKに解かせることができる。\n1 2 3 4  model.x1 = pyo.Var(domain=pyo.Binary) model.x2 = pyo.Var(domain=pyo.Binary) model.x3 = pyo.Var(domain=pyo.Binary) model.x4 = pyo.Var(domain=pyo.Binary)   参考 ナップサック問題について\nナップサック問題 - Wikipedia\n分枝限定法について\n数理計画法第6回（東北大学講義資料、PDF）\n最適化手法 第 5回 整数計画法 (4)：分枝限定法（電通大講義資料、PDF）\n","description":"分枝限定法は、組合せ最適化問題の解を効率的に求める手法である。組合せ最適化問題の1つであるナップサック問題を対象に、分枝限定法のアルゴリズムを示す。","id":4,"section":"posts","tags":["最適化"],"title":"ナップサック問題と分枝限定法","uri":"https://helve2017.github.io/posts/math/knapsack-problem-branch-and-bound/"},{"content":"はじめに 本記事は以下の記事の続きである。等式制約を2つ持つ最適化問題をラグランジュの未定乗数法で解き、その幾何学的な意味を示す。\n等式制約付き最適化問題とラグランジュの未定乗数法 前編\n例題（承前） 例題2 等式制約が2つある場合 2次元ベクトル$\\boldsymbol{x}=(x_1, x_2)$に対して、次式の等式制約を2つ持つ最小化問題を考える。\n$$ \\begin{array}{ll} \\mathrm{min} \\ \u0026amp; f(\\boldsymbol{x}) = x_1^2 + x_2^2 \\\\ \\mathrm{s.t.}\\ \u0026amp; g_1(\\boldsymbol{x}) = x_1 + 2 x_2 - 6 = 0 \\\\ \u0026amp; g_2(\\boldsymbol{x}) = 2 x_1 + x_2 - 6 = 0 \\end{array}$$\n上記の$f$は凸関数かつ、$g_i$は全て1次式であるから、ラグランジュの未定乗数法で得られる解は最適解になる。なお、最適解は$(x_1, x_2)=(2, 2)$となり、最小値$f=8$を得る（下図参照）。\n上記の問題のラグランジュ関数は次式で与えられる。\n$$ L(\\boldsymbol{x}, \\boldsymbol{\\lambda}) = x_1^2 + x_2^2 - \\lambda_1 (x_1 + 2 x_2 - 6) - \\lambda_2 (2 x_1 + x_2 - 6) $$\n最適解は、このラグランジュ関数の勾配ベクトルの各成分が0となる$\\boldsymbol{x}$である。よって、次の連立方程式が得られる。\n$$ \\nabla_\\boldsymbol{x} L(\\boldsymbol{x}, \\boldsymbol{\\lambda}) = \\left[ \\begin{array}{l} \\frac{\\partial L}{\\partial x_1} \\\\ \\frac{\\partial L}{\\partial x_2} \\end{array} \\right] = \\left[ \\begin{array}{l} 2 x_1 - \\lambda_1 - 2 \\lambda_2 \\\\ 2 x_2 - 2 \\lambda_1 - \\lambda_2 \\end{array} \\right] = \\left[ \\begin{array}{l} 0 \\\\ 0 \\end{array} \\right] $$\n$$ \\nabla_\\boldsymbol{\\lambda} L(\\boldsymbol{x}, \\boldsymbol{\\lambda}) = \\left[ \\begin{array}{l} \\frac{\\partial L}{\\partial \\lambda_1} \\\\ \\frac{\\partial L}{\\partial \\lambda_2} \\end{array} \\right] = \\left[ \\begin{array}{l} - (x_1 + 2 x_2 - 6) \\\\ - (2 x_1 + x_2 - 6) \\end{array} \\right] = \\left[ \\begin{array}{l} 0 \\\\ 0 \\end{array} \\right] $$\n連立方程式を解くと、以下の解が得られる。\n$$ (x_1, x_2, \\lambda_1, \\lambda_2) = (2, 2, \\frac{4}{3}, \\frac{4}{3}) $$\nしたがって、最適解は$\\boldsymbol{x}^{*}=(2, 2)$となる。このとき、目的関数は$f=8$となる。\nまた、最適解における評価関数と等式制約の各勾配ベクトルは以下のようになる。\n$$ \\nabla f(\\boldsymbol{x}^*) = \\left[ \\begin{array}{l} 4 \\\\ 4 \\end{array} \\right] $$\n$$ \\nabla g_1(\\boldsymbol{x}^*) = \\left[ \\begin{array}{l} 2 \\\\ 1 \\end{array} \\right]$$\n$$ \\nabla g_2(\\boldsymbol{x}^*) = \\left[ \\begin{array}{l} 1 \\\\ 2 \\end{array} \\right] $$\nここで、$(\\lambda_1, \\lambda_2)=(4/3, 4/3)$であるから、次式が成り立つ。\n$$ \\nabla f(\\boldsymbol{x}^{*}) = \\lambda_1 \\nabla g_1(\\boldsymbol{x}^{*}) + \\lambda_2 \\nabla g_2(\\boldsymbol{x}^{*}) $$\n$$ \\left[ \\begin{array}{l} 4 \\\\ 4 \\end{array} \\right] = \\frac{4}{3} \\left[ \\begin{array}{l} 2 \\\\ 1 \\end{array} \\right] + \\frac{4}{3} \\left[ \\begin{array}{l} 1 \\\\ 2 \\end{array} \\right] $$\nすなわち、最適解において、評価関数の勾配ベクトルと、等式制約の勾配ベクトルの線形和は等しい。\n","description":"等式制約付き最適化問題に対する、ラグランジュの未定乗数法についてまとめた。簡単な例題に対して、最適解が満たす幾何学的な意味を示す。","id":5,"section":"posts","tags":["最適化"],"title":"等式制約付き最適化問題とラグランジュの未定乗数法 後編","uri":"https://helve2017.github.io/posts/math/lagrange-multiplier-with-equality-constraints-2/"},{"content":"はじめに ラグランジュの未定乗数法は制約条件を持つ最適化問題を解くための手法である。この手法は非線形問題に対して適用でき、内点法や有効制約法などにおいても利用されている。\nラグランジュの未定乗数法では、制約条件に定数（ラグランジュ乗数）を掛けて目的関数と線形結合したラグランジュ関数と呼ばれる関数を定義する。この関数の極値を求めると、局所最適解が得られる（問題が特定の条件を満たせば最適解が得られる）。\nまた、ラグランジュの未定乗数法は、等式制約を持つ場合、不等式制約を持つ場合、またはそれら両方を持つ場合のどちらでも適用できる。本記事では、等式制約のみ持つ場合を対象とする。\n（※ただし、不等式制約はスラック変数を導入して等式制約に置き換えることができる。例えば、不等式制約$g(x) \\le 0$は、スラック変数$s \\ge 0$を用いて等式制約$g(x)+s=0$に置き換えられる。そのため、単に最適化問題を解くためであれば、等式制約のみ扱う手法のみ知っていれば実用上は問題ない）\n対象とする問題 以下の等式制約付き非線形最小化問題を考える。\n$$ \\begin{array}{ll} \u0026amp; \\mathrm{min} \\ f(\\boldsymbol{x}) \\\\ \u0026amp; \\mathrm{s.t.}\\ g_i(\\boldsymbol{x})=0 \\ (i=1, \u0026hellip;, m) \\tag{1} \\end{array} $$\nここで、$\\boldsymbol{x} \\in \\mathbb{R}^n$, $n \\ge m$とする。また、$f, g$は微分可能とする。\nこれは、等式制約$g_i(\\boldsymbol{x})=0$をすべて満たし、関数$f(\\boldsymbol{x})$を最小化する変数$\\boldsymbol{x}$を求める問題となる。\nラグランジュの未定乗数法 上記の問題に対して、次式の関数を定義する。\n$$ \\begin{array}{ll} L(\\boldsymbol{x}, \\boldsymbol{\\lambda}) \u0026amp; = f(\\boldsymbol{x}) - \\boldsymbol{\\lambda}^{\\top} \\boldsymbol{g}(\\boldsymbol{x}) \\\\ \u0026amp; = f(\\boldsymbol{x}) - \\sum_{i=1}^{m} \\lambda_i g_i(\\boldsymbol{x}) \\end{array} \\tag{2} $$\nこれをラグランジュ関数と呼ぶ。また、$\\lambda_i (i=1, \u0026hellip;, m)$をラグランジュ乗数、$\\boldsymbol{\\lambda}$をラグランジュ乗数ベクトルと呼ぶ。\n等式付き制約問題の局所解を$\\boldsymbol{x}^{*}$とすると、$\\boldsymbol{x}^{*}$は次の等式を満たす。\n$$ \\nabla_\\boldsymbol{x} L(\\boldsymbol{x}^*, \\boldsymbol{\\lambda}^*) = \\nabla f(\\boldsymbol{x}^*) - \\sum_{i=1}^{m} \\lambda_i^* \\nabla g_i(\\boldsymbol{x^*}) = \\boldsymbol{0} \\tag{3} $$\n$$ \\nabla_\\boldsymbol{\\lambda} L(\\boldsymbol{x}^*, \\boldsymbol{\\lambda}^*) = \\boldsymbol{g} (\\boldsymbol{x^*}) = \\boldsymbol{0} \\tag{4} $$\nすなわち、ラグランジュ関数の勾配ベクトルの各成分が0となる値が最適解となる。\n式(3)を変形すると次式を得る。\n$$ \\nabla f(\\boldsymbol{x}^*) = \\sum_{i=1}^{m} \\lambda_i^* \\nabla g_i(\\boldsymbol{x^*}) \\tag{5} $$\nこれは、等式制約$g_i$の勾配ベクトルに、あるラグランジュ乗数$\\lambda_i^{*}$を掛けた合成ベクトルと、目的関数$f$の勾配ベクトルが平行であることを意味する。\nなお、$f$が凸関数かつ、$g_i$が全て1次式ならば、$\\boldsymbol{x}^{*}$は最適解になる。これはKKT条件（Karush-Kuhn-Tucker条件）から得られるが、本記事ではこれ以上触れない。\nまた、式(4)は、局所解が元の最適化問題の等式制約を満たすことを示す。\n例題 以下の2つの例題に対して、ラグランジュの未定乗数法を適用し、幾何学的な意味を示す。\n 等式制約が1つだけの場合 等式制約が2つある場合（後編の記事に分割）  例題1 等式制約が1つだけの場合 2次元ベクトル$\\boldsymbol{x}=(x_1, x_2)$に対して、次式の等式制約を1つだけ持つ最小化問題を考える。\n$$ \\begin{array}{ll} \u0026amp; \\mathrm{min} \\ f(\\boldsymbol{x}) = x_1^2 + x_2^2 \\\\ \u0026amp; \\mathrm{s.t.}\\ g(\\boldsymbol{x}) = x_1 + x_2 - 2 = 0 \\end{array} $$\n上記の$f$は凸関数かつ、$g_i$は全て1次式であるから、ラグランジュの未定乗数法で得られる解は最適解になる。なお、最適解は$(x_1, x_2)=(1, 1)$となり、最小値$f=2$を得る（下図参照）。\n上記の問題のラグランジュ関数は次式で与えられる。\n$$ L(\\boldsymbol{x}, \\boldsymbol{\\lambda}) = x_1^2 + x_2^2 - \\lambda (x_1 + x_2 -2) $$\n最適解は、このラグランジュ関数の勾配ベクトルの各成分が0となる$\\boldsymbol{x}$である。よって、次の連立方程式が得られる。\n$$ \\nabla_\\boldsymbol{x} L(\\boldsymbol{x}, \\boldsymbol{\\lambda}) = \\left[ \\begin{array}{l} \\frac{\\partial L}{\\partial x_1} \\\\ \\frac{\\partial L}{\\partial x_2} \\\\ \\end{array} \\right] = \\left[ \\begin{array}{l} 2 x_1 - \\lambda \\\\ 2 x_2 - \\lambda \\\\ \\end{array} \\right] = \\left[ \\begin{array}{l} 0 \\\\ 0 \\\\ \\end{array} \\right] $$\n$$ \\nabla_\\boldsymbol{\\lambda} L(\\boldsymbol{x}, \\boldsymbol{\\lambda}) = - (x_1 + x_2 - 2) = 0 $$\n連立方程式を解くと、以下の解が得られる。\n$$ (x_1, x_2, \\lambda) = (1, 1, 2) $$\nしたがって、最適解は$\\boldsymbol{x}^{*}=(1, 1)$となる。このとき、目的関数は$f=2$となる。\n$\\nabla_\\boldsymbol{x} L(\\boldsymbol{x}, \\boldsymbol{\\lambda})$は、最適解において評価関数$f$の勾配ベクトルと等式制約$g$の勾配ベクトルが平行であることを意味する。各勾配ベクトルは、\n$$ \\nabla f(\\boldsymbol{x}) = \\left[ \\begin{array}{l} 2 x_1 \\\\ 2 x_2 \\end{array} \\right] $$\n$$ \\nabla g(\\boldsymbol{x}) = \\left[ \\begin{array}{l} 1 \\\\ 1 \\end{array} \\right] $$\nとなる。最適解における$f$の勾配ベクトルは、\n$$ \\nabla f(\\boldsymbol{x}^*) = \\left[ \\begin{array}{l} 2 \\\\ 2 \\end{array} \\right] $$\nであるから、$\\nabla g(\\boldsymbol{x})$に平行である。言い換えると、最適解において、$f$の等高線と$g$の接線は一致する。\n等式制約が2つある場合については、後編の記事を参照。\n等式制約付き最適化問題とラグランジュの未定乗数法 後編\n","description":"等式制約付き最適化問題に対する、ラグランジュの未定乗数法についてまとめた。 また、簡単な例題を用いて、最適解が満たす幾何学的な意味を示す。","id":6,"section":"posts","tags":["最適化"],"title":"等式制約付き最適化問題とラグランジュの未定乗数法 前編","uri":"https://helve2017.github.io/posts/math/lagrange-multiplier-with-equality-constraints-1/"},{"content":"はじめに 主双対内点法とは、実行可能領域の内部を最適解に向けて探索する手法である。本記事では、非線形問題に対する主双対内点法のアルゴリズムについて述べる。線形問題に対する主双対内点法については以下の記事を参照のこと。\n線形計画問題の主双対内点法\n対象とする非線形問題 以下の制約付き非線形計画問題を考える。\n$$ \\begin{array}{l} \\mathrm{min} \\ f(\\boldsymbol{x}) \\\\ \\mathrm{s.t.} \\ \\boldsymbol{g}(\\boldsymbol{x})=\\boldsymbol{0}, \\boldsymbol{x} \\ge \\boldsymbol{0} \\end{array} $$\nここで、$\\boldsymbol{x} \\in \\mathbb{R}^n, \\boldsymbol{g}(\\boldsymbol{x}) \\in \\mathbb{R}^m$である。\nまた、問題に$\\boldsymbol{x} \\ge \\boldsymbol{0}$以外の不等式制約が含まれる場合にも、上記の式の形に変換することが出来る。例えば、\n$\\boldsymbol{h}(\\boldsymbol{x}) \\le \\boldsymbol{0}$\nなる不等式制約$\\boldsymbol{h}(\\boldsymbol{x})$があるとき、新たに変数ベクトル$\\boldsymbol{s} \\ge \\boldsymbol{0}$を導入して、\n$ \\boldsymbol{h}(\\boldsymbol{x}) + \\boldsymbol{s} = \\boldsymbol{0}$\nという等式制約に変換できる。なお、この$\\boldsymbol{s}$をスラック変数と呼ぶ。\n最適解が満たす条件 次に、上記の最適化問題の最適解が満たす条件（最適性条件）を考える。最適性条件は、ラグランジュの未定乗数法により得られる。\nまず、最適化問題のラグランジュ関数を次式で定義する。\n$$ L(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = f(\\boldsymbol{x}) + \\boldsymbol{y}^{\\top} \\boldsymbol{g}(\\boldsymbol{x}) - \\boldsymbol{z}^{\\top} \\boldsymbol{x} $$\nここで、$\\boldsymbol{y}, \\boldsymbol{z}$はラグランジュ乗数ベクトルである。\n局所解は、次の5つの式を満たす解である。\n$$ \\begin{array}{l} \\nabla_\\boldsymbol{x} L(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = \\boldsymbol{0} \\\\ \\nabla_\\boldsymbol{y} L(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = \\boldsymbol{g}(\\boldsymbol{x}) = \\boldsymbol{0} \\\\ \\nabla_\\boldsymbol{z} L(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = - \\boldsymbol{x} \\le \\boldsymbol{0} \\\\ \\boldsymbol{z} \\ge \\boldsymbol{0} \\\\ z_i x_i = 0 \\ (i=1, \u0026hellip;, m) \\end{array} $$\n上記の5つの条件を Karush-Kuhn-Tucker条件（KKT条件） と呼ぶ。また、$z_i x_i = 0 \\ (i=1, \u0026hellip;, m)$を相補性条件 (complementarity condition)と呼ぶ。\nさらに、\n$ \\boldsymbol{w}=[\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}]^{\\top} $\nとおき、KKT条件を以下のように変形する。\n$$ \\begin{array}{c} \\boldsymbol{r_0} (\\boldsymbol{w}) = \\left[ \\begin{array}{c} \\nabla_\\boldsymbol{x} L(\\boldsymbol{w}) \\\\ \\boldsymbol{g}(\\boldsymbol{x}) \\\\ XZ \\boldsymbol{e} \\end{array} \\right] = \\left[ \\begin{array}{l} \\boldsymbol{0} \\\\ \\boldsymbol{0} \\\\ \\boldsymbol{0} \\end{array} \\right] \\\\ \\boldsymbol{x} \\ge \\boldsymbol{0} \\\\ \\boldsymbol{z} \\ge \\boldsymbol{0} \\end{array} $$\nここで、\n$$ \\begin{array}{c} X = \\mathrm{diag}(x_1, x_2, \u0026hellip;, x_n) \\in \\mathbb{R}^{n \\times n}, \\\\ Z = \\mathrm{diag}(z_1, z_2, \u0026hellip;, z_n) \\in \\mathbb{R}^{n \\times n}, \\\\ \\boldsymbol{e} = [1, 1, \u0026hellip;, 1 ] ^{\\top} \\in \\mathbb{R}^n \\end{array} $$\nである。なお、diagは対角行列である。\n主双対内点法のアルゴリズム 中心化KKT条件 変形後のKKT条件をそのまま内点法で解く場合、計算途中の解が$\\boldsymbol{x} = \\boldsymbol{0}, \\boldsymbol{z} = \\boldsymbol{0}$の境界に近づくと、収束が遅くなる可能性がある。そこで、バリアパラメータと呼ばれる変数を導入し、計算途中の解を境界から離しながら最適解に近づける。\nバリアパラメータ$\\mu (\u0026gt; 0)$を導入したKKT条件は次式のようになる。\n$$ \\begin{array}{c} \\boldsymbol{r} (\\boldsymbol{w}; \\mu) = \\left[ \\begin{array}{c} \\nabla_\\boldsymbol{x} L(\\boldsymbol{w}) \\\\ \\boldsymbol{g}(\\boldsymbol{x}) \\\\ XZ \\boldsymbol{e} - \\mu \\boldsymbol{e} \\end{array} \\right] = \\left[ \\begin{array}{l} \\boldsymbol{0} \\\\ \\boldsymbol{0} \\\\ \\boldsymbol{0} \\end{array} \\right] \\\\ \\boldsymbol{x} \\ge \\boldsymbol{0} \\\\ \\boldsymbol{z} \\ge \\boldsymbol{0} \\end{array} $$\nこれを中心化KKT条件またはバリアKKT条件と呼ぶ。$\\mu =0$とすると、中心化KKT条件の解はもとのKKT条件の解に等しくなる。主双対内点法では、始めに適当な$\\mu$の初期値を与え、解の更新の度に徐々に$\\mu$の値を小さくして0に近づけていく。\n解の更新 中心化KKT条件の方程式は非線形であるため、最適解を直接求めることは困難である。よって、ニュートン法により解候補を徐々に最適解の方向に更新することによって最適解を求める。\n解の更新方向を\n$ \\boldsymbol{\\Delta w} = [\\boldsymbol{\\Delta x}, \\boldsymbol{\\Delta y}, \\boldsymbol{\\Delta z}]^{\\top}$\nとすると、これを求めるには次の1次方程式を解けばよい。\n$J(\\boldsymbol{w}) \\boldsymbol{\\Delta w} = - \\boldsymbol{r} (\\boldsymbol{w}; \\mu)$\nここで、$J(\\boldsymbol{w})$は$\\boldsymbol{r} (\\boldsymbol{w}; \\mu)$のヤコビ行列であり、\n$$ J(\\boldsymbol{w}) = \\left[ \\begin{array}{ccc} \\nabla_x^2 L(\\boldsymbol{w}) \u0026amp; \\nabla \\boldsymbol{g}(\\boldsymbol{x}) \u0026amp; -I \\\\ \\nabla \\boldsymbol{g}(\\boldsymbol{x})^{\\top} \u0026amp; O \u0026amp; O \\\\ Z \u0026amp; O \u0026amp; X \\end{array} \\right] $$\nで与えられる。ただし、$I$は単位行列である。\n解の探索方向が得られれば、適当なステップサイズ$\\alpha \u0026gt; 0$により、解を以下のように更新する。\n$ \\boldsymbol{w}_{k+1} = \\boldsymbol{w}_k + \\alpha \\boldsymbol{\\Delta w}_k $\nただし、添え字の$k$は更新回数を示す。\n以上が、主双対内点法の基本的なアルゴリズムである。\n補足 解の更新幅 解の更新幅$\\alpha$の決め方として、Armijo（アルミホ）条件を用いた直線探索が参考文献の「最適化とその応用」で紹介されている。また、Ipoptという最適化ソルバでは、フィルター法による直線探索が実装されている。\nヘッセ行列の計算 中心化KKT条件のヤコビ行列$J(\\boldsymbol{w})$には、ラグランジュ関数のヘッセ行列\n$ \\nabla^2_x L(\\boldsymbol{w}) $\nが現れている。これは、元の最適化問題の目的関数$f(\\boldsymbol{x})$のヘッセ行列の計算が必要なことを意味する。しかしながら、ヘッセ行列が得られない場合は、準ニュートン法(L-BFGS法)による近似行列で代用することも可能である。\n参考文献 以下のページを参考にさせて頂いた。\n非線形最適化問題に対する主双対内点法の収束性について (PDF)\nhttps://github.com/coin-or/Ipopt\n","description":"非線形問題に対する主双対内点法のアルゴリズムについて解説する。","id":7,"section":"posts","tags":["最適化"],"title":"非線形計画問題の主双対内点法","uri":"https://helve2017.github.io/posts/math/primal_dual_interior_point_methd_nlp/"},{"content":"はじめに 関数の2階微分を利用する最適化手法であるニュートン法について、機械学習プロフェッショナルシリーズの「機械学習のための連続最適化」で勉強したので、備忘録として残す。\n本記事では、ニュートン法と、簡単な関数を対象にPythonで実装した例を示す。使用したPythonとライブラリのバージョンは以下の通り。\n    バージョン     Python 3.7.4   NumPy 1.16.5   matplotlib 3.1.1    ニュートン法 ニュートン法は、関数の2階微分までの情報を用いる最適化手法である。1階微分の情報までしか用いない再急降下法（以下の記事を参照）と比較すると、ニュートン法は解の収束速度が速い利点がある。\n直線探索を使った最急降下法をPythonで実装\n最小化したい関数$f(\\boldsymbol{x})$が2回連続微分可能であるとする。また、反復法により得られた$k$回目の解を$\\boldsymbol{x_k}$とし、$\\boldsymbol{x_k}$に対する解の更新ベクトルを$\\boldsymbol{d}$とする。このとき、更新後の解$\\boldsymbol{x_k+d}$における2次のテイラー展開は次式で近似される。\n$$ f(\\boldsymbol{x_k+d}) = f(\\boldsymbol{x_k}) + \\nabla f(\\boldsymbol{x_k})^\\top \\boldsymbol{d} + \\frac{1}{2} \\boldsymbol{d}^\\top \\nabla ^2 f(\\boldsymbol{x_k}) \\boldsymbol{d} $$\nここで、$\\boldsymbol{x_k+d}$が最適解と仮定すると、$f(\\boldsymbol{x_k+d})$を微分した勾配ベクトルは$\\boldsymbol{0}$である。すなわち、\n$$ \\nabla f(\\boldsymbol{x_k})^\\top + \\nabla ^2 f(\\boldsymbol{x_k}) \\boldsymbol{d} = 0 $$\nここで、ヘッセ行列$\\nabla ^2 f(\\boldsymbol{x_k})$が正定値行列とする。\n正定値行列とは、任意のベクトル$\\boldsymbol{x}$≠$0$に対して、\n$ \\boldsymbol{x}^\\top A \\boldsymbol{x} \u0026gt; 0 $\nとなる行列$A$のことである。また、対称行列$A$が正定値行列の場合、$A$は正則であり、逆行列を持つ。\nすなわち、ヘッセ行列は対称行列であるから、正定値行列であれば逆行列を持つ。\n先ほどの式を$\\boldsymbol{d}$について解くと、以下のようになる。\n$$ \\boldsymbol{d} = - (\\nabla ^2 f(\\boldsymbol{x_k}))^{-1} \\nabla f(\\boldsymbol{x_k}) $$\nしたがって、解を以下のように更新すれば、関数値が減少することが期待できる。\n$$ \\begin{array}{ll} \\boldsymbol{x_{k+1}} \u0026amp; = \\boldsymbol{x_k} + \\boldsymbol{d} \\\\ \u0026amp; = \\boldsymbol{x_k} - (\\nabla ^2 f(\\boldsymbol{x_k}))^{-1} \\nabla f(\\boldsymbol{x_k}) \\end{array} $$\n条件を満たすまで解の更新を繰り返す。\n以上がニュートン法のアルゴリズムである。\nニュートン法の実装例 以下の目的関数を考える。\n$$ f(\\boldsymbol{x}) = x_1^4 + x_1^2 + x_1 x_2 + x_2^2 + 2 x_2^4 $$\nただし、$\\boldsymbol{x}=[x_1, x_2 ]$ である。関数を図示すると以下のようになる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D if False: N = 41 x1 = np.linspace(-2, 2, N) x2 = np.linspace(-2, 2, N) X1, X2 = np.meshgrid(x1, x2) Y = X1**4 + X1**2 + X1*X2 + X2**2 + 2*X2**4 fig = plt.figure() ax = fig.add_subplot(111, projection=\u0026#39;3d\u0026#39;) surf = ax.plot_surface(X1, X2, Y, cmap=\u0026#39;bwr\u0026#39;, linewidth=0) fig.colorbar(surf) ax.set_xlabel(\u0026#34;x1\u0026#34;) ax.set_ylabel(\u0026#34;x2\u0026#34;) fig.show()   目的関数$f(\\boldsymbol{x})$は、$(x_1, x_2)=(0, 0)$で最小値0をとる。\nまた、関数の勾配ベクトルとヘッセ行列はそれぞれ以下のようになる。\n$$ \\nabla f(\\boldsymbol{x}) = [4x_1^3 + 2x_1 + x_2, x_1+ 2x_2 + 8x_2^3 ]^{\\top} $$\n$$ \\nabla ^2 f(\\boldsymbol{x}) = \\begin{bmatrix} 12x_1^2 + 2 \u0026amp; 1 \\\\ 1 \u0026amp; 2+24x_2^2 \\end{bmatrix} $$\n関数値と勾配ベクトル、ヘッセ行列を返す関数を以下のように定義する。\n1 2 3 4 5 6 7  def f(x0, x1): y = x0**4 + x0**2 + x0*x1 + x1**2 + 2*x1**4 dydx = np.array([4*x0**3 + 2*x0 + x1, x0 + 2*x1 + 8*x1**3]) H = np.array([[12*x0+2, 1], [1, 2+24*x1**2]]) return y, dydx, H   ニュートン法を用いた関数の最小化のコードは以下のようになる。ここでは、初期値を$(x_1, x_2)=(2, 2)$とし、反復回数を9回とした。\n1 2 3 4 5 6 7 8  x0, x1 = 2, 2 print(\u0026#34;i x1 x2 f(x)\u0026#34;) for i in range(10): y, dydx, H = f(x0, x1) print(f\u0026#34;{i:3d} [{x0:10.3e}, {x1:10.3e}], {y:10.3e}\u0026#34;) d = - np.dot(np.linalg.inv(H), dydx) x0 += d[0] x1 += d[1]   結果: ニュートン法による最適化計算の推移を以下に示す。$(x_1, x_2)=(0, 0)$で最小値0に収束しており、最適解を求められたことが分かる。\ni x1 x2 f(x)\r0 [ 2.000e+00, 2.000e+00], 6.000e+01\r1 [ 5.654e-01, 1.300e+00], 8.566e+00\r2 [ 2.610e-01, 8.201e-01], 1.864e+00\r3 [ 5.120e-02, 4.836e-01], 3.707e-01\r4 [-8.328e-02, 2.486e-01], 5.574e-02\r5 [ 2.092e-02, 6.459e-02], 5.997e-03\r6 [ 1.783e-03, 1.204e-03], 6.775e-06\r7 [ 2.504e-05, -1.251e-05], 4.703e-10\r8 [ 5.015e-09, -2.508e-09], 1.887e-17\r9 [ 2.012e-16, -1.006e-16], 3.037e-32\r参考 ニュートン法のアルゴリズムについて、機械学習プロフェッショナルシリーズの「機械学習のための連続最適化」を参考にさせて頂いた。\nまた、記事では触れなかったが、ニュートン法による探索方向は降下方向とは異なる場合があるため、初期値が局所解から離れていると収束しない場合がある。\nその欠点を補うため、探索方向が降下方向となるようにニュートン法を改良した修正ニュートン法と呼ばれる手法があり、同書籍で紹介されている。\n","description":"ニュートン法による最適化アルゴリズムへの理解を深めるため、Pythonで実装した。","id":8,"section":"posts","tags":["Python","最適化"],"title":"ニュートン法による最適化とPythonによる実装","uri":"https://helve2017.github.io/posts/math/newtons-method-python/"},{"content":"はじめに PowerShellのGet-Processコマンドレットを使って、特定のプロセスのメモリ使用量を一定周期でロギングするコードを作成した。\nロギング用スクリプト 特定のプロセスのメモリ使用量を一定周期で取得し、テキストファイルにCSV形式で保存するコードは以下の通り。\nただし、同じ名前の複数のプロセスが起動しているときには、それらのプロセスのメモリ使用量を合計する。\n1 2 3 4 5 6 7 8 9 10 11 12  $FileName = \u0026#34;log.txt\u0026#34; $ProcessName = \u0026#34;notepad\u0026#34; \u0026#34;Time,Working set(MB)\u0026#34; | Out-File -Append $FileName while($TRUE){ $d = Get-Date -Format \u0026#34;yyyy-MM-dd HH:mm:ss.ff\u0026#34; $p = Get-Process -Name $ProcessName | Select-Object WS $p | ForEach-Object {$mem = 0} {$mem += $_.WS} $mem = ($mem/1024/1024).ToString() $d+\u0026#39;,\u0026#39;+$mem | Out-File -Append $FileName Start-Sleep -Seconds 1 }   ここで、$FileNameは保存ファイル名、$ProcessNameは取得するプロセス名である。また、Start-Sleep -Secondsで実行周期を秒単位で指定する。\nコードを停止する場合には、Ctrl+Cを押す。\n実行すると、以下のようなCSV形式のファイルが出力される。\nTime,Working set(MB) 2020-09-27 14:57:02.30,95.5 2020-09-27 14:57:03.32,94.4609375 2020-09-27 14:57:04.34,95.5 2020-09-27 14:57:05.37,95.5234375 2020-09-27 14:57:06.40,94.53515625 2020-09-27 14:57:07.43,94.53515625 2020-09-27 14:57:08.45,94.5234375 2020-09-27 14:57:09.49,95.5625 以下、スクリプトを解説する。\nファイルの保存(Out-File) コマンドの出力をファイルに保存するには、Out-Fileコマンドレットを用いる。\n1 2  Get-Process | Out-File output.txt Get-Process | Out-File -Append output.txt   上記のように、文字列（または別のコマンド）をパイプラインでOut-Fileに与えることで、出力を指定した名前のファイルに保存できる。\nまた、-Appendオプションを付けると、出力をファイルの末尾に追加する。\n時刻の取得(Get-Date) システムの時刻を取得するには、Get-Dateコマンドレットを用いる。\nGet-Dateコマンドレットにオプションを付けない場合、戻り値はSystem.DateTimeオブジェクトになる。\n一方、-Formatオプションを追加すると戻り値は文字列になる。\n1  $d = Get-Date -Format \u0026#34;yyyy-MM-dd HH:mm:ss.ff\u0026#34;   この例におけるフォーマットの意味は以下の通り。\n   フォーマット 説明     yyyy 4桁の西暦年   MM 2桁の月   dd 2桁の日   HH 2桁の時間   mm 2桁の分   ss 2桁の秒   ff 秒の端数（ミリ秒）の上位2桁    メモリ使用量の取得(Get-Process) Get-Processコマンドレットを実行すると、プロセスのメモリ使用量などを取得できる。\n例\n1 2 3 4 5 6  PS \u0026gt; Get-Process Handles NPM(K) PM(K) WS(K) CPU(s) Id SI ProcessName ------- ------ ----- ----- ------ -- -- ----------- 855 44 40696 86404 106.11 3828 12 Code 330 17 3972 20736 0.50 6928 12 notepad 345 18 4116 21216 0.23 7432 12 notepad   Get-Processの-NameオプションでProcessNameのプロセス名を指定すると、そのプロセスのみの結果が得られる。\n1 2 3 4 5  PS \u0026gt; Get-Process -Name notepad Handles NPM(K) PM(K) WS(K) CPU(s) Id SI ProcessName ------- ------ ----- ----- ------ -- -- ----------- 330 17 3972 20736 0.50 6928 12 notepad 345 18 4116 21216 0.23 7432 12 notepad   プロセスのメモリ使用量はWS（ワーキングセット）であり、この値を取得するにはSelect-Objectを用いる（WSを取得する理由については後述）。\n1 2 3 4 5  PS \u0026gt; Get-Process -name notepad | Select-Object WS WS -- 21139456 21630976   上記の例のように、プロセスが複数起動している場合は戻り値が複数あるので、それらを合計する（ただし、単位がバイトになっていることに注意）。\n1 2  $p = Get-Process -Name $ProcessName | Select-Object WS $p | ForEach-Object {$mem = 0} {$mem += $_.WS}   ForEach-Objectを使って、%pの各要素からWSの値を.WSプロパティを使って取り出している。また、WSの合計値は$memに格納される。\n（補足）メモリ使用量の種類 Get-Processで取得できるメモリ使用量には、次の3種類がある。\n NPM (Nonpaged System Memory) PM (Paged Memory) WS (Working Set)  正式名称を見てもこれらの違いは分かりづらいが、タスクマネージャの説明が分かりやすかったので、ここに記載する。\nタスクマネージャの「詳細」タブを開き、表のヘッダを右クリックして「列の選択」を押し、以下の項目を表示させる。\n 非ページプール コミットサイズ ワーキングセット(メモリ)  表示した項目と、Get-ProcessのNPM, PM, WSはそれぞれ以下の表の値が等しいことから、同じものを指していることが分かる。\n   Get-Process タスクマネージャ     NPM 非ページプール   PM コミットサイズ   WS ワーキングセット(メモリ)    さらに、タスクマネージャで表示した項目のヘッダにマウスカーソルを置くと、次の説明が表示される。\n 非ページプール：プロセスの代わりにカーネルまたはドライバーによって割り当てられた、ページング不可能なカーネルメモリの量 コミットサイズ：プロセス用にオペレーティングシステムによって予約されている仮想メモリの量 ワーキングセット(メモリ)：プロセスによって現在使用されている物理メモリの量  したがって、プロセスが使用しているメモリ使用量としては、ワーキングセット(WS)を見ればよいことが分かる。\n参考 Get-Processについて\nPowerShell - Powershellのpsコマンドで表示されるプロセスの情報の意味｜teratail\n逆引き！PowerShellでプロセスを取得する方法は？その見方は？【Get-Process】 | 【ﾁｪｼｬわら】PowerShellとは、から学ぶ入門者の教科書-脱コマンドプロンプト-\nメモリのワーキングセットについて\n第4回 メモリ管理：Windows OS入門 - ＠IT\n","description":"","id":9,"section":"posts","tags":["PowerShell"],"title":"Powershellでプロセスのメモリ使用量をロギングする","uri":"https://helve2017.github.io/posts/powershell/powershell-memory-usage-logging/"},{"content":"はじめに Poweshellを使って、フォルダ内のファイルに連番を振ってリネームする方法をまとめた。現在のファイル名の順に連番を振る場合、以下を実行する（拡張子は適宜変更のこと）。\n1 2  ls | sort Name | % {$i = 1} { $NewName = \u0026#34;{0:000}.txt\u0026#34; -f $i; mv $_.Name $NewName; $i++ }   もしくは以下を実行しても同じ結果になる。\n1  ls | sort Name | % {$i = 1} {mv $_.Name (\u0026#34;{0:000}.txt\u0026#34; -f $i++)}   後者のコードは少し複雑なため、本記事では前者を解説する。\n実行手順 あるフォルダに以下のファイルが存在するとする（拡張子はtxt以外でも良い）。\naaa.txt bbb.txt ccc.txt これらのファイルの順番を変更せずに、以下のように連番を振ってリネームしたい。\n001.txt \u0026lt;- aaa.txtからリネーム 002.txt \u0026lt;- bbb.txtからリネーム 003.txt \u0026lt;- ccc.txtからリネーム Powershellを使ってリネームする場合、以下の手順で行う。\nただし、失敗した場合に備えて、あらかじめオリジナルのフォルダをバックアップするか、数個のファイルで動作を検証してから実行されたい。\n フォルダの何もない場所でShiftキーを押しながら右クリックし、「PowerShell ウィンドウをここで開く(S)」を押す。 PowerShellが起動したら、以下のどちらかを実行する（拡張子がtxt以外の場合は適宜変更する）。  1 2  ls | sort Name | % {$i = 1} { $NewName = \u0026#34;{0:000}.txt\u0026#34; -f $i; mv $_.Name $NewName; $i++ }   1  ls | sort Name | % {$i = 1} {mv $_.Name (\u0026#34;{0:000}.txt\u0026#34; -f $i++)}   解説 前者のコマンドレットについて解説する（PowerShellのコマンドは、コマンドレットと呼ばれる）。なお、疑似コードにすると以下のようになる。\nファイルの一覧を取得 ファイル一覧を名前の順にソートする i = 1 for　（各ファイルについてループ） { 新しいファイル名 = {i}.txt ファイル名を「新しいファイル名」に変更 i = i+1 } エイリアス（別名） コマンドレットは基本的に「動詞+名詞」の組み合わせであるが、一部のコマンドレットにはLinuxシェルなどと同じ名前のエイリアス（別名）が付けられている。\n1 2  ls | sort Name | % {$i = 1} { $NewName = \u0026#34;{0:000}.txt\u0026#34; -f $i; mv $_.Name $NewName; $i++ }   というコマンドレットには、以下のエイリアスが含まれている。\n   エイリアス コマンドレット 備考     ls Get-ChildItem ディレクトリ情報の取得   sort Sort-Object ソート   % ForEach-Object 配列のオブジェクトを一つずつ処理   mv Move-Item ファイルの移動・リネーム    パイプライン あるコマンドレットの実行結果を別のコマンドレットで処理したい場合、パイプライン|でコマンドレット同士をつなぐ。\nlsを実行すると、実行フォルダにあるファイル・フォルダのリストが返される。\nそれをsort Nameで名前の順に並べ替える。\nさらに、mvで名前を変更する。\n変数 PowerShellでは、文字列の先頭に$を付けると変数になる。\nここでは$i = 1で変数を宣言し、初期値1を代入している。\nもしファイル名を0始まりにしたい場合は$i = 0とする。\nまた、$NewNameには文字列が格納される。\n$_は少し特殊であり、前のパイプラインから渡されたオブジェクトを表す変数である。\nコマンドレットの先頭から追っていくと、最初のlsはファイルオブジェクトの配列を返す。\nsort Nameは単にソートするだけであるので、やはりファイルオブジェクトの配列を返す。\n2番目のパイプラインの後ろではループ処理が入っている（後述）ので、$_にはファイルオブジェクトが格納されている。\nまた、$_.Nameはファイル名（言い換えるとファイルオブジェクトのNameプロパティ）である。\nForEach-Objectによるループ処理 %（ForEach-Objectのエイリアス）では、配列の要素を一個ずつ取り出して処理することができる。\n1  % {$i = 1} { $NewName = \u0026#34;{0:000}.txt\u0026#34; -f $i ; mv $_.Name $NewName; $i++ }   上記の例では、{$i = 1}が最初に1回だけ実行され、\n{ $NewName = \u0026quot;{0:000}.txt\u0026quot; -f $i ; mv $_.Name $NewName; $i++ }\nは配列の長さ（ここではファイルの数）と同じ回数実行される。\n%では、以下のオプションでループの前および後に処理を追加できる。\n -Begin: ループの前に実行する処理 -Process: ループ内で実行する処理 -End: ループ後に実行する処理  追加する処理は{ }で囲む（囲まれた単位をスクリプトブロックと呼ぶ）。\n例\n最初にAと表示し、ループ回数(3回)だけBと表示し、最後にCと表示する。\n1 2 3 4 5 6  PS \u0026gt; 1..3 | % -Begin {\u0026#34;A\u0026#34;} -Process {\u0026#34;B\u0026#34;} -End {\u0026#34;C\u0026#34;} A B B B C   ここで1..3は数値1, 2, 3の配列である。なお、-Begin, -Process, -Endオプションを指定しない場合、以下のように解釈される。\nスクリプトブロックが、\n 1個の場合：-Process 2個の場合：1個目は-Begin, 2個目は-Process 3個以上の場合：1個目は-Begin, 最後は-End, それ以外は-Process  スクリプトブロックが4個の例 : 最初にAと表示し、ループ回数(3回)だけB, Cの順に表示し、最後にDと表示する。\n1 2 3 4 5 6 7 8 9  PS \u0026gt; 1..3 | % {\u0026#34;A\u0026#34;} {\u0026#34;B\u0026#34;} {\u0026#34;C\u0026#34;} {\u0026#34;D\u0026#34;} A B C B C B C D   数値→文字列変換のフォーマット $iは数値であるので、これをファイル名にするため、以下で文字列に変換する。\n1  $NewName = \u0026#34;{0:000}.txt\u0026#34; -f $i   {0:000}の最初の0は、複数の変数を文字列に変換したいときに、何番目の変数を変換するかを指定する。\n2つの変数を文字列に変換する例\n1 2 3 4  PS \u0026gt; $i = 5 PS \u0026gt; $j = 10 PS \u0026gt; \u0026#34;{0:000}_{1:000}.txt\u0026#34; -f $i, $j 005_010.txt   また、{0:000}の:以降で数値の書式を指定しており、000は先頭を0埋めした3桁の整数を意味する。\nなお、\u0026quot;{0:000}.txt\u0026quot; -f $iは以下と等価である。\n \u0026quot;{0:D3}.txt\u0026quot; -f $i $i.ToString(\u0026quot;000\u0026quot;)+\u0026quot;.txt\u0026quot;  ファイルの名前を変更する mv（Move-Itemのエイリアス）は、以下のようにファイルを移動・または名前を変更するコマンドレットである。\n1  mv [移動元のファイル名] [移動先のファイル名]   なお、移動先に同じ名前のファイルがある場合、mvはエラーを返す。ここでは、\n1  mv $_.Name $NewName   となっているので、現在のファイル名$_.Nameを新しいファイル名$NewNameに変更する。\nまとめ ファイル名に連番を振ってリネームするコマンドレットを再掲する。\n1 2  ls | sort Name | % {$i = 1} { $NewName = \u0026#34;{0:000}.txt\u0026#34; -f $i; mv $_.Name $NewName; $i++ }   ここから$NewNameを省略し、ファイル名の定義時に$iをインクリメントすると、以下のように短縮できる。\n1  ls | sort Name | % {$i = 1} {mv $_.Name (\u0026#34;{0:000}.txt\u0026#34; -f $i++)}   ちなみに、インクリメント演算子++を変数の後ろに置くと、変数の評価後にインクリメントされる。\n逆に++を変数の前に置く(++$i)と、インクリメント後に変数の値が評価されるので注意。\n追記: ファイルの拡張子を自動で引き継ぐ場合は、以下のコマンドレットを実行する。\n1  ls | sort Name | % {$i = 1} {mv $_.Name ((\u0026#34;{0:000}\u0026#34; -f $i++) + $_.Extension)}   参考 【Windows】ファイル名を一括で変更する［連番ファイル名］ | BIZLOG.TECH\n","description":"","id":10,"section":"posts","tags":["PowerShell"],"title":"Powershellでファイル名に連番を振ってリネームする","uri":"https://helve2017.github.io/posts/powershell/powershell-rename-files-serial-number/"},{"content":"はじめに PowerShellでサブフォルダを含むファイル名を一覧表示するには、Get-ChildItem -Recurse -Name -Fileを実行する。さらに、ファイル名で抽出する場合には-Filterオプションを追加する。\n本記事では、上記のコマンドについて解説する。\n動作を確認した環境は以下の通り。\n    バージョン     Windows 10 Home 1909   PowerShell 5.1.18362.752    なお、PowerShellのバージョンは、以下のコマンドで表示されるPSVersionの値から確認できる。\n1  PS \u0026gt; $PSVersionTable   PowerShellの起動 エクスプローラ上でShiftキーを押しながら、アプリケーションキーを押すと（またはマウスの右クリック）、「PowerShell ウィンドウをここで開く(S)」が表示される。\nこれを選択すると、エクスプローラで開いているフォルダをカレントディレクトリとして、PowerShellが起動する。\nGet-ChildItemコマンドレットの基本 Get-ChildItemコマンドレットをオプションを付けずに実行すると、カレントディレクトリにあるフォルダ・ファイルの一覧が表示される。\n例：\n1 2 3 4 5 6 7 8 9 10  PS \u0026gt; Get-ChildItem ディレクトリ: C:\\Test Mode LastWriteTime Length Name ---- ------------- ------ ---- d----- 2020/07/18 10:07 Subdir1 d----- 2020/07/18 10:07 Subdir2 -a---- 2020/07/18 10:07 11 aaa.txt -a---- 2020/07/18 10:07 8 bbb.txt -a---- 2020/07/18 10:08 30 ccc.txt   ここで、Lengthはファイルサイズを表し、単位はバイトである。\nGet-ChildItemコマンドレットの主なオプションは以下の通り。\n   オプション 説明     -Recurse サブフォルダの結果も表示   -Depth -Recurseを適用する階層の深さを指定   -Name ファイル名・フォルダ名のみ表示   -File ファイルのみ結果を表示   -Filter ファイル名・フォルダ名を絞り込み    以下では、各オプションについて解説する。\n-Recurseオプションでサブフォルダも表示 Get-ChildItemコマンドレットに-Recurseオプションを付けて実行すると、全てのサブフォルダにあるフォルダ・ファイルの一覧が表示される。\n1  PS \u0026gt; Get-ChildItem -Recurse   探索するサブフォルダの階層数を制限する場合は、-Depthオプションを追加する。\n-Depthの後に0以上の整数を付けると、その数だけ下の階層を表示する。\n-Depth 0のときにはカレントフォルダの結果しか表示しない。\n例：3階層下までの結果を表示する\n1  PS \u0026gt; Get-ChildItem -Recurse -Depth 3   -Nameオプションでフォルダ名・ファイル名のみ表示 Get-ChildItemコマンドレットに-Nameオプションを付けて実行すると、フォルダ・ファイルの名前のみ表示される。\n例：\n1 2 3 4 5 6  PS C:\\Test\u0026gt; Get-ChildItem -Name Subdir1 Subdir2 aaa.txt bbb.txt ccc.txt   -Fileオプションでファイルのみ表示 Get-ChildItemコマンドレットに-Fileオプションを付けて実行すると、結果からフォルダが除外され、ファイルのみ表示される。\n例：\n1 2 3 4 5 6 7 8 9  PS C:\\Test\u0026gt; Get-ChildItem -File ディレクトリ: C:\\Test Mode LastWriteTime Length Name ---- ------------- ------ ---- -a---- 2020/07/18 10:07 11 aaa.txt -a---- 2020/07/18 10:07 8 bbb.txt -a---- 2020/07/18 10:08 30 ccc.txt   -Filterオプションでファイル名を絞り込み Get-ChildItemコマンドレットに-Filterオプションを付けて実行すると、フォルダ名・ファイル名を絞り込んだ結果が表示される。\n-Filterの後に文字列を追加すると、その文字列に一致したファイル名のみ表示される。文字列にはワイルドカード*を使用できる。\n例：拡張子がtxtのファイルのみ表示する\n1  PS C:\\Test\u0026gt; Get-ChildItem -Filter *.txt   まとめ 上記のオプションを組み合わせ、Get-ChildItem -Recurse -Name -Fileを実行すると、サブフォルダを含むファイル名を一覧表示される。\nファイル名で抽出する場合には-Filterオプションを追加すれば良い。\n参考 PowerShellのGet-ChildItemコマンドレットでファイル名の一覧を取得する（基本編）：Tech TIPS - ＠IT\nGet-ChildItemコマンドレットのその他のオプションについては、以下のリファレンスを参照。\nGet-ChildItem (Microsoft.PowerShell.Management) - PowerShell | Microsoft Docs\n","description":"PowerShellでGet-ChildItemコマンドレットを使ってサブフォルダを含むファイル名を一覧表示する方法を調べた。","id":11,"section":"posts","tags":["PowerShell"],"title":"PowerShellでサブフォルダにあるファイル名を一覧表示する","uri":"https://helve2017.github.io/posts/powershell/powershell-get-childitem/"},{"content":"はじめに C#ではstring型を使って文字列を扱うことができる。 本記事ではstringオブジェクトのプロパティとメソッド、および文字列と数値の変換についてまとめた。\n対象とする環境は以下の通り。\n Visual Studio Community 2019 (Version 16.6.2) C# Version 8.0  string型の基本 C#におけるstring型は、System.Stringクラスのエイリアス（別名）である。\nしたがって、下の2行のコードは等価である。\n1 2  string str = \u0026#34;hoge\u0026#34;; System.String str = \u0026#34;hoge\u0026#34;; // 上と等価   文字列の宣言 文字列型の変数は、ダブルクォーテーション\u0026quot;で囲んで宣言する。文字列には改行\\nのようなエスケープシーケンスを含めることができる。\n1 2  string str = \u0026#34;hoge\\npiyo\u0026#34; Console.WriteLine(str);   出力\n1 2  hoge piyo   また、記述したままの状態を文字列として扱いたい場合は、先頭に@を付けた逐語的文字列リテラルとする。\n例えば、ファイルパスなどのように\\を含む文字列に対して、通常の文字列ではエスケープシーケンスを使って\\を\\\\と記述する必要がある。\n一方、逐語的文字列リテラルでは、\\のままパスとして解釈される。\n1 2  string path1 = @\u0026#34;C:\\Users\\\\user\\Documents\u0026#34;; // 逐語的文字列リテラルを使う場合 string path2 = \u0026#34;C:\\\\Users\\\\user\\\\Documents\u0026#34;; // 逐語的文字列リテラルを使わない場合   string型のプロパティとメソッド string型のプロパティは以下の通り。\n   プロパティ 戻り値の型 説明     Length int 文字列の長さ    string型の主なメソッドは以下の通り。\n   プロパティ 戻り値の型 説明     CompareTo(string) int 文字列を比較   Contains(string) bool 文字列を含むか判定   Remove(int[, int]) string 指定した位置の文字を削除   Replace(string, string) string 指定した文字を置換   Split(string) string[] 指定した文字列で分割   ToLower() string 全て小文字にする   ToUpper() string 全て大文字にする   Trim() string 文字列の先頭と末尾の半角空白を削除   TrimStart() string 文字列の先頭の半角空白を削除   TrimEnd() string 文字列の末尾の半角空白を削除    CompareTo()メソッドとRemove()メソッドについて、以下で詳細を述べる。\n文字列の比較(CompareTo) strA.CompareTo(string strB)メソッドでは、strAとstrBをアルファベット順に比較して以下の結果を返す。\n   文字列の順序 CompareToの戻り値     strAがstrBより先に来る -1   strAとstrBが等しい 0   strAがstrBより後に来る 1    例\n1 2 3 4 5  string str = \u0026#34;abc\u0026#34;; Console.WriteLine(str.CompareTo(\u0026#34;b\u0026#34;)); // -1 Console.WriteLine(str.CompareTo(\u0026#34;abc\u0026#34;)); // 0 Console.WriteLine(str.CompareTo(\u0026#34;aaa\u0026#34;)); // 1 Console.WriteLine(str.CompareTo(\u0026#34;ABC\u0026#34;)); // -1   なお、大文字は小文字より先に来ると判定される。\n文字列の削除(Remove) Remove(int startIndex, int count)メソッドでは、startIndexで指定した位置からcountの数だけ文字を削除する。countを指定しない場合は、最後の文字まで削除する。\n1 2 3  string str = \u0026#34;hogepiyo\u0026#34;; Console.WriteLine(str.Remove(4)); // hoge Console.WriteLine(str.Remove(4, 2)); // hogeyo   文字列の結合 文字列を結合するには、以下の方法がある。\n +, +=演算子 String.Concat()メソッド String.Joint()メソッド  ただし、string型では一度作成したオブジェクトは変更することは出来ないため、文字列を結合すると、新たなstringオブジェクトが作成されることになる。\n何度も文字列の変更を繰り返す場合には、StringBuilderクラスを使った方が効率が良い。\n文字列と数値の変換 文字列を数値に変換する場合はParse()メソッドを用いる。\n1 2  int a = int.Parse(\u0026#34;123\u0026#34;); float b = float.Parse(\u0026#34;3.14\u0026#34;);   反対に、数値を文字列に変換する場合はToString()メソッドを用いる。文字列にするときの書式を指定することが可能。\n1 2 3 4 5  double x = 123.45; Console.WriteLine(x.ToString()); // 123.45 Console.WriteLine(x.ToString(\u0026#34;0000.0000\u0026#34;)); // 0123.4500（0埋め） Console.WriteLine(x.ToString(\u0026#34;F1\u0026#34;)); // 123.5（小数点以下1桁） Console.WriteLine(x.ToString(\u0026#34;E\u0026#34;)); // 1.234500E+002（指数表示）   参考 文字列 - C# プログラミング ガイド | Microsoft Docs\n","description":"C#ではstring型を使って文字列を扱うことができる。本記事ではstringオブジェクトのプロパティとメソッド、および文字列と数値の変換についてまとめた。","id":12,"section":"posts","tags":["Python","C Sharp"],"title":"C#のstring型で文字列を扱う","uri":"https://helve2017.github.io/posts/csharp/csharp-string/"},{"content":"はじめに 普段はPythonを使っているが、C#を勉強することになったので、 Pythonプログラマから見た相違点を備忘録として残す。\n比較した言語のバージョンは以下の通り。\n   言語 バージョン     Python 3.8.3   C# 8.0    なお、C#を勉強し始めて数週間程度なので、C#について理解が浅かったり、例外を知らない箇所もあるかと思います。記事に誤り等ありましたら、コメント欄にてご指摘ください。\nコーディング以外の違い 開発環境 Pythonの統合開発環境 (IDE) には、SpyderやPyCharm, Jupyter, Visual Studioなどがある。\n一方、C#はMicrosoftが言語の開発を行っているため、IDEはVisual Studioほぼ一択という状況である。2020年7月4日現在、Visual StudioにはWindows版とMac版が利用できる。\n最新のWindows版であるVisual Studio 2019には、Community, Professional, Enterpriseの3エディションがあり、個人利用であればCommunityを無償で利用できる。\nまた、Mac版にはエディションの違いはなく、無償で利用できる。\nプログラムの実行形式 Pythonはインタープリタ方式の言語であり、実行時はプログラムの先頭から1行ずつ読み込んで実行される。\n一方、C#はコンパイル方式の言語である。しかし、C/C++と異なり、C#はコンパイル時には中間言語と呼ばれるものに変換されるだけで、機械語には変換されない。中間言語が機械語に変換されるのは、プログラムを実行するタイミングである。\nまた、C#のプログラムは、エントリポイントと呼ばれる箇所から開始される。エントリポイントはMain()という名前で定義したメソッドになる。\n基本的な文法の違い 文末のセミコロンの有無 Pythonではプログラムの文の最後にセミコロン;は必須ではない（ただし、同じ行で複数の文を書く場合には、区切りを示すために必要）。\n一方、C#では文末にセミコロンが必須である。\nオフサイドルールがない Pythonではif文, for文や関数定義などの範囲をインデントを使って表現する（オフサイドルール）。\nC#ではインデントは可読性を上げる役割しかなく、波括弧{ }でif文などの範囲を定める。\nPythonの例：\n1 2  for i in range(10): （処理）   C#の例：\n1 2 3 4  for (int i; i \u0026lt; 10; i++) { （処理） }   オブジェクト指向 C#はPythonよりもオブジェクト指向の考え方が強い（と個人的に感じる）。\nPythonの場合、オブジェクト指向的なプログラミングを当然できるが、クラスを使わないプログラムを書くこともできる。\n一方、C#の場合、全ての変数と関数（メソッド）はクラスに属している必要があり、クラスを理解せずにプログラムを書くことは難しい（さらに、クラスは名前空間に属している必要がある）。\n例えば、文字を表示する場合、Pythonではprint関数を使うが、C#ではSystem.Console.WriteLineメソッドを使う。\nここで、Systemは名前空間、Consoleはクラス名、WriteLineがメソッド名になる。\n変数のスコープ Pythonでは、関数内で定義された変数はローカル変数となり、基本的に関数の外からアクセスすることは出来ない。\nC#では変数のスコープは{ }で囲まれた中である。したがって、\n1 2 3 4 5 6 7  static void Main(string[] args) { int a = 1; { Console.WriteLine($\u0026#34;{a}\u0026#34;); } }   は有効だが、以下はコンパイルエラーが出る。\n1 2 3 4 5 6 7  static void Main(string[] args) { { int b = 2; } Console.WriteLine($\u0026#34;{b}\u0026#34;); // {}の外ではbは有効ではない }   変数の型 変数型の宣言 Pythonでは変数の型を宣言する必要はない。\nC#では、全ての変数と、メソッドの戻り値の型を宣言する必要がある。整数型はint, 小数型はdoubleなどと変数の前に付ける。\nC#の例：\n1 2  int a = 3; double b = 4.2;   文字列 Pythonではstr型で文字列を扱う。\nC#でもほぼ同様のstring型がある。\nC#の例：\n1 2  string st = \u0026#34;abc\u0026#34;; Console.WriteLine(st.Length); // 文字列の長さ(3)を表示   ただし、Pythonではシングルクォーテーションとダブルクォーテーションのどちらで文字列を囲っても良かったが、C#では後者しか使えない。\nC#では、char型という1文字だけ格納する型にシングルクォーテーションを使うようになっており、string型と区別されている。\nリスト型・辞書型 Pythonでは数値や文字列を混在したリスト型変数、辞書型変数を作成できる。\n一方、C#では、1つのリスト型変数、辞書型変数に格納できる型は1種類だけである。\nまた、リストや辞書は、コレクションクラスと呼ばれている。リスト配列の使い方の例を以下に示す。\n1 2 3  List\u0026lt;int\u0026gt; a = new List\u0026lt;int\u0026gt;(); // 整数型のリストを作成 a.Add(1); // 要素を追加 int cnt = a.Count; // 要素数(1)を取得   Pythonではリストにスライスを使って、例えば5番目から10番目の要素を取得したり、要素を2つ飛ばしで取得するといったことができる。\n一方、C#にはスライスがなく、このような処理を簡単に記述することは難しい。\n制御文 Pythonではプログラムの流れを制御するための文としてif, for, whileがある。\nC#ではそれらに加えて、foreachとswitch文, doループがある。\n以下、両者の主な相違を述べる。\nfor文・foreach文 前述のように、Pythonではfor文は以下のように書ける。inの後ろにはイテラブル（繰り返し可能な）オブジェクトを置くと、forの後ろの変数に1つずつ要素が代入される。\n1 2  for i in range(10): （処理）   一方、C#のfor文にはforとforeachの2種類がある。for文は以下のように、カウンターとなる変数、繰り返す条件、1周ごとにカウンター変数に行う操作、をセミコロン;で区切って書く。\n1 2 3 4  for (int i; i \u0026lt; 10; i++) { （処理） }   一方、C#のforeach文は配列の要素を順に取り出すものであり、Pythonのfor文に近い使い方ができる。\n1 2 3 4 5  int[] a = {0, 1, 2, 3}; foreach (int i in a) { （処理） }   switch文・doループ switch文は変数の値によって、処理を分岐させるものである。処理が複数ある場合には、for文よりも可読性が高い。\ndoループはwhileループのように、繰り返し処理を行うものである。\n相違点は、whileループが内部処理の前にループの脱出判定を行うのに対して、doループでは内部処理の後にループの脱出判定を行うことである。すなわち、doループでは最低でも一度は処理が実施されることになる。\nその他 インクリメント演算子・デクリメント演算子 C#ではインクリメント演算子++, デクリメント演算子--を使用できる。\nC#の例：\n1 2  int a = 0; a++; // aを1だけ増加させる   論理演算子 Pythonでは、bool型 (True, False) に対する論理演算子としてand, or, notを使用する。\n一方、C#ではbool型をtrue, false（全て小文字）として、論理演算子に\u0026amp;, |, !を使用する。\n参考 以下の記事では、C#プログラマから見たPythonの特徴を扱っている。\nC#からPythonに乗りかえるための両者の比較 - Qiita\n","description":"普段はPythonを使っているが、C#を勉強することになったので、Pythonプログラマから見た相違点を備忘録として残す。","id":13,"section":"posts","tags":["Python","C Sharp"],"title":"Pythonプログラマから見たC#","uri":"https://helve2017.github.io/posts/csharp/python-to-csharp/"},{"content":"はじめに PyomoはPythonで書かれた最適化モデリングツールである。Pyomoの概要と基本的な使い方は以下の記事を参照。\nPyomoで線形計画問題を解く\nGDPは最適化問題の表現の1つであり、Generalized Disjunctive Programming の頭文字をとったものである。直訳すると一般化離接計画問題となる。離接とは論理和 (OR) のことである。\nGDPでは最適化問題における論理的な制約を表現できる。例えば、2つの等式制約があるが、どちらか片方のみ満たせば良い、という表現ができる。\n本記事では、Pyomoを使ったGDP問題の定義、およびGDPソルバの実行方法についてまとめた。GDPを解くときにはMINLPなどに変換するが、詳細については触れない。\nソフトウェアのバージョンは以下の通り。\n    バージョン     Python 3.7.4   Pyomo 5.6.9   glpk 4.65    環境の設定 Pyomoに拡張機能としてGDPのモデリング機能が実装されているので、Pyomoと適当なソルバを導入する。ここでは、pyomoと線形ソルバGLPKをインストールする。\nconda環境の場合は、次の通り。\nconda install -c conda-forge pyomo\rconda install -c conda-forge glpk\rpip環境の場合は、次の通り。\npip install pyomo\rpip install glpk\rGDPの基本形 GDPの基本的な式は、以下のように表記される。\n出展：\nhttps://www.gams.com/latest/docs/UG_EMP_DisjunctiveProgramming.html\n主な変数の意味は以下の通り。\n x: 変数 f(x): 目的関数 g(x): 不等式制約 Y: ブーリアン L: xの下限 U: xの上限 Ω(Y): Yの論理制約 r(x): 対応するYがTrueのときのみ有効な不等式制約 n: 変数の数 K: 論理和条件の数  また、記号Vは論理和を示す。\nGDPは、化学プラントなどの最適な装置の組み合わせを求めるのに用いられる。プラントの生成物などが変数、利益などが目的関数になる。また、装置によって生成物の上限やコストなどは異なるが、このような条件が制約条件になる。\nGDPの例 GDPの例を示す。2変数$x_1, x_2$に対して、目的関数$x_1+x_2$を最大化する問題を考える。実行可能領域は下図の斜線部とすると、$(x_1, x_2)=(10, 7)$で大域的最適解$ 17$をとる。\nこの問題をGDPで表すと、次式のようになる。\n$$ \\begin{array}{ll} \\text{maximize} \u0026amp; x_1 + x_2 \\\\ \\text{subject to} \u0026amp; \\begin{bmatrix} Y_{1} \\\\ 5x_1 + 4x_2 \\le 20 \\end{bmatrix} \\vee \\begin{bmatrix} Y_{2} \\\\ 2x_1 + x_2 \\ge 23 \\end{bmatrix} \\\\ \u0026amp; Y_1 \\rightarrow \\neg Y_2 \\\\ \u0026amp; Y_2 \\rightarrow \\neg Y_1 \\\\ \u0026amp; 0 \\le x_1 \\le 10, 0 \\le x_2 \\le 7, \\\\ \u0026amp; Y_{1}, Y_{2} \\in { \\text{True, False} } \\end{array} $$\nここで、￢は否定 (NOT) の意味である。上記の式では、Y1とY2の片方のみTrueになる。\nなお、GDPの disjuntive は論理和 (OR) を意味するが、Pyomoの公式リファレンスや関連する論文を読むと、排他的論理和 (XOR) の意味でも用いられることが多いように思う。\nPyomoでGDPを解く 上記の例をpyomoで実装すると、以下のようになる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import pyomo.environ as pe import pyomo.gdp as pg model = pe.ConcreteModel() model.x1 = pe.Var(domain=pe.Reals, bounds=(0, 10)) model.x2 = pe.Var(domain=pe.Reals, bounds=(0, 7)) model.Y1 = pg.Disjunct() model.Y1.c = pe.Constraint(expr = 5*model.x1+4*model.x2 \u0026lt;= 20) model.Y2 = pg.Disjunct() model.Y2.c = pe.Constraint(expr = 2*model.x1+model.x2 \u0026gt;= 23) model.c = pg.Disjunction(expr=[model.Y1, model.Y2]) model.OBJ = pe.Objective(expr=model.x1+model.x2, sense=pe.maximize) pe.SolverFactory(\u0026#39;gdpopt\u0026#39;).solve(model, mip_solver=\u0026#39;glpk\u0026#39;) print(f\u0026#34;評価関数：{model.OBJ()}\u0026#34;) print(f\u0026#34;x1: {model.x1()}\u0026#34;) print(f\u0026#34;x2: {model.x2()}\u0026#34;)   実行結果は以下のようになり、最適解を得られたことが分かる。\n1 2 3  評価関数：17.0 x1: 10.0 x2: 7.0   ソースコードの解説 GDPに関する部分のみ、ソースコードを簡単に解説する。\n1 2  model.Y1 = pg.Disjunct() model.Y1.c = pe.Constraint(expr = 5*model.x1+4*model.x2 \u0026lt;= 20)   Disjunctクラスは、ブーリアンに相当する。上記のコードでは、model.Y1がTrueの場合のみ、model.Y1.cで定義された制約条件が有効になる。\n1  model.c = pg.Disjunction(expr=[model.Y1, model.Y2])   Disjunctionクラスは、論理和の制約を示す。引数exprに渡した2つのDisjunctオブジェクトの内、どちらか片方のみTrueになることを示す。\n※公式リファレンスでは\u0026quot;logical OR\u0026quot;という表現だが、実際は排他的論理和 (XOR) のように振る舞う。\n1  pe.SolverFactory(\u0026#39;gdpopt\u0026#39;).solve(model, mip_solver=\u0026#39;glpk\u0026#39;)   ソルバにはGDPoptを指定する。ただし、GDPoptはGDPを変換するがMIPソルバを含んでいないので、GLPKを指定する。\n参考 PyomoにおけるGDPのクラスについて\nGeneralized Disjunctive Programming — Pyomo 5.7.2 documentation\nGDPoptソルバについて\nGDPopt logic-based solver — Pyomo 5.7.2 documentation\n","description":"PyomoでGDP (Generalized Disjunctive Programming) と呼ばれる最適化問題を解いた。GDPは論理的な制約を持つ最適化問題である。","id":14,"section":"posts","tags":["Pyomo","最適化"],"title":"PyomoでGDP最適化問題を解く","uri":"https://helve2017.github.io/posts/python/pyomo-gdp/"},{"content":"はじめに PyomoはPythonで書かれた最適化モデリングツールである。一般に、高速な最適化ソルバはC言語などで書かれており、 最適化問題をAMPLなどのフォーマットで記述する必要がある。 そのため、最適化モデリングツールを使って、（Pythonなど）他の言語で記述された問題を変換して最適化ソルバに渡す。\nまた、Couenneは非凸なMINLP問題を解くことができる最適化ソルバである（詳細は後述）。MINLPは混合整数非線形計画問題 (Mixed Integer Nonlinear Programming) の略である。PyomoからCouenneを呼び出して使用することができる。\n本記事では、Couenneの紹介、およびWindowsにおける導入方法、PyomoとCouenneを用いてMINLP問題を解く例を示す。\nまた、Pyomoは既に導入されているものとする。Pyomoの導入方法と基本的な使い方は以下の記事を参照。\nPyomoで線形計画問題を解く\n環境\n Windows 10 Home Couenne Ver. 0.3.2  Couenneの基本 Couenne (Convex Over and Under ENvelopes for Nonlinear Estimation) は、非凸なMINLPを解くことができるソルバである。Couenneには、spatial branch \u0026amp; bound（日本語訳は不明だが、空間分枝限定法？）と呼ばれる最適化手法が実装されている。\nなお、Couenneは同じCOIN-ORプロジェクトで開発された以下の最適化ソルバを間接的に呼び出して使用している。\n CBC: MILPソルバ CLP: LPソルバ（CBCから使用される） IPOPT: NLPソルバ  Coueeneの導入 Couenneを使用するには、以下の2つの方法がある。\n ネットから実行ファイルをダウンロードして使う ソースコードをビルドして使う  Windowsで2の方法を取るには、Cygwinを導入したり、BlasやLapackなどのライブラリを用意する必要があるなどハードルが高いので、ここでは1の方法を取る。\nまず、以下のページの\u0026quot;Couenne-0.3.2-win32-..\u0026gt;\u0026ldquo;からzipファイルをダウンロードする。\nhttps://www.coin-or.org/download/binary/Couenne/\nただし、2011年から実行ファイルの配布が止まっており、バージョン0.3.2までしか入手できない。最新のバージョンを利用する場合は、ソースコードをビルドする必要がある。\nダウンロードしたzipファイルを解凍すると、binフォルダの中にcouenne.exeがある。この実行ファイルには、Couenneが呼び出すライブラリが全て含まれている。\n次に、Pyomoからcouenne.exeを呼ぶためにパスを通す。具体的には以下のような方法がある。\n Windowsの環境変数のPathにcouenne.exeがあるフォルダを追加する Pythonのカレントディレクトリにcouenne.exeを置く  以上でPyomoからCouenneを使用する準備が整った。\nなお、binフォルダに含まれるbonmin.exe, cbc.exe, ipopt.exeも、couenne.exeと同様にパスを通せばPyomoから呼び出して使用することができる。\n非凸MINLPの例題 以下の2変数の非凸MINLPを考える。\n$$ \\begin{array}{ll} \\text{minimize} \u0026amp; 3 x_1^4 - 4 x_1^3 -12 x_1^2 + 3 x_2^4 - 4 x_2^3 -12 x_2^2 \\\\ \\text{subject to} \u0026amp; -5 \\le x_1 \\le 5, -5 \\le x_2 \\le 5 \\\\ \u0026amp; x_1, x_2 \\in \\mathbb{Z} \\end{array} $$\nここで、$\\mathbb{Z}$は整数の集合を表す。また、$x_1, x_2$が実数の場合の-2～3付近を拡大したグラフを示す。\n$(x_1, x_2)=(2, 2)$で大域的最適解$-64$を持つが、$(x_1, x_2)=(-1, -1), (-1, 2), (2, -1)$の3箇所で局所解を持つ非凸な問題である。\nPyomoのソースコード 上記の問題をPyomoとCouenneで解くためのコードは以下の通り。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  import pyomo.environ as pyo def ObjRule(m): return 3*m.x1**4-4*m.x1**3-12*m.x1**2 + 3*m.x2**4-4*m.x2**3-12*m.x2**2 model = pyo.ConcreteModel(name=\u0026#34;Nonconvex MINLP sample\u0026#34;) model.x1 = pyo.Var(domain=pyo.Integers, bounds=(-5, 5), initialize=-1) model.x2 = pyo.Var(domain=pyo.Integers, bounds=(-5, 5), initialize=-1) model.OBJ = pyo.Objective(rule = ObjRule, sense = pyo.minimize) opt = pyo.SolverFactory(\u0026#39;couenne\u0026#39;) res = opt.solve(model, tee=False) # tee=Trueとすればソルバーのメッセージが表示 print(f\u0026#34;評価関数：{model.OBJ()}\u0026#34;) print(f\u0026#34;x1: {model.x1()}\u0026#34;) print(f\u0026#34;x2: {model.x2()}\u0026#34;)   ここでは、変数の初期値をあえて局所解とした。\n実行結果\nコードを実行すると以下が表示され、大域的最適解が得られたことが分かる。\n1 2 3  評価関数：-64.0 x1: 2.0 x2: 2.0   参考文献 Couenneの開発元 (COIN-OR) のページ\nCouenne\nCouenneのオプションについて\nCouenneのユーザマニュアル(PDF)\n","description":"PyomoというPythonライブラリと、Couenneという最適化ソルバを使って非凸の混合整数非線形計画問題 (MINLP) を解く方法をまとめた。","id":15,"section":"posts","tags":["Pyomo","最適化"],"title":"PyomoとCouenneで非凸の混合整数非線形計画問題(MINLP)を解く","uri":"https://helve2017.github.io/posts/python/pyomo-couenne-nonconvex-minlp/"},{"content":"はじめに PyomoはPythonで書かれた最適化モデリングツールである。Pyomoの基本的な使い方と、線形計画問題の解き方については以下の記事を参照。\nPyomoで線形計画問題を解く\n本記事では、Pyomoを使って非線形計画問題を解く方法を示す。Pyomoには最適化ソルバが含まれていないため、IPOPT (Interior Point OPTimizer)という無償ソルバーを使う。IPOPTは主双対内点法を利用したソルバであり、大規模な非線形問題を高速に解くことができる。問題は連続である必要がある。また、大域的最適解を求めるには問題が凸である必要がある。\n環境は以下の通り。\n   ソフトウェア バージョン     Python 3.7.4   Pyomo 5.6.9   IPOPT 3.11.1    ソフトウェアのインストール PyomoとIPOPTをインストールする。conda環境の場合は以下を実行する。\nconda install -c conda-forge pyomo\rconda install -c conda-forge ipopt\rpip環境の場合は以下を実行する。\npip install pyomo\rpip install ipopt\r対象とする線形計画問題 以下の制約付き非線形最小化問題を考える。\n$$ \\begin{array}{ll} \\text{minimize} \\ \u0026amp; f(x_1, x_2) = x_1^2 + x_2^2 \\\\ \\text{subject to} \\ \u0026amp; x_1 x_2 \\ge 1 \\\\ \u0026amp; x_1 \\ge 0, x_2 \\ge 0 \\end{array} $$\n図示すると以下のようになり、$(x_1, x_2)=(1, 1)$で最小値$ 2$をとる。青色で図示した領域は実行可能領域を示す。\nPyomoのソースコード 上記の問題をPyomoを使って記述し、最適化を実行したコードは以下のようになる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import pyomo.environ as pyo model = pyo.ConcreteModel(name=\u0026#34;NLP sample\u0026#34;, doc=\u0026#34;2 variables, 1 constraints\u0026#34;) model.x = pyo.Var([1,2], domain=pyo.NonNegativeReals) # 変数を定義 model.OBJ = pyo.Objective(expr = model.x[1]**2 + model.x[2]**2, sense = pyo.minimize) # 目的関数を定義 model.Constraint = pyo.Constraint(expr = model.x[1] * model.x[2] \u0026gt;= 1) # 制約条件を定義 opt = pyo.SolverFactory(\u0026#39;ipopt\u0026#39;) # 最適化ソルバを設定 res = opt.solve(model) # 最適化計算を実行 print(f\u0026#34;評価関数：{model.OBJ()}\u0026#34;) print(f\u0026#34;x1: {model.x[1]()}\u0026#34;) print(f\u0026#34;x2: {model.x[2]()}\u0026#34;)   実行結果は以下のようになり、最適値を得られている。\n1 2 3  評価関数：1.9999999825046202 x1: 0.999999995626155 x2: 0.999999995626155   ソースコードの解説 以下、ソースコードの詳細を述べる。\n問題のオブジェクトの作成 まず、ConcreteModelクラスを用いて問題のオブジェクトを作成する。\n1 2  model = pyo.ConcreteModel(name=\u0026#34;NLP sample\u0026#34;, doc=\u0026#34;2 variables, 1 constraints\u0026#34;)   pyomoでは問題を定義するためのクラスには、次の2種類があるが、ここではConcreteModelを用いた。\n ConcreteModel: 具体的なパラメータを定義しながら作成する AbstractModel: パラメータは後で設定する  また、name, docという引数では、それぞれモデルの名前と説明を文字列 (str) で設定している。これらの値を取得するには、オブジェクトのname, docメンバ変数を呼ぶ。\n例：\n1 2  \u0026gt;\u0026gt;\u0026gt; model.name \u0026#39;NLP sample\u0026#39;   勿論、ConcreteModelクラスは引数を与える必要はなく、単に以下のようにしても最適化の結果には影響しない。\n1  model = pyo.ConcreteModel()   変数の定義 次に、Varクラスを用いて変数を定義する。\n1  model.x = pyo.Var([1,2], domain=pyo.NonNegativeReals) # 変数を定義   modelにxといった適当なメンバ変数を作り、Varクラスのオブジェクトを定義する。\nVarクラスの第1引数に数値のリストを割り当てることで、xはそのリストと同じ長さのベクトルになる。\nまた、Varクラスの引数domainは変数の種類を表す。Pyomoで定義可能なdomainの一部を以下に示す。\n Reals PositiveReals NonPositiveReals NegativeReals NonNegativeReals Integers PositiveIntegers NonPositiveIntegers  また、Varクラスの引数boundsとinitializeでそれぞれ変数の範囲と初期値を定義できる。\n例：\n1 2  pyo.Var([1,2], domain=pyo.NonNegativeReals, bounds=(3, 6), initialize=5)   目的関数の定義 次に、Objectiveクラスを用いて、目的関数を定義する。\n1 2  model.OBJ = pyo.Objective(expr = model.x[1]**2 + model.x[2]**2, sense = pyo.minimize) # 目的関数を定義   先ほど定義した変数xを用いて、exprに目的関数を記述する。\nまた、senseで最小化問題(minimize)か最大化問題(maximize)かを定義する（初期値はminimize）。\n目的関数を定義する方法として、以下のように関数を定義して、ruleに渡す方法もある。\n1 2 3 4 5  def ObjRule(model): return model.x[1]**2 + model.x[2]**2 model.OBJ = pyo.Objective(rule = ObjRule, sense = pyo.minimize)   なお、ConcreteModelではexprを使う方法とruleを使う方法のどちらも使えるが、AbstractModelではruleを使う方法しか使えない。\n制約条件の定義 Constraintクラスで制約条件を設定する。\n1 2  model.Constraint = pyo.Constraint(expr = model.x[1] * model.x[2] \u0026gt;= 1) # 制約条件を定義   等式制約は==で、不等式制約は\u0026lt;=, \u0026gt;=でそれぞれ設定する。\nObjectiveクラスの場合と同様に、exprの代わりに、ruleと関数で制約条件を定義することができる。\n例：\n1 2 3 4  def ConstRule(model): return model.x[1] * model.x[2] \u0026gt;= 1 model.Constraint1 = pyo.Constraint(rule = ConstRule)   ソルバの指定と最適化 最後に、ソルバを指定して最適化を行う。\n1 2  opt = pyo.SolverFactory(\u0026#39;ipopt\u0026#39;) res = opt.solve(model)   SolverFactoryでソルバを指定する。ここではIPOPTを用いる。次に、SolverFactoryオブジェクトのsolveメソッドにmodelを指定して実行すると、最適化が行われる。resには最適化の結果が格納される。\nまた、solveでtee=Trueとすると、ソルバの出力が表示される。\n1  res = opt.solve(model, tee=True)   最適化ソルバのオプション設定 最適化ソルバ（ここではIPOPT）にオプションを設定するためには、最適化計算の前に、SolverFactoryオブジェクトのoptions変数に辞書形式で渡す。\n例：\n1 2 3 4 5  opt = pyo.SolverFactory(\u0026#39;ipopt\u0026#39;) opt.options = {\u0026#34;print_level\u0026#34; : 4, \u0026#34;tol\u0026#34; : 1E-3} res = opt.solve(model, tee=True)   もしくは、以下のようにしてもよい。\n1 2 3 4 5  opt = pyo.SolverFactory(\u0026#39;ipopt\u0026#39;) opt.options[\u0026#34;print_level\u0026#34;] = 4 opt.options[\u0026#34;tol\u0026#34;] = 1E-3 res = opt.solve(model, tee=True)   上記の例では、\n 最適化計算のログ出力の詳細度合い (print_level) を4（0～12の範囲。数字が大きいほど詳細になる） 最適解の許容誤差 (tol) を1E-3  と設定している。\nIPOPTで設定可能なオプションについては、以下のページを参照。\nIpopt: Ipopt Options\n一覧の形式で確認したい場合には、以下のページを参照。\nhttps://www.coin-or.org/Bonmin/option_pages/options_list_ipopt.html\n最適化結果の評価 最適化後の変数や目的関数の値を取得するには、modelの変数に直接アクセスする。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; model.OBJ() 1.9999999825046202 \u0026gt;\u0026gt;\u0026gt; model.x[1]() 0.999999995626155 \u0026gt;\u0026gt;\u0026gt; model.x[2]() 0.999999995626155   最適化問題の概要を表示するには、model.display(), model.pprint()などを実行する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026gt;\u0026gt;\u0026gt; print(model.display()) Model NLP sample Variables: x : Size=2, Index=x_index Key : Lower : Value : Upper : Fixed : Stale : Domain 1 : 0 : 0.999999995626155 : None : False : False : NonNegativeReals 2 : 0 : 0.999999995626155 : None : False : False : NonNegativeReals Objectives: OBJ : Size=1, Index=None, Active=True Key : Active : Value None : True : 1.9999999825046202 Constraints: Constraint1 : Size=1 Key : Lower : Body : Upper None : 1.0 : 0.9999999912523101 : None None   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  \u0026gt;\u0026gt;\u0026gt; print(model.pprint()) 2 variables, 1 constraints 1 Set Declarations x_index : Dim=0, Dimen=1, Size=2, Domain=None, Ordered=False, Bounds=(1, 2) [1, 2] 1 Var Declarations x : Size=2, Index=x_index Key : Lower : Value : Upper : Fixed : Stale : Domain 1 : 0 : 0.999999995626155 : None : False : False : NonNegativeReals 2 : 0 : 0.999999995626155 : None : False : False : NonNegativeReals 1 Objective Declarations OBJ : Size=1, Index=None, Active=True Key : Active : Sense : Expression None : True : minimize : x[1]**2 + x[2]**2 1 Constraint Declarations Constraint1 : Size=1, Index=None, Active=True Key : Lower : Body : Upper : Active None : 1.0 : x[1]*x[2] : +Inf : True 4 Declarations: x_index x OBJ Constraint1 None   最適化の結果を表示するには、opt.solve()の戻り値をprintで表示する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026gt;\u0026gt;\u0026gt; print(res) Problem: - Lower bound: -inf Upper bound: inf Number of objectives: 1 Number of constraints: 1 Number of variables: 2 Sense: unknown Solver: - Status: ok Message: Ipopt 3.11.1\\x3a Optimal Solution Found Termination condition: optimal Id: 0 Error rc: 0 Time: 0.35607051849365234 Solution: - number of solutions: 0 number of solutions displayed: 0   参考 Pyomoで線形計画問題を解く\nIPOPTに利用されている主双対内点法の概要。\n非線形計画問題の主双対内点法\nPyomoの公式リファレンス\nPyomo Documentation 5.7.2 — Pyomo 5.7.2 documentation\nIPOPTのドキュメント\nIpopt: Documentation\nPythonで使える最適化ツールの比較(Pyomo, PuLPなど）。\nソルバの導入についても紹介されている。\nPython + Pyomoによる(非線形)数値最適化 - Easy to type\n","description":"最適化モデリングツールPyomoと、最適化ソルバIPOPTを使って非線形計画問題を解く方法をまとめた。","id":16,"section":"posts","tags":["Pyomo","最適化"],"title":"PyomoとIPOPTで非線形計画問題を解く","uri":"https://helve2017.github.io/posts/python/pyomo-nonlinear-programming/"},{"content":"はじめに PyomoというPythonライブラリを使って線形計画問題を解く方法をまとめた。\n本記事では、Pyomoの導入方法と、問題の記述方法について示す。\nPyomoはPythonで書かれた最適化モデリングツールである。\n一般に、高速な最適化ソルバはC言語などで書かれており、最適化問題をAMPLなどのフォーマットで記述する必要がある。最適化モデリングツールは、（Pythonなど）他の言語で記述された問題を変換して最適化ソルバに渡すためのツールである。\n本記事では、Pyomoを使って簡単な線形計画問題を解く方法を示す。なお、ソルバはGLPK (GNU Linear Programming Kit) という無償ソルバを使う。\n環境は以下の通り。\n    バージョン     Python 3.7.4   Pyomo 5.6.9   GLPK 4.65    ライブラリのインストール Pyomoと最適化ソルバGLPKをインストールする。Pyomoにはソルバが含まれていないので、別途インストールする必要がある。\nconda環境の場合は次の通り。\nconda install -c conda-forge pyomo\rconda install -c conda-forge glpk\rpip環境の場合は次の通り。\npip install pyomo\rpip install glpk\rなお、GLPKは線形計画問題 (LP, Linear Programming) と混合整数問題 (MIP, Mixed Integer Programming)を解くためのライブラリである。\nGLPKには、以下のようなアルゴリズムが実装されている。\n 単体法・双対単体法 (primal and dual simplex method) 主双対内点法 (primal-dual interior-point method) 分枝限定法 (branch-and-cut method)  本来、GLPKで数理計画問題を解く場合には、GNU MathProgという言語で記述する必要がある。しかし、Pyomoを使うことで、Python上で問題を記述してGLPKに渡すことができる。\n対象とする線形計画問題 以下の最小化問題を考える。\n$ \\begin{array}{ll} \\text{minimize} \u0026amp; -5x_1-4x_2 \\\\ \\text{subject to} \u0026amp; 5x_1+2x_2 \\le 30 \\\\ \u0026amp; x_1 + 2x_2 \\le 14 \\\\ \u0026amp; x_1 \\ge 0, x_2 \\ge 0 \\end{array} $\n図示すると以下のようになり、$(x_1, x_2)=(4, 5)$で最小値$ -40$をとる。\nPyomoのソースコード 上記の線形計画問題をPyomoを使って記述し、最適化を実行したコードは以下のようになる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  import pyomo.environ as pyo model = pyo.ConcreteModel(name=\u0026#34;LP sample\u0026#34;, doc=\u0026#34;2 variables, 2 constraints\u0026#34;) model.x1 = pyo.Var(domain=pyo.NonNegativeReals) model.x2 = pyo.Var(domain=pyo.NonNegativeReals) model.OBJ = pyo.Objective(expr = -5*model.x1 -4*model.x2, sense = pyo.minimize) model.Constraint1 = pyo.Constraint(expr = 5*model.x1 + 2*model.x2 \u0026lt;= 30) model.Constraint2 = pyo.Constraint(expr = model.x1 + 2*model.x2 \u0026lt;= 14) opt = pyo.SolverFactory(\u0026#39;glpk\u0026#39;) res = opt.solve(model) print(f\u0026#34;評価関数：{model.OBJ()}\u0026#34;) print(f\u0026#34;x1: {model.x1()}\u0026#34;) print(f\u0026#34;x2: {model.x2()}\u0026#34;)   実行結果は以下のようになり、最適値を得られている。\n1 2 3  評価関数：-40.0 x1: 4.0 x2: 5.0   ソースコードの解説 以下、ソースコードの詳細を述べる。\n問題のオブジェクトの作成 まず、ConcreteModelクラスを用いて問題のオブジェクトを作成する。\n1 2  model = pyo.ConcreteModel(name=\u0026#34;LP sample\u0026#34;, doc=\u0026#34;2 variables, 2 constraints\u0026#34;)   pyomoでは問題を定義するためのクラスには、次の2種類がある。\n ConcreteModel: 具体的なパラメータを定義しながら作成する AbstractModel: パラメータは後で設定する  ここではConcreteModelを用いた。\nまた、name, docという引数では、それぞれモデルの名前と説明を文字列 (str) で設定している。これらの値を取得するには、オブジェクトのname, docメンバ変数を呼ぶ。\n例：\n1 2  \u0026gt;\u0026gt;\u0026gt; model.name \u0026#39;LP sample\u0026#39;   勿論、name, docは設定する必要はなく、以下のようにしても良い。\n1  model = pyo.ConcreteModel()   変数の定義 次に、Varクラスを用いて変数を定義する。\n1 2  model.x1 = pyo.Var(domain=pyo.NonNegativeReals) model.x2 = pyo.Var(domain=pyo.NonNegativeReals)   modelにx1, x2といった適当な変数を作り、Varクラスのオブジェクトとする。\nVarクラスの引数domainは変数の種類を表す。Pyomoで定義可能なdomainの一部を以下に示す。\n Reals PositiveReals NonPositiveReals NegativeReals NonNegativeReals Integers PositiveIntegers NonPositiveIntegers  また、Varクラスの引数boundsとinitializeでそれぞれ変数の範囲と初期値を定義できる。\n例：\n1 2  pyo.Var(domain=pyo.NonNegativeReals, bounds=(3, 6), initialize=5)   目的関数の定義 次に、Objectiveクラスを用いて目的関数を定義する。\n1 2  model.OBJ = pyo.Objective(expr = -5*model.x1 -4*model.x2, sense = pyo.minimize)   先ほど定義した変数x1, x2を用いて、exprに目的関数を記述する。\nまた、senseで最小化問題(minimize)か最大化問題(maximize)かを定義する（初期値はminimize）。\n目的関数を定義する方法として、以下のように関数を定義してruleに渡す方法もある。\n1 2 3 4 5  def ObjRule(model): return -5*model.x1 -4*model.x2 model.OBJ = pyo.Objective(rule = ObjRule, sense = pyo.minimize)   なお、ConcreteModelではexprとruleのどちらも使えるが、AbstractModelではruleしか使えない。\n制約条件の定義 Constraintクラスで制約条件を設定する。\n1 2  model.Constraint1 = pyo.Constraint(expr = 5*model.x1 + 2*model.x2 \u0026lt;= 30) model.Constraint2 = pyo.Constraint(expr = model.x1 + 2*model.x2 \u0026lt;= 14)   等式制約は==で、不等式制約は\u0026lt;=, \u0026gt;=でそれぞれ設定する。\n目的関数と同様に、exprの代わりにruleと関数で制約条件を定義できる。\n例：\n1 2 3 4  def ConstRule1(model): return 5*model.x1 + 2*model.x2 \u0026lt;= 30 model.Constraint1 = pyo.Constraint(rule = ConstRule1)   ソルバの指定と最適化 最後に、ソルバを指定して最適化を行う。\n1 2  opt = pyo.SolverFactory(\u0026#39;glpk\u0026#39;) res = opt.solve(model)   SolverFactoryでソルバを指定し、solveメソッドで最適化を行う。resには最適化の結果が格納される。\nまた、solveでtee=Trueとすると、ソルバの出力が表示される。\n1  res = opt.solve(model, tee=True)   最適化結果の評価 最適化後の変数や目的関数の値を取得するには、modelの変数に直接アクセスする。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; model.OBJ() -40.0 \u0026gt;\u0026gt;\u0026gt; model.x1() 4.0 \u0026gt;\u0026gt;\u0026gt; model.x2() 5.0   最適化問題の概要を表示するには、model.display(), model.pprint()などを実行する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026gt;\u0026gt;\u0026gt; print(model.display()) Model LP sample Variables: x1 : Size=1, Index=None Key : Lower : Value : Upper : Fixed : Stale : Domain None : 0 : 4.0 : None : False : False : NonNegativeReals x2 : Size=1, Index=None Key : Lower : Value : Upper : Fixed : Stale : Domain None : 0 : 5.0 : None : False : False : NonNegativeReals Objectives: OBJ : Size=1, Index=None, Active=True Key : Active : Value None : True : -40.0 Constraints: Constraint2 : Size=1 Key : Lower : Body : Upper None : None : 14.0 : 14.0 Constraint1 : Size=1 Key : Lower : Body : Upper None : None : 30.0 : 30.0 None   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026gt;\u0026gt;\u0026gt; print(model.pprint()) 2 variables, 2 constraints 2 Var Declarations x1 : Size=1, Index=None Key : Lower : Value : Upper : Fixed : Stale : Domain None : 0 : 4.0 : None : False : False : NonNegativeReals x2 : Size=1, Index=None Key : Lower : Value : Upper : Fixed : Stale : Domain None : 0 : 5.0 : None : False : False : NonNegativeReals 1 Objective Declarations OBJ : Size=1, Index=None, Active=True Key : Active : Sense : Expression None : True : minimize : -5*x1 - 4*x2 2 Constraint Declarations Constraint1 : Size=1, Index=None, Active=True Key : Lower : Body : Upper : Active None : -Inf : 5*x1 + 2*x2 : 30.0 : True Constraint2 : Size=1, Index=None, Active=True Key : Lower : Body : Upper : Active None : -Inf : x1 + 2*x2 : 14.0 : True 5 Declarations: x1 x2 OBJ Constraint2 Constraint1 None   ソルバの結果を表示するには、opt.solve()の戻り値をprintで表示する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026gt;\u0026gt;\u0026gt; print(res) Problem: - Name: unknown Lower bound: -40.0 Upper bound: -40.0 Number of objectives: 1 Number of constraints: 3 Number of variables: 3 Number of nonzeros: 5 Sense: minimize Solver: - Status: ok Termination condition: optimal Statistics: Branch and bound: Number of bounded subproblems: 0 Number of created subproblems: 0 Error rc: 0 Time: 0.17183566093444824 Solution: - number of solutions: 0 number of solutions displayed: 0   参考 Pyomoの公式リファレンス\nPyomo Documentation 5.6.9 — Pyomo 5.6.9 documentation\nGLPKについて\nGLPK - GNU Project - Free Software Foundation (FSF)\n参考にさせていただいた日本語の記事\nPythonで線形計画問題を解く即戦力コード with Pyomo – Takala\u0026rsquo;s Memory\nPython + Pyomoによる(非線形)数値最適化 - Easy to type\n","description":"PyomoというPythonライブラリを使って線形計画問題を解く方法をまとめた。本記事では、Pyomoの導入方法と、問題の記述方法について示す。","id":17,"section":"posts","tags":["Pyomo","最適化"],"title":"Pyomoで線形計画問題を解く","uri":"https://helve2017.github.io/posts/python/pyomo-linear-programming/"},{"content":"はじめに PandasのTimestampクラスでタイムゾーンを扱う方法をまとめた。Timestampオブジェクトにタイムゾーンを設定する方法や、異なるタイムゾーンに変換する方法について述べる。\nTimestampクラスの基本については以下の記事を参照。\nPandasのTimestampで時刻を扱う\n以降では、ライブラリを以下のようにインストールしていることを前提とする。なお、pytzはタイムゾーンを扱うライブラリである。\n1 2  import pandas as pd import pytz   また、環境は以下の通り。\n    バージョン     Python 3.7.4   Pandas 0.25.1   pytz 2019.3    Timestampクラスのタイムゾーン Timestampクラスのオブジェクトは、タイムゾーンの情報を持っていない状態と、持っている状態を取り得る。Pandasのリファレンスでは、前者をtz-native, 後者をtz-awareと呼ぶ。\n両社の違いを以下に示す。\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;2020/03/14\u0026#34;) # タイムゾーン情報を持たない場合 Timestamp(\u0026#39;2020-03-14 00:00:00\u0026#39;) \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;2020/03/14\u0026#34;, tz=\u0026#34;Asia/Tokyo\u0026#34;) # タイムゾーン情報を持つ場合 Timestamp(\u0026#39;2020-03-14 00:00:00+0900\u0026#39;, tz=\u0026#39;Asia/Tokyo\u0026#39;)   タイムゾーンを持ったTimestampオブジェクトの作成 タイムゾーンを持ったTimestampオブジェクトの作成する方法はいくつかあるが、ここでは以下の2つを扱う。\n pd.Timestampのtz引数に文字列でタイムゾーンを渡す。 pd.Timestampのtz引数にpytz.timezoneオブジェクトを渡す。  文字列で設定する場合 pd.Timestampのtz引数にタイムゾーンを表す文字列を与えると、タイムゾーンを持つオブジェクトを作成できる。\n1 2  \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;2020/03/14\u0026#34;, tz=\u0026#34;Asia/Tokyo\u0026#34;) Timestamp(\u0026#39;2020-03-14 00:00:00+0900\u0026#39;, tz=\u0026#39;Asia/Tokyo\u0026#39;)   指定可能なタイムゾーン文字列はpytz.all_timezonesで確認できる。\nタイムゾーンの例を以下に示す。都市名や国名、または一般に良く使われる略称があてはめられている。\n   文字列 UTCとの時差 備考     \u0026lsquo;America/New_York\u0026rsquo; -5 ニューヨーク   Asia/Tokyo' +9 東京   \u0026lsquo;EST\u0026rsquo; -5 米国東部時間   \u0026lsquo;Europe/Berlin\u0026rsquo; +1* ベルリン   \u0026lsquo;Japan\u0026rsquo; +9 日本   \u0026lsquo;UCT\u0026rsquo; 0 世界標準時    * 夏時間の場合は+2\npytz.timezoneオブジェクトで設定する場合 pytz.timezoneにタイムゾーンを表す文字列を与え、さらにpd.Timestampのtz引数に与えると、タイムゾーンを持つオブジェクトを作成できる。\n1 2 3  \u0026gt;\u0026gt;\u0026gt; jst = pytz.timezone(\u0026#34;Asia/Tokyo\u0026#34;) \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;2020/03/14\u0026#34;, tz=jst) Timestamp(\u0026#39;2020-03-14 00:00:00+0900\u0026#39;, tz=\u0026#39;Asia/Tokyo\u0026#39;)   タイムゾーンを持った現在時刻を取得 タイムゾーンを持つ現在時刻を取得する場合は、pd.Timestamp.now()のtz引数にタイムゾーン情報を渡す。\n1 2  \u0026gt;\u0026gt;\u0026gt; pd.Timestamp.now(tz=\u0026#34;UTC\u0026#34;) Timestamp(\u0026#39;2020-03-14 05:22:50.800153+0000\u0026#39;, tz=\u0026#39;UTC\u0026#39;)   タイムゾーン情報の取得 Timestampオブジェクトのtzinfo属性からpytz.timezoneオブジェクトを取得できる。さらに、pytz.timezoneオブジェクトのzone属性からタイムゾーン文字列を取得できる。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; t = pd.Timestamp(\u0026#34;2020/03/14\u0026#34;, tz=\u0026#34;Asia/Tokyo\u0026#34;) \u0026gt;\u0026gt;\u0026gt; t.tzinfo \u0026lt;DstTzInfo \u0026#39;Asia/Tokyo\u0026#39; JST+9:00:00 STD\u0026gt; \u0026gt;\u0026gt;\u0026gt; t.tzinfo.zone \u0026#39;Asia/Tokyo\u0026#39;   タイムゾーンの変換 タイムゾーンがあるTimestampオブジェクトを異なるタイムゾーンに変換するには、tz_convertメソッドを用いる。tz_convertの引数は文字列でもpytz.timezoneオブジェクトでも良い。\n1 2 3  \u0026gt;\u0026gt;\u0026gt; t = pd.Timestamp(\u0026#34;2020/03/14\u0026#34;, tz=\u0026#34;Asia/Tokyo\u0026#34;) \u0026gt;\u0026gt;\u0026gt; t.tz_convert(\u0026#34;UTC\u0026#34;) Timestamp(\u0026#39;2020-03-13 15:00:00+0000\u0026#39;, tz=\u0026#39;UTC\u0026#39;)   タイムゾーンがあるTimestampオブジェクトからタイムゾーン情報を削除する場合、2つの方法がある。UCT時刻に変換してからタイムゾーンを削除するには、tz_convertメソッドの引数にNoneを与える。また、現地時刻のままタイムゾーンを削除するには、tz_localizeメソッドの引数にNoneを与える。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; t = pd.Timestamp(\u0026#34;2020/03/14\u0026#34;, tz=\u0026#34;Asia/Tokyo\u0026#34;) \u0026gt;\u0026gt;\u0026gt; t.tz_convert(None) Timestamp(\u0026#39;2020-03-13 15:00:00\u0026#39;) \u0026gt;\u0026gt;\u0026gt; t.tz_localize(None) Timestamp(\u0026#39;2020-03-14 00:00:00\u0026#39;)   タイムゾーンがないTimestampオブジェクトにタイムゾーンを設定するには、tz_localizeメソッドを用いる。tz_localizeの引数は文字列でもpytz.timezoneオブジェクトでも良い。\n1 2 3  \u0026gt;\u0026gt;\u0026gt; t = pd.Timestamp(\u0026#34;2020/03/14\u0026#34;) \u0026gt;\u0026gt;\u0026gt; t.tz_localize(\u0026#34;Asia/Tokyo\u0026#34;) Timestamp(\u0026#39;2020-03-14 00:00:00+0900\u0026#39;, tz=\u0026#39;Asia/Tokyo\u0026#39;)   以上の変換をまとめると、以下の表となる。\n   変換前/変換後 tzあり tzなし     tzあり tz_convert tz_convert/tz_localize   tzなし tz_localize -    参考 pandas.Timestamp — pandas 1.2.0 documentation\n","description":"PandasのTimestampオブジェクトにタイムゾーンを設定する方法や、異なるタイムゾーンに変換する方法について述べる。","id":18,"section":"posts","tags":["Python","Pandas"],"title":"PandasのTimestampでタイムゾーンを扱う","uri":"https://helve2017.github.io/posts/python/pandas-timestamp-timezone/"},{"content":"はじめに 本記事では、Atomを使って以下の技術文書をmarkdownで書くための環境設定方法を示す。\n 数式を記述できる 図、表に自動で番号を振る A4縦長の用紙に印刷する  一方、以下の機能は対象としない。\n 引用文献の管理 文章中から図、表に対して自動でリンクを張る 数式に自動で番号を振る  また、Atomではmarkdown文書のHTML出力までしか出来ない。\nそのため、PDFが必要であれば、Chromeなどの適当なブラウザで変換する。\n環境 本記事で検証したライブラリのバージョンは以下の通り。ただし、下3つは必須ではない。\n    バージョン 備考     Atom 1.45.0    markdown-preview-plus 3.11.5 markdownのプレビューを表示   markdown-toc 0.4.2 目次を自動生成   document-outline 2.1.2 アウトラインを表示   japanese-menu 1.15.0 Atomを日本語化    また、OSはWindows10である。\nAtomの環境準備 必要なパッケージのインストールと設定を行う。\nAtomには、標準でmarkdownをプレビューするためのパッケージmarkdown-previewがあるが、数式を表示できないためmarkdown-preview-plusをインストールする。なお、markdown-preview-plusを入れると、markdown-previewが自動で無効になる。\nまた、markdown-tocというパッケージを入れると、目次を自動で生成できる。\nさらに、document-outlineというパッケージでは、markdownのアウトラインが表示されて便利である。\n次に、markdownをHTML表示するときの体裁を整える。「ファイル」→「スタイルシート」を押すと、style.lessというファイルが開くので、それに以下を追加する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  // for markdown-preview-plus body{ counter-reset: figcnt; counter-reset: tablecnt; h1, h2, h3, h4, h5 { font-weight: normal; border-bottom-style: hidden !important; } h1 { text-align: center; counter-reset: h2cnt; } h2 { font-size: 25px; margin: 50px auto 25px; counter-reset: h3cnt; } h3 { font-size: 18px; margin-bottom: 10px; counter-reset: h4cnt; } h2::before { counter-increment: h2cnt; content: counter(h2cnt) \u0026#34;. \u0026#34;; } h3::before { counter-increment: h3cnt; content: counter(h2cnt) \u0026#34;-\u0026#34; counter(h3cnt) \u0026#34;. \u0026#34;; } h4::before { counter-increment: h4cnt; content: counter(h2cnt) \u0026#34;-\u0026#34; counter(h3cnt) \u0026#34;-\u0026#34; counter(h4cnt) \u0026#34;. \u0026#34;; } p { margin-bottom: 0em !important; // 段落後の空白をなくす \u0026amp;.figtitle::before { counter-increment: figcnt; content: \u0026#34;図\u0026#34; counter(figcnt) \u0026#34; \u0026#34;; } \u0026amp;.tabletitle::before { counter-increment: tablecnt; content: \u0026#34;表\u0026#34; counter(figcnt) \u0026#34; \u0026#34;; } } hr { margin: 50px 0; background-color: transparent; \u0026amp;:after{ content: \u0026#34;\u0026#34;; display: block; /* border-top-style: ridge; */ } \u0026amp;.pb { // \u0026lt;hr class=\u0026#34;pb\u0026#34;\u0026gt;を入れる事で、 // プリント時の改ページを指定することができる。 page-break-after: always; \u0026amp;:after { display: none; } } } // テキストの中央揃え .center { text-align: center; \u0026amp;:extend(.margin-clear); } }   スタイルシートの作成には以下を参考にさせていただいた。\nCSSで見出し要素(h1, h2\u0026hellip;)の前に自動で採番する方法 - Qiita\nAtomエディタのMarkdown PreviewのCSSを実務書類的に調整する | 大石制作ブログ\nなお、style.lessはCSSを定義するファイルである（厳密には、LESSと呼ばれるCSSを拡張した言語）。CSSはHTMLのデザインやレイアウトを整えるものである。後ほど、作成したmarkdownをHTML出力するときに、同じHTMLファイル内にstyle.lessで定義したレイアウトが一緒に出力される。\nmarkdownで文書を書く 出力される文書のイメージは以下の通り。段落の後の空白行をなくしている。\n以下のルールでmarkdownを書く\n 文書のタイトルは#1つとする 以下、章は##, 節は###, \u0026hellip;となる。 中央揃えの文は\u0026lt;p class=\u0026quot;center\u0026quot;\u0026gt;hoge\u0026lt;/p\u0026gt;のように書く 図のタイトルは\u0026lt;p class=\u0026quot;figtitle\u0026quot;\u0026gt;piyo\u0026lt;/p\u0026gt;のように書くと、順に番号が付与される 表のタイトルは\u0026lt;p class=\u0026quot;tabletitle\u0026quot;\u0026gt;piyo\u0026lt;/p\u0026gt;のように書くと、順に番号が付与される  その他、数式や図、表、リンクの挿入は、markdownの通常の記法に従う。\nまた、プレビューを表示するためには、「パッケージ」→「Markdown Preview Plus」→「Toggle Preview」を選択する。または、Ctrl+Shift+Mを押す（他のパッケージのショートカットと競合していない場合）。\n目次を自動生成するには、「パッケージ」→「markdown-toc」→「Toggle」を選択する。ただし、章番号は表示されないことに注意。\nさらに、文書中のソースコードのシンタックスハイライトは、以下のいずれかから設定できる。\n 「パッケージ」→「Markdown Preview Plus」→「Select preview syntax theme」をクリック プレビュー上で右クリックし、「Change syntax theme」をクリック。  文書中のソースコードのフォントは、Atomの設定が引き継がれる。Atomのフォントは、「設定」→「エディタ設定」でfont-familyとして、デフォルトでは以下のようになっている。\nMenlo, Consolas, DejaVu Sans Mono, monospace この場合、HTMLでは以下のようになる。\n1 2 3  \u0026lt;code style=\u0026#34;font-family: Menlo, Consolas, \u0026amp;quot;DejaVu Sans Mono\u0026amp;quot;, monospace;\u0026#34;\u0026gt; hoge \u0026lt;/code\u0026gt;   HTML出力する プレビュー上で右クリックし、「Save As \u0026hellip;」からHTMLファイルを保存する。PDFに変換したい場合は、Chromeなどの適当なブラウザで開き、「印刷」→「PDFに保存」とする。\n参考 スタイルシートを作成するにあたり、以下のサイトを参考にさせていただいた（ただし、両サイトともmarkdown-preview-plusではなく、markdown-previewを使っているため、スタイルシートの設定を少し変更している）。\nCSSで見出し要素(h1, h2\u0026hellip;)の前に自動で採番する方法 - Qiita\nAtomエディタのMarkdown PreviewのCSSを実務書類的に調整する | 大石制作ブログ\n","description":"Atomを使って技術文書をMarkdownで書くための環境設定方法を示す。","id":19,"section":"posts","tags":["Atom","Markdown"],"title":"AtomとMarkdownで技術文書を書く","uri":"https://helve2017.github.io/posts/text-editor/atom-markdown/"},{"content":"はじめに 本記事では、線形計画問題に対する主双対内点法 (primal-dual interior point method) についてまとめた。\n内点法 主双対内点法の前に内点法 (interior point method) について述べる。\n内点法とは、線形計画問題を多項式時間で解くことが可能な手法である。\n線形計画問題を解く手法として、単体法 (simplex method) と呼ばれるものもある。\n線形計画問題では、最適解は実行可能領域の端点にあることが知られている。\n単体法では実行可能領域の端点を移動することで、有限回の反復で厳密な最適解が探索される。\n単体法は一般的な線形計画問題に対して有用な手法であるが、問題が特殊な場合には反復回数が指数関数的に増加する。\n一方、内点法は実行可能領域の内部を最適解に向けて探索する手法である。\n内点法では問題の規模に対して計算時間が多項式的にしか増加しない。\nそのため、大規模な問題に対しては内点法が適している。\n主双対内点法 主双対内点法は、双対定理を利用して、線形計画問題の主問題と双対問題を同時に解く手法である。\n主問題または双対問題を単独に内点法で解く手法もあるが、主双対内点法はそれらの手法よりも計算が速いという利点がある。\nまた、詳細は本記事では触れないが、主双対内点法は非線形問題にも適用できる。\n主双対内点法のアルゴリズム 最適性条件 双対定理を用いて、線形計画問題の最適解が満たす条件（最適性条件）を考える。\n双対定理については、以下の記事も参考のこと。\n線形計画問題と双対問題\nまず、以下の制約付き線形計画問題を考える。\n$ \\mathrm{min} \\ f_p(\\boldsymbol{x}) = \\boldsymbol{c}^{\\top} \\boldsymbol{x} $\n$ \\mathrm{s.t.}\\ A\\boldsymbol{x}=\\boldsymbol{b}, \\boldsymbol{x} \\ge \\boldsymbol{0} $\nここで、$ \\boldsymbol{x} \\in \\mathbb{R}^n, A\\in \\mathbb{R}^{n\\times m}, \\boldsymbol{b} \\in \\mathbb{R}^m, \\boldsymbol{c} \\in \\mathbb{R}^n$である。\nこの問題に対して、双対問題 (dual problem) は以下で与えられる。\n$ \\mathrm{max} \\ f_d(\\boldsymbol{y}) = \\boldsymbol{b}^{\\top} \\boldsymbol{y} $\n$ \\mathrm{s.t.}\\ A^{\\top} \\boldsymbol{y}+\\boldsymbol{z} =\\boldsymbol{c}, \\boldsymbol{z} \\ge \\boldsymbol{0} $\nここで、$ \\boldsymbol{y} \\in \\mathbb{R}^m, \\boldsymbol{z} \\in \\mathbb{R}^m$である。\n双対問題に対し、元の問題を主問題 (primal problem) と呼ぶ。\n双対定理により、主問題と双対問題が最適解を持つならば、2つの最適解の値は一致する。\nすなわち、\n$\\boldsymbol{c}^{\\top} \\boldsymbol{x} = \\boldsymbol{b}^{\\top} \\boldsymbol{y}$\nである。\nこの式を変形すると、\n$$ \\begin{array}{rl} \\boldsymbol{c}^{\\top} \\boldsymbol{x} - \\boldsymbol{b}^{\\top} \\boldsymbol{y} = 0 \u0026amp; \\Leftrightarrow (A^{\\top} \\boldsymbol{y}+\\boldsymbol{z})^{\\top} \\boldsymbol{x} - (A\\boldsymbol{x})^{\\top} \\boldsymbol{y} = 0 \\\\ \u0026amp; \\Leftrightarrow \\boldsymbol{z}^{\\top} \\boldsymbol{x} = 0 \\\\ \u0026amp; \\Leftrightarrow x_i z_i = 0 (i=1, \u0026hellip;, n) \\\\ \u0026amp; \\Leftrightarrow X \\boldsymbol{z} = \\boldsymbol{0} \\end{array} $$\nが得られる。\nただし、$X$は対角が$x_i (i=1, \u0026hellip;, n)$, その他の要素が0の行列である。\nしたがって、最適性条件は以下のようになる。\n$$ \\begin{array}{rl} \\left( \\begin{array}{l} A\\boldsymbol{x}=\\boldsymbol{b} \\\\ A^{\\top} \\boldsymbol{y}+\\boldsymbol{z} =\\boldsymbol{c} \\\\ X \\boldsymbol{z} = \\boldsymbol{0} \\\\ \\boldsymbol{x} \\ge \\boldsymbol{0}, \\boldsymbol{z} \\ge \\boldsymbol{0} \\\\ \\end{array} \\right. \\end{array} $$\n1番目と2番目の条件は、それぞれ主問題と双対問題の制約条件である。\n3番目の条件は、双対定理より得られた条件である。\n最適性条件を以下のベクトル表現に変形する。\n$ \\boldsymbol{r_0}(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = \\left[ \\begin{array}{c} A \\boldsymbol{x} - \\boldsymbol{b} \\\\ A^{\\top} \\boldsymbol{y} + \\boldsymbol{z} - \\boldsymbol{c} \\\\ X \\boldsymbol{z} \\end{array} \\right] = \\boldsymbol{0} $\n$ \\boldsymbol{x} \\ge \\boldsymbol{0}, \\boldsymbol{z} \\ge \\boldsymbol{0} $\nすなわち、最適解は$\\boldsymbol{r_0}(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = \\boldsymbol{0}$を満たす$\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}$である。\n上記の方程式は非線形であるため、最適解を直接求めることは困難である。\nよって、ニュートン法により解候補を徐々に最適解の方向に更新することによって最適解を求める。\n解の更新 解の更新方向を$[\\boldsymbol{\\Delta x}, \\boldsymbol{\\Delta y}, \\boldsymbol{\\Delta z}]$とすると、これを求めるには、次の1次方程式を解けばよい。\n$$ J(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) \\left[ \\begin{array}{c} \\boldsymbol{\\Delta x} \\\\ \\boldsymbol{\\Delta y} \\\\ \\boldsymbol{\\Delta z} \\\\ \\end{array} \\right] = - \\boldsymbol{r_0}(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) $$\nここで、$J(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z})$は$\\boldsymbol{r_0}(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z})$のヤコビ行列であり、\n$$ J(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = \\left[ \\begin{array}{ccc} O \u0026amp; A^{\\top} \u0026amp; I \\\\ A \u0026amp; O \u0026amp; O \\\\ Z \u0026amp; O \u0026amp; X \\\\ \\end{array} \\right] $$\nで与えられる。\n$Z$は対角が$z_i (i=1, \u0026hellip;, n)$でその他の要素が0の行列、$I$は単位行列である。\n解の探索方向が求まれば、適当なステップサイズ$\\alpha \u0026gt; 0$により、解を以下のように更新する。\n$$ \\left[ \\begin{array}{c} \\boldsymbol{x_{k+1}} \\\\ \\boldsymbol{y_{k+1}} \\\\ \\boldsymbol{z_{k+1}} \\\\ \\end{array} \\right] = \\left[ \\begin{array}{c} \\boldsymbol{x_{k}} \\\\ \\boldsymbol{y_{k}} \\\\ \\boldsymbol{z_{k}} \\\\ \\end{array} \\right] + \\alpha \\left[ \\begin{array}{c} \\boldsymbol{\\Delta x} \\\\ \\boldsymbol{\\Delta y} \\\\ \\boldsymbol{\\Delta z} \\\\ \\end{array} \\right] $$\nただし、$k$は更新回数を示す。\n以上が、主双対内点法の基本的なアルゴリズムである。\nただし、実際には収束性を改善するため、様々な工夫がなされている。\nパス追跡法、アフィン・スケーリング法、プレディクタ・コレクタ法など様々な手法があるが、以下ではパス追跡法について述べる。\nパス追跡法 解の更新時に非負制約$\\boldsymbol{x} \\ge \\boldsymbol{0}, \\boldsymbol{z} \\ge \\boldsymbol{0}$の境界に近づくと、最適解への収束が停滞する可能性がある。\nしたがって、最適解への収束速度を上げるためには、可能な限り境界から遠い場所を通る必要がある。\nそこで、中心パス (central path) と呼ばれるものを考える。\nパラメータ$\\mu \u0026gt;0$を導入し、最適性条件の方程式を以下のように置き換える。\n$$ \\boldsymbol{r}(\\boldsymbol{x}, \\boldsymbol{y}, \\boldsymbol{z}) = \\left[ \\begin{array}{c} A\\boldsymbol{x} - \\boldsymbol{b} \\\\ A^{\\top} \\boldsymbol{y}+\\boldsymbol{z} - \\boldsymbol{c} \\\\ X \\boldsymbol{z} - \\mu \\boldsymbol{e} \\\\ \\end{array} \\right] = \\boldsymbol{0} $$\n$$ \\boldsymbol{x} \\ge \\boldsymbol{0}, \\boldsymbol{z} \\ge \\boldsymbol{0} $$\nここで、$\\boldsymbol{e}$は要素が全て1のベクトルである。\n$ X \\boldsymbol{z} = \\mu \\boldsymbol{e}$とすることで、$x_i, z_i (i=0, \u0026hellip;, n)$が0に近づかないようにしている。\n$\\mu$の値を固定したとき、上記の方程式はただ1つの解を持つ。\nこの解は、$\\mu$の値を変化させると滑らかな曲線を描き、$\\mu = 0$となるときに最適解となる。\nしたがって、解を更新しながら、$\\mu$の値を徐々に小さくすることで最適解に収束することが期待できる。\n参考 以下の論文を参考にさせて頂いた。\n中田 和秀「主双対内点法」、オペレーションズ・リサーチ 2019年4月号 (PDF)\n","description":"線形計画問題に対する主双対内点法 (primal-dual interior point method) についてまとめた。","id":20,"section":"posts","tags":["最適化"],"title":"線形計画問題の主双対内点法","uri":"https://helve2017.github.io/posts/math/primal_dual_interior_point_methd_lp/"},{"content":"はじめに 本記事では、最適化でよく用いられる双対問題についてまとめた。\nまた、サポートベクターマシンにおける双対問題についても少し触れている。\n線形計画問題の標準形 まず、以下の制約付き線形計画問題を考える。\n$ \\mathrm{min} \\ f_p(\\boldsymbol{x}) = \\boldsymbol{c}^{\\top} \\boldsymbol{x} $\n$ \\mathrm{s.t.}\\ A\\boldsymbol{x}=\\boldsymbol{b}, \\boldsymbol{x} \\ge \\boldsymbol{0} $\nここで、$ \\boldsymbol{x} \\in \\mathbb{R}^n, A\\in \\mathbb{R}^{n\\times m}, \\boldsymbol{b} \\in \\mathbb{R}^m, \\boldsymbol{c} \\in \\mathbb{R}^n$である。\n上記の形は、線形計画問題の標準形と呼ばれる。\nまた、問題に不等式制約が含まれる場合にも、標準形に変換することが出来る。例えば、\n$ A\\boldsymbol{x} \\le \\boldsymbol{b}$\nなる不等式制約があるとき、新たに変数$ \\boldsymbol{y} \\ge \\boldsymbol{0}$を導入して、\n$ A\\boldsymbol{x}+ \\boldsymbol{y} =\\boldsymbol{b}$\nとできる。この$ \\boldsymbol{y}$をスラック変数と呼ぶ。\n双対問題 先程の線形計画問題\n$ \\mathrm{min} \\ f_p(\\boldsymbol{x}) = \\boldsymbol{c}^{\\top} \\boldsymbol{x} $\n$ \\mathrm{s.t.}\\ A\\boldsymbol{x}=\\boldsymbol{b}, \\boldsymbol{x} \\ge \\boldsymbol{0} $\nに対して、双対問題 (dual problem) は以下で与えられる。\n$ \\mathrm{max} \\ f_d(\\boldsymbol{y}) = \\boldsymbol{b}^{\\top} \\boldsymbol{y} $\n$ \\mathrm{s.t.}\\ A^{\\top} \\boldsymbol{y}+\\boldsymbol{z} =\\boldsymbol{c}, \\boldsymbol{z} \\ge \\boldsymbol{0} $\nここで、$ \\boldsymbol{y} \\in \\mathbb{R}^m, \\boldsymbol{z} \\in \\mathbb{R}^m$である。\n双対問題に対し、元の問題を主問題 (primal problem) と呼ぶ。\n双対問題は主問題と密接な関係にあり、その関係を双対性 (duality) と呼ぶ。\n弱双対定理 主問題と双対問題の目的関数について、以下の弱双対定理が成り立つ。\n弱双対定理\n$ \\boldsymbol{x}, \\boldsymbol{y}$がそれぞれ主問題と双対問題の実行可能解であるとき、以下の不等式が成り立つ。\n$f_p(\\boldsymbol{x}) = \\boldsymbol{c}^{\\top} \\boldsymbol{x} \\ge \\boldsymbol{b}^{\\top} \\boldsymbol{y} = f_d(\\boldsymbol{y}) $\n[証明]\n$ \\boldsymbol{x}, \\boldsymbol{y}$は実行可能解であるから、\n$$ \\begin{array}{rl} \\boldsymbol{c}^{\\top} \\boldsymbol{x} - \\boldsymbol{b}^{\\top} \\boldsymbol{y} \u0026amp;= (A^{\\top} \\boldsymbol{y}+\\boldsymbol{z})^{\\top} \\boldsymbol{x} - (A\\boldsymbol{x})^{\\top} \\boldsymbol{y} \\\\ \u0026amp;= (\\boldsymbol{y}^{\\top} A + \\boldsymbol{z}^{\\top})\\boldsymbol{x} - (\\boldsymbol{x}^{\\top} A^{\\top}) \\boldsymbol{y} \\\\ \u0026amp;= \\boldsymbol{y}^{\\top} A \\boldsymbol{x} + \\boldsymbol{z}^{\\top} \\boldsymbol{x} - \\boldsymbol{x}^{\\top} A^{\\top} \\boldsymbol{y} \\\\ \u0026amp;= \\boldsymbol{z}^{\\top}\\boldsymbol{x} \\\\ \u0026amp;\\ge 0 \\end{array} $$\nよって、\n$$ \\boldsymbol{c}^{\\top} \\boldsymbol{x} \\ge \\boldsymbol{b}^{\\top} \\boldsymbol{y} $$\nが成り立つ。■\nまた、主問題と双対問題の目的関数の差\n$ f_p(\\boldsymbol{x}) - f_d(\\boldsymbol{y}) = \\boldsymbol{c}^{\\top} \\boldsymbol{x} - \\boldsymbol{b}^{\\top} \\boldsymbol{y} $\nを双対ギャップと呼ぶ。\n双対定理 主問題と双対問題について、以下の双対定理が成り立つ（証明は省略）。\n双対定理\n主問題と双対問題のいずれか一方が最適解を持つなら、もう一方も最適解を持ち、主問題の最小値と双対問題の最大値は一致する。\nすなわち、\n$ \\boldsymbol{c}^{\\top} \\boldsymbol{x} = \\boldsymbol{b}^{\\top} \\boldsymbol{y}$\nが成り立つならば、$ \\boldsymbol{x}, \\boldsymbol{y} $はそれぞれ主問題と双対問題の最適解である。\nしたがって、双対問題を解くことで、主問題の最適解を求めることが出来る。\nサポートベクターマシンと双対定理 サポートベクターマシン (SVM) では、以下の2つの利点により双対定理が利用されている。\n 双対問題ではカーネルトリックを利用でき、非線形な分類が可能になる 訓練データ数が次元数より少ない場合、計算が高速になる  2つ目の利点を補足すると、主問題の最適化変数の次元をn, 等式制約の数をmとすると、双対問題では最適化変数の次元がm, 等式制約の数がnと入れ替わる。よって、n\u0026raquo;mであれば、双対問題を解く方が計算が速くなる。\nただし、SVMでは線形計画問題ではなく二次計画問題となる。\n参考 以下のページ・書籍を参考にさせて頂いた。\n双対定理 - 数理計画用語集\n","description":"最適化でよく用いられる双対問題についてまとめた。","id":21,"section":"posts","tags":["最適化"],"title":"線形計画問題と双対問題","uri":"https://helve2017.github.io/posts/math/dual_problem_lp/"},{"content":"はじめに PandasのTimestampを使った時刻の生成や、時刻オブジェクトからの属性の取得、任意形式の文字列での出力について述べる。\nPandasには時刻を扱うためのTimestampというクラスがある。本記事では、Timestampクラスを用いた時刻オブジェクトの生成方法や、その時刻オブジェクトから年月日などの情報を属性として取得する方法について述べる。また、時刻を文字列として取得する方法などについても述べる。\nPandasのTimestampは、Pythonの標準パッケージに含まれるdatetimeモジュールとほぼ同じ機能を持つ。したがって、Pandasをよく使う場合は、時刻もPandasで統一して扱うと、datetime.datetimeオブジェクトと変換したり、datetimeモジュールをインポートしたりする手間を省ける。\n以降では、Pandasを以下のようにインストールしていることを前提とする。\n1  import pandas as pd   また、環境は以下の通り。\n    バージョン     Python 3.7.3   Pandas 0.24.2    Timestampクラスについて Timestampクラスは、日付や時刻を扱うクラスであり、扱える最小時刻はナノ秒である。\nTimestampをDataFrame配列のインデックスにすることにより、時刻データを柔軟に扱うことができる。\nまた、Timestampオブジェクト同士の差をとると、Timedeltaという時間の長さを表すオブジェクトが生成されるが、本記事では扱わない。\nさらに、Timestampクラスはタイムゾーン（時差の情報）を持つことができるが、これも扱わない。\n時刻（Timestampオブジェクト）の生成 pd.Timestampオブジェクトを作成する方法はいくつかあるが、ここでは、pd.Timestampクラスから直接作成する以下3つの方法を示す。\n 日付の文字列から生成 UNIX時刻からの生成 現在時刻から生成  また、pd.date_range()関数を使って、連続した時刻を生成する方法についても述べる。\n日付の文字列から生成 Timestampに時刻を表す文字列を渡すと、時刻オブジェクトが生成される。時刻を表す文字列は柔軟に解釈されるため、年・月・日などの区切りに-や/などが入っていても問題ない。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;20200103\u0026#34;) Timestamp(\u0026#39;2020-01-03 00:00:00\u0026#39;) \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;2020-01-03\u0026#34;) Timestamp(\u0026#39;2020-01-03 00:00:00\u0026#39;) \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;2020/01/03\u0026#34;) Timestamp(\u0026#39;2020-01-03 00:00:00\u0026#39;)   また、ナノ秒単位まで扱える（ナノ秒未満を指定すると切り捨てられる）。\n1 2  \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(\u0026#34;2020-01-03 01:23:45.6789012345\u0026#34;) Timestamp(\u0026#39;2020-01-03 01:23:45.678901234\u0026#39;)   UNIX時刻からの生成 TimestampにUNIX時刻を整数または小数で渡すと、時刻オブジェクトが生成される。UNIX時刻とは、1970年1月1日0時0分0秒を起点とした時刻である。\nデフォルトでは、UNIX時刻の単位はナノ秒である。これを変更するには、Timestampのunit引数にUNIX時刻の単位を文字列で指定する。有効な単位はD, h, m, s, ms, us, nsである。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(0) ### UNIX時刻の起点 Timestamp(\u0026#39;1970-01-01 00:00:00\u0026#39;) \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(1) ### デフォルトでは1ナノ秒に解釈される Timestamp(\u0026#39;1970-01-01 00:00:00.000000001\u0026#39;) \u0026gt;\u0026gt;\u0026gt; pd.Timestamp(1, unit=\u0026#34;s\u0026#34;) ### 1秒単位に変更 Timestamp(\u0026#39;1970-01-01 00:00:01\u0026#39;)   現在時刻から生成 Timestampのnow()メソッドを実行すると、現在時刻が得られる。\n1 2  \u0026gt;\u0026gt;\u0026gt; pd.Timestamp.now() Timestamp(\u0026#39;2020-01-03 10:15:49.030441\u0026#39;)   連続した時刻の生成 一定の間隔で連続した時刻の配列を生成したい場合は、\npd.date_range()関数を用いる。\nこの関数の主な引数を示す。\n1  pd.date_range(start=None, end=None, periods=None, freq=None)   引数の説明は以下の通り。\n   引数 データ型 説明     start str, pd.Timestamp 開始時刻   end str, pd.Timestamp 終了時刻   periods int 時刻の数   freq str 時刻の間隔    4つの引数 (start, end, periods, freq) の内、3つを指定する必要がある。\nまた、freqは時間の単位を表す文字列を与える。主な時間の単位と、対応する文字列を示す。\n   時間の単位 文字列     年末 A, Y   年始 AS, YS   月末 M   月始 MS   日 D   時間 H   分 T, min   秒 S   ミリ秒 L, ms   マイクロ秒 U, us   ナノ秒 N    また、文字列の前に数字を付けると、その時間の倍数になる。\n例：3分の場合、freq=\u0026quot;3T\u0026quot;\nまた、その他の時間の単位（四半期、営業日など）は以下のリンクを参照。\nTime series _ date functionality — pandas 1.2.0 documentation\nTimestampの主な属性 Timestampオブジェクトの主な属性を示す。\nまず、時刻の単位を数字で取り出せる属性を示す（なぜかミリ秒がない）。\n   時間の単位 属性名     年 year   月 month   日 day   時間 hour   分 minute   秒 second   マイクロ秒 microsecond   ナノ秒 nanosecond    また、その他の属性を以下に示す。\n   説明 属性     UNIX時刻（ナノ秒単位） value   曜日(月曜: 0, \u0026hellip;, 日曜: 6) dayofweek   その年の何日目か dayofyear    例\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; t1 = pd.Timestamp(\u0026#34;2020-01-03\u0026#34;) \u0026gt;\u0026gt;\u0026gt; t1.year ### 年を取得 2020 \u0026gt;\u0026gt;\u0026gt; t1.value ### UNIX時刻（ナノ秒単位） 1578009600000000000   Timestampの主なメソッド Timestampオブジェクトの主なメソッドを示す。\n時刻の単位を置換する(replace) replaceメソッドで、ミリ秒を除く時刻を置換できる。\n1 2 3  Timestamp.replace(year=None, month=None, day=None, hour=None, minute=None, second=None, microsecond=None, nanosecond=None)   時刻を文字列で出力する(strftime) strftimeメソッドで、任意のフォーマットで時刻を文字列として出力できる。なお、strftimeのfはformatの頭文字である。\n主なフォーマットを以下の表に示す。\n   時間の単位 フォーマット     4桁の西暦 %Y   下2桁の西暦 %y   月 %m   日 %d   時(24時間制) %H   分 %M   秒 %S   マイクロ秒(6桁の0埋め) %f    これらのフォーマットは、全て0埋め (0 padding) である。\n例\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; t1 = pd.Timestamp(\u0026#34;2020-01-03\u0026#34;) \u0026gt;\u0026gt;\u0026gt; t1.strftime(\u0026#34;%Y%m%d\u0026#34;) \u0026#39;20200103\u0026#39; \u0026gt;\u0026gt;\u0026gt; t1.strftime(\u0026#34;%Y/%m/%d\u0026#34;) \u0026#39;2020/01/03\u0026#39;   その他のフォーマットについては、以下のページの表を参照のこと。\ndatetime — Basic date and time types — Python 3.9.1 documentation\n参考 pandas.Timestamp — pandas 1.2.0 documentation\n","description":"PandasのTimestampを使った時刻の生成や、時刻オブジェクトからの属性の取得、任意形式の文字列での出力について述べる。","id":22,"section":"posts","tags":["Python","Pandas"],"title":"PandasのTimestampで時刻を扱う","uri":"https://helve2017.github.io/posts/python/pandas-timestamp/"},{"content":"はじめに 辞書内包表記を使って、PandasのSeries, DataFrameを少ないコード量で作成する。\n辞書内包表記は、Pythonの標準機能であり、辞書(dict)型の変数を簡潔に作成できる。また、Pandasの配列データ型であるSeries, DataFrameは辞書から作成できる。\nそのため、辞書内包表記を使って、Series, DataFrameを少ないコード量で作成する方法を示す。\n以降では、Pandasを以下のようにインストールしていることを前提とする。\n1  import pandas as pd   また、環境は以下の通り。\n    バージョン     Python 3.7.3   Pandas 0.24.2    辞書内包表記 辞書内包表記の例を示す。0から9までの数字をキー、各キーを2倍にしたものを値とした辞書を得る。\n1 2  doubles_dict = {x: x*2 for x in range(10)} print(doubles_dict)   実行結果\n1  {0: 0, 1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18}   上記の例のように、リスト内包表記の[...]を{...}として、コロン:を使ってキーと値を指定すると、辞書内包表記となる。\nまた、辞書内包表記ではifやif～elseを使うことも可能である。詳細は以下の記事を参照。\nPythonの辞書内包表記\n辞書を使ったSerie, DataFrameの作成 PandasのSeriesの場合、辞書を引数として渡すと、キーをindexとするSeriesオブジェクトが生成される。\n例\n1 2 3  dict1 = {\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, \u0026#34;c\u0026#34;:3} sr1 = pd.Series(dict1) print(sr1)   実行結果\n1 2 3 4  a 1 b 2 c 3 dtype: int64   一方、PandasのDataFrameの場合、値をリストである辞書を引数として渡すと、キーをcolumnsとするDataFrameオブジェクトが生成される。indexは0, 1, \u0026hellip;と整数が割り振られる。\n例\n1 2 3  dict2 = {\u0026#34;a\u0026#34;: [1, 2], \u0026#34;b\u0026#34;: [3, 4], \u0026#34;c\u0026#34;:[5, 6]} df1 = pd.DataFrame(dict2) print(df1)   実行結果\n1 2 3  a b c 0 1 3 5 1 2 4 6   ここで、辞書をDataFrameの引数として直接渡す場合、リストの長さは同じでなければならない。リストの長さが異なる場合にDataFrameを作成したい場合は、以下の記事を参照。\n辞書をpd.DataFrameに変換 - Qiita\n辞書内包表記を使ったSerie, DataFrameの作成 よって、辞書内包表記を使うと、Serie, DataFrameの作成を簡潔に記述できる。\nまず、Seriesの例として、偶数を並べた配列を作成する。\n1 2  sr2 = pd.Series({x: x*2 for x in range(5)}) print(sr2)   実行結果\n1 2 3 4 5 6  0 0 1 2 2 4 3 6 4 8 dtype: int64   次に、DataFrameの例として、1行目に2の倍数、2行目に3の倍数を並べた配列を作成する。\n1 2  df2 = pd.DataFrame({x: [x*2, x*3] for x in range(5)}) print(df2)   実行結果\n1 2 3  0 1 2 3 4 0 0 2 4 6 8 1 0 3 6 9 12   参考 Pythonの辞書内包表記\n辞書をpd.DataFrameに変換 - Qiita\n","description":"辞書内包表記を使って、PandasのSeries, DataFrameを少ないコード量で作成する。","id":23,"section":"posts","tags":["Python","Pandas"],"title":"辞書内包表記でPandasのSeries, DataFrameを作成","uri":"https://helve2017.github.io/posts/python/pandas-constructed-by-dict-comprehension/"},{"content":"はじめに Pythonには、ある関数の前後に処理を追加する仕組みとして、デコレータと呼ばれる機能がある。本記事ではデコレータの使用例として、回帰の精度評価でMSE, RMSEの両方を算出する場合に、入力配列の型を変換する処理をデコレータにまとめたものを示す。\nなお、本記事の内容とは直接関係ないが、WebアプリケーションライブラリのFlaskでコールバック関数にデコレータが使われていたことが勉強の動機である。\n環境は以下の通り。\n    バージョン     Python 3.7.4   NumPy 1.16.5    デコレータの例 デコレータの簡単な例を以下に示す。\n1 2 3 4 5 6 7 8 9 10 11 12  def decorator(func): def wrapper(*args, **kwargs): print(\u0026#39;--start--\u0026#39;) func(*args, **kwargs) print(\u0026#39;--end--\u0026#39;) return wrapper @decorator def hello(): print(\u0026#39;Hello World\u0026#39;) hello()   実行結果\n1 2 3  --start-- Hello World --end--   上記の例では、decoratorがデコレータであり、helloが処理を追加される関数である。hello関数を定義する直前に@（デコレータ名）とすると、helloを呼び出したときにデコレータも同時に呼び出される。\nデコレータ関数decoratorの内部にはさらに関数wrapperが定義されており、decoratorはwrapper関数のオブジェクトを返す。\nwrapper関数では、func(*args, **kwargs)の部分でデコレートされる関数を実行している。その前後に実行したい処理を記述する。\nデコレータの機能 デコレータには以下の使い方もある。\n デコレータを多重にネストできる デコレータが引数をとる  デコレータの使用例 デコレータには、以下のような使い道がある。\n 関数の実行時間を計測する 関数の入力値をチェックする 関数をいつ呼び出したか等の実行ログを残す  2つ目の使い道の例として、回帰の精度評価でMSE, RMSEの両方を算出する場合を考える。なお、MSEは二乗平均誤差、RMSEは二乗平均平方根誤差である。\nここで、MSE, RMSEはそれぞれ別の関数で算出するものとする。また、予測値と実測値は、リスト、NumPy配列、PandasのSeries, DataFrameのいずれの型で与えられても算出できるようにしたい。\nこのとき、予測値と実測値を1つの型に変換する処理をデコレータにまとめることで、MSEとRMSEを算出する関数はその型のみに対応した処理のみ記述すれば済むようになる。\nここではデコレータでNumPy配列に変換するものとして、例を以下に示す。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import numpy as np def conv2nparray(func): def wrapper(*args): a = np.array(args[0]).flatten() b = np.array(args[1]).flatten() res = func(a, b) return res return wrapper @conv2nparray def mse(a, b): return np.mean((a-b)**2) @conv2nparray def rmse(a, b): return np.sqrt(np.mean((a-b)**2))   conv2nparrayでは、2つの引数をそれぞれ1次元のNumPy配列に変換している。また、配列の長さが等しくない場合の処理や、NaNを含むときの処理が必要であれば、デコレータの中に書くことも可能である。\n参考 Pythonのデコレータについて - Qiita\n","description":"Pythonで関数の前後に処理を追加する、デコレータと呼ばれる機能について簡単にまとめた。","id":24,"section":"posts","tags":["Python"],"title":"Pythonのデコレータで関数に処理を追加する","uri":"https://helve2017.github.io/posts/python/python-decorator/"},{"content":"はじめに ウェブUIのテストツールであるseleniumを使った、ブラウザ操作の自動化についてまとめた。\nseleniumはウェブUIのテストを自動化するためのツールである。これをPythonから呼び出すことで、ウェブ画面上の操作を自動化できる。\n本記事では、環境構築 (seleniumとWebDriverの準備)と、ウェブページの自動操作について述べる。\n環境は以下の通り。\n    バージョン     Python 3.7.3   selenium 3.141.0    また、OSはWindows 8.1である。\n環境構築 seleniumのインストールと、WebDriverのダウンロードを行う。\nconda環境では、seleniumを以下の通りインストールする。\nconda install selenium それ以外では、pipでインストールする。\nconda install selenium 次にWebDriverをダウンロードする。WebDriverはブラウザごとに異なるものが必要になる。\n2020年12月17日現在、ChromeのWebDriverは以下のページからダウンロードできる。\nDownloads - ChromeDriver - WebDriver for Chrome\n上記のページから、Chromeのバージョンや、OSが一致するWebDriverをダウンロードする。\nダウンロードしたzipファイルを展開するとchromedriver.exeという実行ファイルがあるので、適当なフォルダに置く。\n本記事では、以下のパスに置くこととする。\nC:\\selenium\\chromedriver.exe chromedriver.exeにパスを通しておくと後々便利であるが、ここではパスを通さずに進める。\nただし、記事を読まれている時点では、WebDriverの情報は古くなっている可能性があるため、適宜最新の情報を参照されたい。最新の情報や、他のブラウザのダウンロード方法については、「selenium WebDriver （ブラウザ名）」で検索すると出てくる。\nseleniumによるページ制御の基本 以下の手順により、Pythonでseleniumを使ったページ制御を行う。\n WebDriverでブラウザを起動 get()メソッドでページを取得 find_*メソッドでWebElementオブジェクト（ページの要素）を取得 WebElementオブジェクトのメソッドを使ってページを操作する  ウェブページを開く 以下のスクリプトを実行すると、英語版Wikipediaのトップページが開く。\n例1\n1 2 3  from selenium import webdriver driver = webdriver.Chrome(executable_path=\u0026#34;C:\\selenium\\chromedriver.exe\u0026#34;) driver.get(\u0026#34;https://en.wikipedia.org\u0026#34;)   まず、webdriver.Chromeでブラウザを立ち上げ、WebDriverオブジェクトを取得する。使用するブラウザによって、Chromeの部分を適宜変更する。また、executable_pathでWebDriverを指定するが、chromedriver.exeにパスが通っている場合は指定する必要はない。\n次に、WebDriverオブジェクトのget()メソッドに開きたいURLを渡すと、ページを開く。\nなお、ブラウザを閉じるときは、WebDriverオブジェクトのquit()メソッドを実行する。\nウェブページの要素を探す WebDriverのメソッドを使って、操作したい要素を探す。\nメソッドは大きく分けて2種類あり、検索条件に一致する最初の要素をWebElementオブジェクトとして返すものと、検索条件に一致する全ての要素をWebElementオブジェクトのリストとして返すものがある。\n前者はfind_element_から始まる名前のメソッドであり、後者は複数形のfind_elements_から始まる名前のメソッドである。\nfind_element_から始まる主なメソッドを以下に示す。\n   メソッド 内容     find_element_by_id id属性が一致する要素   find_element_by_name name属性が一致する要素   find_element_by_link_text 完全一致する\u0026lt;a\u0026gt;要素   find_element_by_partial_link_text 部分一致する\u0026lt;a\u0026gt;要素   find_element_by_tag_name タグ名と一致する要素   find_element_by_class_name CSSクラスと一致する要素   find_element_by_css_selector CSSセレクタに一致する要素    これらのelementをelementsに置き換えると、全ての要素を検索できる。\n例2\n以下のHTMLがあったとする。\n1  \u0026lt;a href=\u0026#34;https://en.wikipedia.org\u0026#34;\u0026gt;Wiki\u0026lt;/a\u0026gt;   このHTMLをブラウザで開くと、https://en.wikipedia.orgへリンクを張った、Wikiという文字列が表示される。\nまた、上記の例では、HTMLの各構造は以下の名前で呼ばれる。\n a: タグ名 href: 属性 Wiki: 内部テキスト  ここで、\u0026lt;a\u0026gt;の開始タグと終了タグで囲まれた全体を要素と呼ぶ。\nこの要素をSeleniumで探すには、\n1  WebDriver.find_element_by_link_text(\u0026#34;Wiki\u0026#34;)   または、\n1  WebDriver.find_element_by_tag_name(\u0026#34;a\u0026#34;)   のようにする。\n要素の内容を取得する WebElementオブジェクトには、要素の内容を取得するために、以下のような属性やメソッドがある。\n   属性・メソッド 内容     tag_name タグ名   text 要素の内部テキスト   get_attribute(name) name属性の値    ウェブページを操作する クリックする WebElementオブジェクトのclick()メソッドを実行すると、その要素上でマウスをクリックする。\n例3\n例1で開いたWikipediaの左カラム上部にある、\u0026ldquo;Contents\u0026quot;というリンクをクリックする動作を考える。\nまず、内部テキストが\u0026quot;Contents\u0026quot;である要素を、find_element_by_link_textメソッドでWebElementとして取得する。次に、このWebElementのclick()メソッドを実行する。\n例1のスクリプトと合わせると、以下のようになる。\n1 2 3 4 5 6  from selenium import webdriver driver = webdriver.Chrome(executable_path=\u0026#34;C:\\selenium\\chromedriver.exe\u0026#34;) driver.get(\u0026#34;https://en.wikipedia.org\u0026#34;) link_ele = driver.find_element_by_link_text(\u0026#34;Contents\u0026#34;) link_ele.click()   上記を実行すると、以下のページが開く。\nhttps://en.wikipedia.org/wiki/Wikipedia:Contents\nテキストを入力・送信する Wikipediaトップページの右上の検索窓に、単語を入力して検索することを考える。\nこの検索窓のHTML上の情報を調べるため、ブラウザの開発者ツールを用いる。Chromeの場合はF12キーを使用する。\n画像右上のHTMLソースの背景が灰色になっている箇所より、検索窓のid属性はsearchInputであることが分かる。これをfind_element_by_idメソッドを使って、WebElementオブジェクトとして取得する。\n次に、send_keysメソッドを使って、検索窓に渡したい文字列を指定する。最後にsubmitメソッドを実行すると、「送信」を押したことになり、検索結果のページが得られる。\n例4\nWikipediaで\u0026quot;python\u0026quot;を検索する。\n1 2 3 4 5 6 7  from selenium import webdriver driver = webdriver.Chrome(executable_path=\u0026#34;C:\\selenium\\chromedriver.exe\u0026#34;) driver.get(\u0026#34;https://en.wikipedia.org\u0026#34;) search_ele = driver.find_element_by_id(\u0026#34;searchInput\u0026#34;) search_ele.send_keys(\u0026#34;python\u0026#34;) search_ele.submit()   実行結果\n以下のページが表示される。\n参考 PythonでSeleniumを操作する — Selenium Python Bindings 2 ドキュメント\n","description":"ウェブUIのテストツールであるseleniumを使った、ブラウザ操作の自動化についてまとめた。","id":25,"section":"posts","tags":["Python","selenium"],"title":"Pythonとseleniumを使ったブラウザ操作自動化","uri":"https://helve2017.github.io/posts/python/python-selenium/"},{"content":"はじめに Pythonのreモジュールの基本的な使い方をまとめた。また、正規表現を扱うために便利なraw文字列、および正規表現についても簡単に述べる。\n正規表現 (Regular Expression) により、柔軟な表現で文字列のパターンマッチングを行える。\n以降ではreモジュールをインポートしていることを前提とする。\n1  import re   環境\nPython 3.7.3\nraw文字列について 正規表現の前に、raw文字列について述べる。\nPythonでは、正規表現をraw文字列で表すことが多い。これは、正規表現を表す文字列には、バックスラッシュが含まれることが多いためである。例えば、1桁の数字を表す正規表現は\\dとなる。\nしかし、標準のPythonの文字列の仕様では、\\記号はエスケープ文字となるため、'\\d'という正規表現を表すためには'\\\\d'と書く必要がある。\nそこで、raw文字列を用いる。raw文字列とは、先頭にrが付いた文字列のことであり、文字列中の\\によるエスケープを無効にできる。\nすなわち、'\\\\d'という文字列とr'\\d'というraw文字列は等価である。\n正規表現を使った文字列の検索例 reモジュールによる正規表現を使った文字列の検索例を示す。\n検索方法は主に以下の2種類がある。\n re.search()関数を使う 正規表現オブジェクト(re.compile)を使う  前者の方が簡潔に記述できる。一方、後者では、リファレンスによると正規表現がキャッシュされるため、同じ正規表現で何度も検索する場合は、処理を高速に行える。\n以下の問題に対して、各方法の例を示す。\n問題：\u0026quot;12 * 3 = 36\u0026quot;という文字列の中から、2桁の数字を探す。\nre.search()関数を使う re.search()関数の第1引数に正規表現、第2引数に検索対象の文字列をとって実行すると、マッチオブジェクトが返される。\nマッチオブジェクトのgroupメソッドを呼ぶと、検索結果が得られる。ただし、re.search()関数では最初にヒットした検索結果しか得られない。\n1 2 3 4  reg_pat = r\u0026#34;\\d\\d\u0026#34; string = \u0026#34;12 * 3 = 36\u0026#34; mo = re.search(reg_pat, string) print(mo.group())   実行結果\n1  12   文字列の中から、正規表現と一致する全ての検索結果を得たい場合は、re.search()関数の代わりにre.findall()関数を用いる。ただし、findallメソッドの戻り値はマッチオブジェクトではなく、マッチした文字列のリストである。\n正規表現オブジェクト(re.compile)を使う 正規表現オブジェクトを使う場合、以下の手順になる。\n re.compileに正規表現を渡して正規表現オブジェクトを作成する。 searchメソッドに検索対象の文字列を渡して、マッチオブジェクトを得る。 groupメソッドから検索結果を得る。  1 2 3 4 5  reg_pat = r\u0026#34;\\d\\d\u0026#34; string = \u0026#34;12 * 3 = 36\u0026#34; reg = re.compile(reg_pat) mo = reg.search(string) print(mo.group())   実行結果\n1  12   文字列の中から、正規表現と一致する全ての検索結果を得たい場合は、searchメソッドの代わりにfindallメソッドを用いる。ただし、findallメソッドの戻り値はマッチオブジェクトではなく、マッチした文字列のリストである。\n正規表現の規則 よく使うと思われる正規表現の規則について示す。（全ての規則を網羅することは困難なため、詳細を知りたい方は別サイトも参照ください）\n同じ表現の繰り返し ある表現が繰り返される回数を指定するときは、その表現の後ろに{（数字）}を付ける。\n例\n3桁の連続した数字を検索したい場合：\\d{3}\nまた、繰り返し回数を「N回以上、M回以下」としたい場合は、{N, M}とする。\n任意回数のマッチ ある表現が0回または1回現れる場合には、その表現の後ろに?を付ける。\n例\n\\d-?\\dという正規表現は、「連続した2つの数字」または「間に-を挟んだ2つの数字」のどちらにもマッチする。\n マッチする：'11', '2-3' マッチしない：'1', 2+3', '2--3'  また、?と同様に*と+も繰り返し回数を指定する記号である。*は0回以上のマッチを、+は1回以上のマッチをそれぞれ示す。\n文字集合 /dは0から9までの数字の集合であるが、下表のようなパターンが定義されている。\n   パターン 意味     \\d 0～9の数字 [0-9]   \\D 数字以外   \\w 文字、数字、下線 [a-zA-Z0-9_]   \\w 文字、数字、下線以外    また、角括弧を使うと、文字集合を定義できる。[abc]はa, b, cのいずれかの文字を表す。\n連続した文字はハイフンを使って指定できる。[A-Z]は大文字のAからZまでの文字集合を示す。\n参考 re \u0026mdash; 正規表現操作 — Python 3.9.1 ドキュメント\n正規表現 - Wikipedia\n","description":"","id":26,"section":"posts","tags":["Python","正規表現"],"title":"Pythonのreモジュールを使った正規表現の基本","uri":"https://helve2017.github.io/posts/python/python-regular-expression/"},{"content":"はじめに Pythonの辞書内包表記を使って、辞書(dict)型の変数を簡潔に作成する例を示す。\nPythonにはリスト型の処理を簡潔に書けるリスト内包表記があるが、辞書型にも同様の内包表記がある。リスト内包表記と合わせて、作成例を示す。\n環境: Python 3.5以降\nリスト内包表記 参考までに、リスト内包表記の例を示す。0から9までの数字を2倍にしたリストを得る。\n1 2  doubles = [x*2 for x in range(10)] print(doubles)   実行結果\n1  [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]   辞書内包表記 次に、辞書内包表記の例を示す。0から9までの数字をキー、各キーを2倍にしたものを値とした辞書を得る。\n1 2  doubles_dict = {x: x*2 for x in range(10)} print(doubles_dict)   実行結果\n1  {0: 0, 1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18}   上記の例のように、リスト内包表記の[...]を{...}として、コロン:を使ってキーと値を指定すると、辞書内包表記となる。\n辞書内包表記のif 辞書内包表記で、ある条件を満たす変数のみ抽出する場合は、in節の後ろにif節を設ける。\n例：0から9までの偶数をキー、各キーを2倍にしたものを値とした辞書を得る。\n1 2  doubles_dict2 = {x: x*2 for x in range(10) if x%2==0} print(doubles_dict2)   実行結果\n1  {0: 0, 2: 4, 4: 8, 6: 12, 8: 16}   辞書内包表記のif～else 辞書内包表記で、条件によって処理を分岐させる場合は、for節の前に、以下のようにif～else節を設ける。\n（条件がTrueのときの値） if （条件） else （条件がFalseのときの値）\n例：0から9までの整数をキーとし、キーが偶数の場合は2倍、キーが奇数の場合は3倍にしたものを値とした辞書を得る。\n1 2  doubles_dict3 = {x: x*2 if x%2==0 else x*3 for x in range(10)} print(doubles_dict3)   実行結果\n1  {0: 0, 1: 3, 2: 4, 3: 9, 4: 8, 5: 15, 6: 12, 7: 21, 8: 16, 9: 27}   参考 5. データ構造 — Python 3.9.0 ドキュメント\n辞書内包表記を使うと、PandasのSeries, DataFrameを簡潔に作成することができます。\n辞書内包表記でPandasのSeries, DataFrameを作成\n","description":"Pythonの辞書内包表記を使って、辞書(dict)型の変数を簡潔に作成する例を示す。","id":27,"section":"posts","tags":["Python"],"title":"Pythonの辞書内包表記","uri":"https://helve2017.github.io/posts/python/python-dict-comprehension/"},{"content":"はじめに pandasで1次元配列を扱うSeriesクラスには、他のSeriesとの相関係数を求めるためのcorrメソッドが用意されている。\nしかし、indexが時系列であるSeries同士で相関係数を求めようとすると、同じ時刻の値同士で相関を計算してしまう。\nこれを避けるためには、shiftメソッドで時刻をずらす必要がある。\n本記事では、これについて実例を示す。\n環境    ソフトウェア バージョン     Python 3.7.3   NumPy 1.16.2   Pandas 0.24.2    また、以下では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2  import numpy as np import pandas as pd   corrメソッドの基本 pandasで1次元配列を扱うSeriesクラスには、他のSeriesとの相関係数を求めるためのcorrメソッドが用意されている。\npandas.Series.corr — pandas 1.2.0 documentation\n例\n1 2 3 4  s1 = pd.Series([1, 2, 3, 4]) s2 = pd.Series([1, 3, 4, 4]) print(s1.corr(s2))   実行結果\n1  0.9128709291752768   時系列データでcorrメソッドを使うときの問題 しかし、indexが時系列であるSeries同士で相関係数を求めようとすると、同じ時刻の値同士で相関を計算してしまう。\n例を示す。乱数で生成した長さ10の配列s1を生成する。また、s1のindexは、2019年12月1日を起点とした、1日周期の日付とする。\n1 2 3 4 5  n_data = 10 start = pd.Timestamp(\u0026#34;2019/12/01\u0026#34;) s1 = pd.Series(np.random.rand(n_data), index=pd.date_range(start, freq=\u0026#34;D\u0026#34;, periods=n_data)) print(s1)   実行結果\n1 2 3 4 5 6 7 8 9 10 11  2019-12-01 0.548814 2019-12-02 0.715189 2019-12-03 0.602763 2019-12-04 0.544883 2019-12-05 0.423655 2019-12-06 0.645894 2019-12-07 0.437587 2019-12-08 0.891773 2019-12-09 0.963663 2019-12-10 0.383442 Freq: D, dtype: float64   次に、s1の1～9番目の要素を抽出したs2と、2～10番目の要素を抽出したs3を定義する。\n1 2 3 4  s2 = s1.iloc[:-1] s3 = s1.iloc[1:] print(s2) print(s3)   実行結果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  2019-12-01 0.548814 2019-12-02 0.715189 2019-12-03 0.602763 2019-12-04 0.544883 2019-12-05 0.423655 2019-12-06 0.645894 2019-12-07 0.437587 2019-12-08 0.891773 2019-12-09 0.963663 Freq: D, dtype: float64 2019-12-02 0.715189 2019-12-03 0.602763 2019-12-04 0.544883 2019-12-05 0.423655 2019-12-06 0.645894 2019-12-07 0.437587 2019-12-08 0.891773 2019-12-09 0.963663 2019-12-10 0.383442 Freq: D, dtype: float64   直観的にはs2とs3の相関係数を計算すると、0に近い値が得られるように思う。しかしながら、実際に計算すると1となる。\n1  print(s2.corr(s3))   実行結果\n1  1.0   これは、corrメソッドの中で、配列の要素の位置ではなく、indexの日付を基準として相関係数の計算が行われているためである。\nなお、この仕様については公式リファレンスに記載されていない。\nこの仕様が問題となるのは、自己相関の算出など、時間をずらして変数間の相関を求めたい場合である。\nちなみに、indexが時刻データであれば、以下のように長さの異なる配列の相関係数も計算できる（結果はもちろん1である）。\n1  print(s2.corr(s1))   時系列データでcorrメソッドを使うときの対策 上記の仕様に関して、時間をずらして相関係数を算出するためには、shiftメソッドを使って配列の時刻をずらすことが必要である。\n試しに、s1の値を1つだけ後ろにずらした配列s4を作成する。\ns1は乱数で生成した配列であるから、s4との相関係数はほぼ0になる。\n1 2 3  s4 = s1.shift(1) print(s4) print(s4.corr(s1))   実行結果\n1 2 3 4 5 6 7 8 9 10 11 12 13  2019-12-01 NaN 2019-12-02 0.548814 2019-12-03 0.715189 2019-12-04 0.602763 2019-12-05 0.544883 2019-12-06 0.423655 2019-12-07 0.645894 2019-12-08 0.437587 2019-12-09 0.891773 2019-12-10 0.963663 Freq: D, dtype: float64 -0.13136358697190584   shiftメソッドについては以下のページを参照。\npandas.Series.shift — pandas 1.2.0 documentation\nまた、他にindexを時刻以外にするという対策もある。\n参考リンク 相関係数を算出するcorrメソッドについては以下を参照。\npandas.Series.corr — pandas 1.2.0 documentation\nPythonで相関係数を計算する[4パターン] - Qiita\npandasのSeries, DataFrameをずらすshiftメソッドについては以下を参照。\npandas.Series.shift — pandas 1.2.0 documentation\npandasでデータを行・列（縦・横）方向にずらすshift | note.nkmk.me\n","description":"","id":28,"section":"posts","tags":["Python","Pandas"],"title":"pandas.Seriesのcorrメソッドで時系列データの相関係数を求める際の注意点","uri":"https://helve2017.github.io/posts/python/pandas-corr-timeseries/"},{"content":"はじめに ディープラーニングのライブラリの1つであるPyTorchには、自動微分の機能が実装されている。\n自動微分を使うと、関数の勾配ベクトルを自動的に求めることができるので、勾配を使った最適化手法を容易に行える。\n本記事では、PyTorchのtensorクラスについて簡単に解説し、1階微分、2階微分の求め方ついてまとめる。\n※本記事はChainerに関する以下の記事をPyTorch向けに書き直したものである。\nChainerの自動微分で勾配を求める\nPyTorchと最適化 PyTorchは、Facebookが提供しているディープラーニング用のライブラリである。\nPyTorchには、ニューラルネットワークの学習を高速に行うため、定義した関数の勾配を自動で求める機能が実装されている。\n（この機能を使うことで、損失関数を最小化するために、ニューラルネットワークの各ノードの重みをどの方向に更新すれば良いか分かる）\n一方、最適化問題を解くとき、最急降下法などの手法では、関数の勾配が必要となる。\n関数の勾配を求めるためには、以下の方法がある。\n 関数の導関数を手計算で求める方法 数値微分（少しだけ変化させた入力変数を与えて出力の差から勾配を求める） 自動微分  問題が複雑な場合、(1)は困難である。\nまた、(2)は計算時間を要する問題がある。\n(3)は、実装に手間が掛かるという欠点があるが、問題ごとに導関数を求める手間も不要で、計算時間も短い利点がある。\nPyTorchには(3)の機能がtensorというクラスで実装されているので、最適化に活用するため仕様についてまとめた。\nまた、最急降下法のPythonでの実装については、過去記事をご参考まで。\n直線探索を使った最急降下法をPythonで実装\nPyTorchはChainerからフォーク（分岐）しているため、Chainerの特徴を受け継いでいる。\n環境    ソフトウェア バージョン     Spyder 3.3.3   Python 3.7.3   NumPy 1.16.2   PyTorch 1.3.1    PyTorchのインストール方法は環境によって異なるため、公式サイトを参考のこと。\nPyTorch\n以下の画像のようにPyTorchのバージョンや、OS, インストールパッケージなどを選択し、\u0026ldquo;Run this Command.\u0026ldquo;に現れるコマンドを使ってPyTorchをインストールする。\nまた、以下では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2 3  import numpy as np import torch from torch import tensor   tensorクラス PyTorchのtensorクラスは、数値の配列データを保持するクラスであり、NumPy配列に近い感覚で扱える。\ntensorクラスのオブジェクトを作成するには、tensorクラスの引数に数値、リスト型の配列、またはNumPy配列を与える。\n例：\n1 2 3  x0 = tensor(1.0) x1 = tensor([1.0, 2.0]) x2 = tensor(np.array([1.0, 2.0]))   ただし、勾配を求めるためには、requires_gradをTrueにする必要がある（デフォルトではFalse）。\n例：\n1  x0 = tensor(1.0, requires_grad=True)   tensorクラスで扱える小数の精度は、16, 32, 64ビットの3種類がある（勾配計算では不要だが、整数やブール型も扱える）。\nデフォルトは32ビット小数であり、変更する場合はdtypeオプションに以下の型を指定する。\n   精度 型指定     16ビット torch.float16 or torch.half   32ビット torch.float32 or torch.float   64ビット torch.float64 or torch.double    例：\n1 2  x0 = tensor(1.0, dtype=torch.float16) x1 = tensor([1.0, 2.0], dtype=torch.double)   また、tensorオブジェクト同士の演算ができる（配列のサイズが異なる場合、ブロードキャストされる）。\n1 2 3  x0 = tensor(1.0) x1 = tensor([1.0, 2.0]) print(x0+x1) # tensor([2., 3.])   配列のインデックスを指定して、要素を取り出すことも可能である。\n1 2  x1 = tensor([1.0, 2.0]) print(x1[1]) # tensor(2.)   tensorオブジェクトのnumpyメソッドを使うと、NumPy配列に変換できる。\n1 2  x1 = tensor([1.0, 2.0]) x1.numpy() # array([1., 2.], dtype=float32)   さらに、tensorオブジェクトのgrad属性から、勾配のtensor配列を取得できる（詳細は後述）。\n1階微分の求め方 tensorオブジェクトを使った1階微分の求め方について述べる。\nまず、以下の2変数関数を考える。\n$$ f(\\boldsymbol{x}) = 2x_0^2 + x_1^2 + 2x_0 + x_1, \\boldsymbol{x}=[ x_0, x_1 ]^\\mathrm{T} $$\nこの関数の勾配ベクトルは次式で与えられる。\n$$ \\nabla f(\\boldsymbol{x}) = \\left[ \\frac{\\partial f}{\\partial x_0}, \\frac{\\partial f}{\\partial x_1} \\right]^\\mathrm{T} = [4x_0 + 2, 2x_1 + 1 ]^\\mathrm{T} $$\n点$ (x_0, x_1)=(1, 2)$において、関数値と勾配ベクトルはそれぞれ以下のようになる。\n$ f(\\boldsymbol{x})=10 $\n$ \\displaystyle \\nabla f(\\boldsymbol{x}) = [6, 5 ]^\\mathrm{T} $\n上記の関数をtensorを使って記述すると以下のようになる。\n1 2  x = tensor([1.0, 2.0], requires_grad=True) y = 2*x[0]**2 + x[1]**2 + 2*x[0] + x[1]   関数の値(10)は既に得られている。\n1 2  \u0026gt;\u0026gt;\u0026gt; y tensor(10., grad_fn=\u0026lt;AddBackward0\u0026gt;)   grad_fnはyに勾配を計算するための計算グラフが構築されていることを示す属性である。\nこの段階では勾配はまだ得られておらず、勾配を取得するためにはbackwardメソッドを実行する。\n1  y.backward()   すると、自動微分が実行され、x.gradに勾配が格納される。\n1 2  \u0026gt;\u0026gt;\u0026gt; x.grad tensor([6., 5.])   ここで、backwardメソッドを実行する変数がスカラーでなければならないことに注意する。\n2つ以上の要素を持つ配列で実行すると、エラーが発生する。\n1 2 3  x = tensor([1.0, 2.0], requires_grad=True) z = 2*x # tensor([2., 4.], grad_fn=\u0026lt;MulBackward0\u0026gt;) z.backward()   実行結果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  Traceback (most recent call last): File \u0026#34;\u0026lt;ipython-input-48-40c0c9b0bbab\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; z.backward() File \u0026#34;D:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u0026#34;, line 166, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File \u0026#34;D:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u0026#34;, line 93, in backward grad_tensors = _make_grads(tensors, grad_tensors) File \u0026#34;D:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u0026#34;, line 34, in _make_grads raise RuntimeError(\u0026#34;grad can be implicitly created only for scalar outputs\u0026#34;) RuntimeError: grad can be implicitly created only for scalar outputs   エラーメッセージには、「スカラーに対してのみ勾配が計算される」とある。\n中間変数の勾配を求める場合 上記の方法では、以下のようにtensorオブジェクトの演算を2回以上重ねた場合に、中間の変数の勾配が保存されない。\n1 2 3 4 5 6  x = tensor(1.0, requires_grad=True) y = x**2 z = y**2 z.backward() y.grad # 勾配が格納されない (None) x.grad # zに対するxの勾配 (tensor(4.))   中間の変数の勾配が欲しい場合には、中間変数のretain_gradメソッドを実行後に、backwardメソッドを実行する。\n1 2 3 4 5 6 7  x = tensor(1.0, requires_grad=True) y = x**2 z = y**2 y.retain_grad() z.backward() y.grad # zに対するyの勾配 (tensor(2.)) x.grad # zに対するxの勾配 (tensor(4.))   2階微分の求め方 2階微分を求めるためには、以下のようにする。\n1 2 3 4 5  x = tensor(1.0, requires_grad=True) y = x**3 grads = torch.autograd.grad(outputs=y, inputs=x, create_graph=True) grads[0].backward() x.grad # yに対するxの2階微分 (tensor(6.))   目的変数yを定義後、torch.autograd.grad関数を使って、1階の勾配を取得する。\nこの関数はoutputsに対するinputsの勾配を計算する関数である。\ncreate_graphをTrueにすることで、微分グラフが構築され、高次の勾配を計算できる。\ninputsは複数のtensor配列をとることができるので、戻り値(grads)はタプルである。\nそのため、中身を[0]で中身を取り出して、backwardメソッドを実行することで、x.gradに2階微分が格納される。\n参考リンク PyTorchの公式リファレンス。\ntorch.Tensor — PyTorch master documentation\nAutomatic differentiation package - torch.autograd — PyTorch master documentation\ntensorクラスの作成方法や、簡単な演算について。\nPytorch Tensorについて - Qiita\n自動微分の基本について。\n【PyTorch入門】第2回 autograd:自動微分 - Qiita\n3階の勾配や、偏導関数を扱っている。\nPyTorchで高階偏微分係数 - Qiita\n","description":"PyTorchのtensorクラスを使った1階微分、2階微分の求め方について解説する。","id":29,"section":"posts","tags":["Python","PyTorch"],"title":"PyTorchの自動微分で勾配を求める","uri":"https://helve2017.github.io/posts/python/pytorch-automatic-differentiation/"},{"content":"はじめに ChainerのVariableクラスを使った自動微分に関する記事である。前回記事の補足として、backwardメソッドを使用するときの注意点と、chainer.grad関数を使った自動微分の計算について述べる。\nbackwardメソッドを使用する度に勾配が加算されるため、2回以上使用するときは、勾配を除去する必要がある。また、chainer.grad関数を使うと、任意のVariable変数間の勾配を計算できる。\n前回記事：Chainerの自動微分で勾配を求める \n環境    ソフトウェア バージョン     Spyder 3.3.3   Python 3.7.3   NumPy 1.16.2   Chainer 6.3.0    以下では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2 3  import numpy as np import chainer from chainer import Variable   backwardメソッドの注意点 chainer.Variableのbackwardを使うと自動微分が計算される。ただし、Chainerの仕様上、backwardを実行するたびに、変数の勾配が加算されてしまう。そのため、2回以上backwardを実行すると、望ましい結果が得られなくなる。\n例：\n$y = 2x$の勾配を計算する。$x=1$に対する勾配は2であるが、2度backwardを実行すると、誤った勾配が出力される。\n1 2 3 4 5 6 7 8 9  \u0026gt;\u0026gt;\u0026gt; x = Variable(np.array([1], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; y = 2*x \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; y.backward() # 1回目の実行 \u0026gt;\u0026gt;\u0026gt; print(x.grad) # 正しい勾配 [2.] \u0026gt;\u0026gt;\u0026gt; y.backward() # 2回目の実行 \u0026gt;\u0026gt;\u0026gt; print(x.grad) # 誤った勾配 [4.]   さらにy.backward()を実行するたびにxの勾配は2ずつ増えていく。すなわち、勾配が蓄積され続けている。\n2回以上backwardを実行しても正しい勾配を得るためには、以下のようにbackwardを実行する度にcleargradで勾配を削除してやる必要がある。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; x = Variable(np.array([1], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; y = 2*x \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; y.backward() # 1回目の実行 \u0026gt;\u0026gt;\u0026gt; print(x.grad) # 正しい勾配 [2.] \u0026gt;\u0026gt;\u0026gt; x.cleargrad() # xの勾配を削除 \u0026gt;\u0026gt;\u0026gt; y.backward() # 2回目の実行 \u0026gt;\u0026gt;\u0026gt; print(x.grad) # 正しい勾配 [2.]   chainer.gradによる勾配計算 chainer.grad関数を使うと、任意のVariable変数間の勾配を計算できる。主な引数を以下に示す。\n1  chainer.grad(outputs, inputs, set_grad=False, retain_grad=False)   引数の説明は以下の通り。\noutputs: (tuple or list of Variable) 逆誤差伝搬の起点となる、出力の変数。\ninputs: (tuple or list of Variable) 勾配を計算する入力側の変数。\nset_grad: bool\nTrueの場合、inputsの変数のgradに勾配が格納される。\nデフォルトはFalse。\nretain_grad: bool\nTrueの場合、中間変数のgradに勾配が格納される。\nデフォルトはFalse。\nchainer.grad関数では、必要最小限の計算パスのみを対象として勾配が計算される。\nなお、backwardと異なり、chainer.gradを何度実行しても勾配は蓄積されず、同じ結果が得られる。\n例：以下の計算グラフを考える。\n実行結果1～5では、全て以下の変数を使用している。\n1 2 3 4  x0 = Variable(np.array([0,1], dtype=np.float32)) x1 = Variable(np.array([2,3], dtype=np.float32)) y = 2*x0 + 3*x1 z = 2*y   実行結果1: zに対するx0の勾配を計算する。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; chainer.grad([z], [x0]) [variable([4., 4.])] \u0026gt;\u0026gt;\u0026gt; print(x0.grad) # set_grad=Falseの時、勾配は残らない None \u0026gt;\u0026gt;\u0026gt; chainer.grad([z], [x0]) # cleargradしなくても同じ結果になる [variable([4., 4.])]   実行結果2: zに対するx0, x1の勾配を計算する。\n1 2  \u0026gt;\u0026gt;\u0026gt; chainer.grad([z], [x0, x1]) [variable([4., 4.]), variable([6., 6.])]   実行結果3: yに対するx0の勾配を計算する。\n1 2  \u0026gt;\u0026gt;\u0026gt; chainer.grad([y], [x0]) [variable([2., 2.])]   実行結果4: gradに勾配を残す\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; chainer.grad([y], [x0], set_grad=True) [variable([4., 4.])] \u0026gt;\u0026gt;\u0026gt; print(x0.grad) array([4., 4.], dtype=float32)   実行結果5: 中間変数yに勾配を残す\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; chainer.grad([y], [x0], retain_grad=True) [variable([4., 4.])] \u0026gt;\u0026gt;\u0026gt; print(y.grad) # 中間変数 array([2., 2.], dtype=float32) \u0026gt;\u0026gt;\u0026gt; print(x0.grad) # 入力変数には勾配は残らない None   ","description":"backwardメソッドを使用するときの注意点と、chainer.grad関数を使った自動微分の計算について述べる。","id":30,"section":"posts","tags":["Python","Chainer"],"title":"Chainerの自動微分で勾配を求める（補足）","uri":"https://helve2017.github.io/posts/python/chainer-automatic-differentiation2/"},{"content":"当サイトのご利用についてご案内します。\n個人情報の利用目的 当サイトでは、コメントの投稿などの際に、名前（ハンドルネーム）、メールアドレス等の個人情報をご登録いただく場合がございます。\n上記の個人情報は、質問に対する回答や必要な情報を電子メールなどをでご連絡する場合に利用させていただくものであり、これらの目的以外では利用いたしません。\n個人情報の第三者への開示 当サイトでは、個人情報を適切に管理し、以下に該当する場合を除き、第三者に開示致しません。\n 本人のご了解を頂いた場合 法令等への協力のため、開示が必要となる場合  個人情報の開示・訂正・追加・削除・利用停止 ご本人からの個人データの開示・訂正・追加・削除・利用停止のご希望の場合には、ご本人であることを確認させていただいた上、速やかに対応させていただきます。\nアクセス解析ツールについて 当サイトは、Googleによるアクセス解析ツール「Googleアナリティクス」を使用しています。\nGoogleアナリティクスは、トラフィックデータを収集するためCookieを使用しています（トラフィックデータは匿名で収集されており、個人を特定するものではありません）。\nCookieを無効にすることで、Googleアナリティクスの機能を無効にしてトラフィックデータの収集を拒否することが出来ますので、お使いのブラウザの設定をご確認ください。\n免責事項 当サイトからリンク等によって他のサイトに移動された場合、移動先サイトで提供される情報、サービス等に対して当サイトは一切の責任を負いません。\nまた、当サイトのコンテンツ・情報につきまして、可能な限り正確を期しておりますが、誤りがあったり、情報が古くなっていることもございます。\n当サイトに記載された内容によって生じた損害等に対し、当サイトは一切の責任を負いかねますのでご了承ください。\nプライバシーポリシーの変更について 当サイトは、個人情報に関して適用される日本の法令を遵守し、本ポリシーの内容を適宜見直しその改善に努めます。\n修正された最新のプライバシーポリシーは常に本ページにて開示致します。\n","description":"Helve Tech Blogについて","id":31,"section":"","tags":null,"title":"About","uri":"https://helve2017.github.io/about/"},{"content":"はじめに 本記事では、ChainerのVariableクラスについて簡単に解説し、1階微分、2階微分の求め方についてまとめる。\n自動微分を使うと、関数の勾配ベクトルを自動的に求めることができるので、勾配を使った最適化手法を容易に行える。\nChainerと最適化 Chainerは、株式会社Preferred Networksが提供しているディープラーニング用のライブラリである。\nChainerには、ニューラルネットワークの学習を高速に行うため、自動微分（定義した関数の勾配を自動で求める）機能が実装されている（この機能を使うことで、損失関数を最小化するために、ニューラルネットワークの各ノードの重みをどの方向に更新すれば良いか分かる）。\n一方、最適化問題を解くとき、最急降下法などの手法では、関数の勾配が必要となる。\n関数の勾配を求めるためには、以下の方法がある。\n 関数の導関数を手計算で求める方法 数値微分（少しだけ変化させた入力変数を与えて出力の差から勾配を求める） 自動微分  問題が複雑な場合、(1)は困難である。\nまた、(2)は計算時間を要する問題がある。\n(3)は、実装に手間が掛かるという欠点があるが、問題ごとに導関数を求める手間も不要で、計算時間も短い利点がある。\nChianerには(3)の機能がVariableというクラスで実装されているので、最適化に活用するため仕様についてまとめた。\nまた、最急降下法のPythonでの実装については、過去記事をご参考まで。\n直線探索を使った最急降下法をPythonで実装\n環境    ソフトウェア バージョン     Spyder 3.3.3   Python 3.7.3   NumPy 1.16.2   Chainer 6.3.0    以下では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2 3  import numpy as np import chainer from chainer import Variable   Variableクラス ChainerのVariableクラスは、数値の配列データを保持するクラスである。\nNumPy配列に近い感覚で扱えるが、相違点もあるので注意。\nVariableオブジェクトは、32ビット精度のNumPy配列を使って作成される。\n例：\n1 2  \u0026gt;\u0026gt;\u0026gt; x0 = Variable(np.array([0, 1], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; x1 = Variable(np.array([[0, 1, 2], [3, 4, 5]], dtype=np.float32))   生成されたオブジェクトは、Variable型の配列である。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; x0 variable([0., 1.]) \u0026gt;\u0026gt;\u0026gt; x1 variable([[0., 1., 2.], [3., 4., 5.]])   Variableオブジェクトでは、同じサイズの配列同士の演算ができる。\n（配列のサイズが異なる場合、NumPyではブロードキャストしてくれるが、Variableオブジェクトはエラーを返す）\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; x0 = Variable(np.array([0, 1], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; x2 = Variable(np.array([2, 3], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; x0+x2 variable([2., 4.])   また、配列のインデックスを指定して、要素を取り出すことも可能である。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; x1 = Variable(np.array([[0, 1, 2], [3, 4, 5]], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; x1[0] variable([0., 1., 2.]) \u0026gt;\u0026gt;\u0026gt; x1[0, 2] variable(2.)   Variableオブジェクトのarray属性から、NumPy配列を取得できる。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; x0 = Variable(np.array([0, 1], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; x0.array array([0., 1.], dtype=float32) \u0026gt;\u0026gt;\u0026gt; type(x0.array) numpy.ndarray   なお、同様にdata属性からもNumPy配列を取得できるが、chainerの公式リファレンスでは「NumPy配列のdata属性」と紛らわしいという理由で、array属性の使用を推奨している。\nVariables and Derivatives — Chainer 7.7.0 documentation\nさらに、Variableオブジェクトのgrad属性から、勾配のNumPy配列を取得できる（詳細は後述）。\n1階微分の求め方 Variableオブジェクトを使った1階微分の求め方について述べる。\nまず、以下の2変数関数を考える。\n$$ f(\\boldsymbol{x}) = 2x_0^2 + x_1^2 + 2x_0 + x_1, \\boldsymbol{x}=[ x_0, x_1 ]^\\mathrm{T} $$\nこの関数の勾配ベクトルは次式で与えられる。\n$$ \\nabla f(\\boldsymbol{x}) = \\left[ \\frac{\\partial f}{\\partial x_0}, \\frac{\\partial f}{\\partial x_1} \\right]^\\mathrm{T} = [4x_0 + 2, 2x_1 + 1 ]^\\mathrm{T} $$\n点$ (x_0, x_1)=(1, 2)$において、関数値と勾配ベクトルはそれぞれ以下のようになる。\n$ f(\\boldsymbol{x})=10 $\n$ \\displaystyle \\nabla f(\\boldsymbol{x}) = [6, 5 ]^\\mathrm{T} $\n上記の関数をVariableを使って記述すると以下のようになる。\n1 2  x = Variable(np.array([1,2], dtype=np.float32)) y = 2*x[0]**2 + x[1]**2 + 2*x[0] + x[1]   関数の値(10)は既に得られている。\n1 2  \u0026gt;\u0026gt;\u0026gt; y variable(10.)   この段階では、勾配はまだ得られておらず、勾配を取得するためには以下を実行する。\n1 2  \u0026gt;\u0026gt;\u0026gt; y.grad = np.ones_like(y.array, dtype=np.float32) \u0026gt;\u0026gt;\u0026gt; y.backward()   まず、yのgradに、値は何でも良いので配列を設定する。\nnp.ones_likeは、引数の配列と同じサイズで、要素が全て1の配列を返す関数である。\n（ただし、厳密にはgradに初期値を与える必要があるのは、yが2つ以上の要素を持つ配列の場合である。\n今回の例のようにyがスカラーの場合は、初期値の設定は省略できる）\n次に、y.backward()メソッドを実行すると、自動微分が実行され、x.gradに勾配が格納される。\n1 2  \u0026gt;\u0026gt;\u0026gt; x.grad array([6., 5.], dtype=float32)   中間変数の勾配を求める場合 上記の方法では、以下のようにVariableオブジェクトの演算を2回以上重ねた場合に、中間の変数の勾配が保存されない。\n1 2 3 4 5 6 7 8  \u0026gt;\u0026gt;\u0026gt; x = Variable(np.array([1], dtype=np.float32)) # 入力 \u0026gt;\u0026gt;\u0026gt; y = x**2 # 中間変数 \u0026gt;\u0026gt;\u0026gt; z = y**2 \u0026gt;\u0026gt;\u0026gt; z.backward() \u0026gt;\u0026gt;\u0026gt; y.grad # 勾配が格納されない (None) \u0026gt;\u0026gt;\u0026gt; x.grad # zに対するxの勾配 array([4.], dtype=float32)   中間の変数の勾配が欲しい場合には、backwardメソッドでretain_grad=Trueとする。\n1 2 3 4 5 6 7 8  \u0026gt;\u0026gt;\u0026gt; x = Variable(np.array([1], dtype=np.float32)) # 入力 \u0026gt;\u0026gt;\u0026gt; y = x**2 # 中間変数 \u0026gt;\u0026gt;\u0026gt; z = y**2 \u0026gt;\u0026gt;\u0026gt; z.backward(retain_grad=True) \u0026gt;\u0026gt;\u0026gt; y.grad # zに対するyの勾配 array([2.], dtype=float32) \u0026gt;\u0026gt;\u0026gt; x.grad # zに対するxの勾配 array([4.], dtype=float32)   2階微分の求め方 2階微分を求めるためには、以下のようにする。\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026gt;\u0026gt;\u0026gt; x = Variable(np.array([1], dtype=np.float32)) \u0026gt;\u0026gt;\u0026gt; y = x**3 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; y.grad = np.ones_like(y.array, dtype=np.float32) \u0026gt;\u0026gt;\u0026gt; y.backward(enable_double_backprop=True) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; gx = x.grad_var \u0026gt;\u0026gt;\u0026gt; x.cleargrad() \u0026gt;\u0026gt;\u0026gt; gx.backward() \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; x.grad # yに対するxの2階微分 array([6.], dtype=float32)   目的関数yのbackwardを実行するまでは同じであるが、\nその後にx.grad_varを取得する。\n次に、cleargradメソッドでxの勾配を削除したのち、\nx.grad_varを格納した変数に対して、backwardを実行すると、\nx.gradに2階微分が格納される。\n参考リンク Variables and Derivatives — Chainer 7.7.0 documentation\nchainer.Variable — Chainer 7.7.0 documentation\nChainerのVariableを使って自動微分を簡単実装 | 自調自考の旅\n","description":"ChainerのVariableクラスを使った1階微分、2階微分の求め方について解説する。","id":32,"section":"posts","tags":["Python","Chainer"],"title":"Chainerの自動微分で勾配を求める","uri":"https://helve2017.github.io/posts/python/chainer-automatic-differentiation/"},{"content":"はじめに 本記事では、最急降下法と、Armijo条件と呼ばれる直線探索手法について簡単に解説する。\n数理工学社の「工学基礎　最適化とその応用」（矢部博 著）を読んだので、4章「非線形計画法I（無制約最小化問題）」から、直線探索を使った最急降下法をPythonで実装した。\n最急降下法とは勾配を用いる最適化手法の1つであり、最急降下法で解の更新幅を求める手法を直線探索という。\n本記事では、これらについて簡単に解説し、Pythonで実装したコードを示す。\n最後に、実装したコードを使って、簡単な2変数関数を最小化する。\nまた、以降ではライブラリを次のようにインポートしていることを前提とする。\n1 2  import numpy as np import matplotlib.pyplot as plt   バージョンは以下の通り。\n   ソフトウェア バージョン     python 3.7.4   numpy 1.16.4   matplotlib 3.1.0    最急降下法 最急降下法 (gradient descent, または steepest descent) は、数値最適化手法の1つであり、関数の勾配の方向に解を更新して、最適解に収束させようとするものである。\nまず、$n$次元ベクトル$\\boldsymbol{x} \\in \\mathbb{R}^n$の関数$f(\\boldsymbol{x}) \\in \\mathbb{R}$を最小化する問題を考える。\n$f(\\boldsymbol{x})$は微分可能であり、勾配ベクトルは次式で表されるとする。\n$$ \\nabla f(\\boldsymbol{x}) = \\left[ \\frac{\\partial f}{\\partial x_1}, \u0026hellip;, \\frac{\\partial f}{\\partial x_n} \\right]^\\mathrm{T} \\in \\mathbb{R}^n $$\n次に、最急降下法のアルゴリズムについて述べる。\n 反復回数を$ k=0$として、解の初期値$\\boldsymbol{x_k}$を与える。 終了条件を満たせば最適解を$\\boldsymbol{x_k}$として終了する。そうでなければ、$\\boldsymbol{x_k}$における勾配$ \\nabla f(\\boldsymbol{x_k})$を求める。 解の探索方向を$ \\boldsymbol{d_k} = -\\nabla f(\\boldsymbol{x_k})$とする。 探索方向のステップ幅$ \\alpha_k$を直線探索により求め、新たな解を$ \\boldsymbol{x_{k+1}} = \\boldsymbol{x_k} + \\alpha_k \\boldsymbol{d_k}$と更新する。 $ k \\leftarrow k+1$として、2に戻る。  下図は2変数関数における勾配降下法のイメージである。\n等高線は関数の値を示し、$ (x_1, x_2)=(0, 0)$で最小値をとる。\n解候補の点$\\boldsymbol{x_k}$における探索方向$ \\boldsymbol{d_k}$は、勾配が最も急な方向（等高線と垂直な方向）となる。\n最急降下法には、ステップ幅$ \\alpha_k$が大きすぎると解が発散し、小さすぎると収束が遅くなる問題がある。\nこの問題に対処できるように$ \\alpha_k$を決める手法が、次節の直線探索である。\n直線探索 直線探索 (line search) は、最急降下法や準ニュートン法などの最適化手法において得られた解の探索方向に対して、適切な更新幅を求める手法である。\n解を大域的に収束させることが求められる。\n実用的な直線探索手法としてArmijo（アルミホ）条件とWolf（ウルフ）条件があり、本記事では前者のみ扱う。\nArmijo条件とは、$ 0\u0026lt;\\xi\u0026lt;1$である定数$\\xi$に対して、\n$ f(\\boldsymbol{x_k}+\\alpha \\boldsymbol{d_k}) \\leq f(\\boldsymbol{x_k}) + \\xi \\alpha \\nabla f(\\boldsymbol{x_k})^\\mathrm{T} \\boldsymbol{d_k}$\nを満たす$ \\alpha \u0026gt; 0$を選ぶものである。\n下図にArmijo条件を幾何的に示す。\n関数$ y=f(\\boldsymbol{x_k}+\\alpha \\boldsymbol{d_k})$は$ \\boldsymbol{d_k}$方向の目的関数である。\nArmijo条件を満たす$\\alpha$とは、目的関数$ y=f(\\boldsymbol{x_k}+\\alpha \\boldsymbol{d_k})$が、直線$ f(\\boldsymbol{x_k}) + \\xi \\alpha \\nabla f(\\boldsymbol{x_k})^\\mathrm{T} \\boldsymbol{d_k}$よりも小さい区間にある。\nなお、$ \\xi=0$のとき、直線の値は$ f(\\boldsymbol{x_k})$と等しくなるので解の収束が保障されなくなる。\nまた、$ \\xi=1$のとき、直線は接線$ y=f(\\boldsymbol{x_k}) + \\alpha \\nabla f(\\boldsymbol{x_k})^\\mathrm{T} \\boldsymbol{d_k}$と一致するので$ \\alpha=0$となり、解の更新幅が0になる。\nArmijo条件を満たすステップ幅$ \\alpha_k$を得るアルゴリズムは、以下の通り。\n パラメータ$ 0\u0026lt;\\xi\u0026lt;1, 0\u0026lt;\\tau\u0026lt;1$を与える。 更新幅の初期値を$ \\alpha=1$とおく。 $ \\alpha$がArmijo条件を満たすならば終了。 満たさなければ$ \\alpha \\leftarrow \\tau \\alpha$と更新して3に戻る。  上記のアルゴリズムでは、初めにある程度大きなステップ幅を与え、Armijo条件を満たすまで徐々に小さくしている。そのため、有限回の反復でArmijo条件を満たすステップ幅が得られることが保証される。\nPythonによる実装 Armijo条件を用いた最急降下法をPythonで実装した。\nfunに目的関数、derに勾配を返す関数を与える。また、minimizeメソッドにxを初期値として与えると、最急降下法を実行する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  class GradientDescent: def __init__(self, fun, der, xi=0.3, tau=0.9, tol=1e-6, ite_max=2000): self.fun = fun # 目的関数 self.der = der # 関数の勾配 self.xi = xi # Armijo条件の定数 self.tau = tau # 方向微係数の学習率 self.tol = tol # 勾配ベクトルのL2ノルムがこの値より小さくなると計算を停止 self.path = None # 解の点列 self.ite_max = ite_max # 最大反復回数 def minimize(self, x): path = [x] for i in range(self.ite_max): grad = self.der(x) if np.linalg.norm(grad, ord=2)\u0026lt;self.tol: break else: beta = 1 while self.fun(x - beta*grad) \u0026gt; (self.fun(x) - self.xi*beta*np.dot(grad, grad)): # Armijo条件を満たすまでループする beta = self.tau*beta x = x - beta * grad path.append(x) self.opt_x = x # 最適解 self.opt_result = self.fun(x) # 関数の最小値 self.path = np.array(path) # 探索解の推移   最適化の例 次式の2変数関数を最小化する例を示す。\n$$ f(\\boldsymbol{x}) = 2x_1^2 + x_2^2 + x_1 x_2, (\\boldsymbol{x}=[ x_1, x_2 ]^\\mathrm{T}) $$\nこの関数は、$ (x_1, x_2)=(0, 0)$で最小値0をとる。\nまた、勾配ベクトルは次式で与えられる。\n$$ \\nabla f(\\boldsymbol{x}) = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\right]^\\mathrm{T} = [4x_1 + x_2, x_1 + 2x_2 ]^\\mathrm{T} $$\n関数値と勾配を求める関数を、それぞれf(x), f_der(x)として定義する。\n1 2 3 4 5  def f(x): return 2*x[0]**2 + x[1]**2 + x[0]*x[1] def f_der(x): return np.array([4*x[0] + x[1], x[0] + 2*x[1]])   関数の等高線をプロットする。\n1 2 3 4 5 6 7 8 9 10 11  x1 = np.linspace(-2, 2, 21) x2 = np.linspace(-2, 2, 21) x1_mesh, x2_mesh = np.meshgrid(x1, x2) z = f(np.array((x1_mesh, x2_mesh))) fig, ax = plt.subplots(figsize=(6, 6)) ax.contour(x1, x2, z, levels=np.logspace(-0.3, 1.2, 10)) ax.set_xlabel(\u0026#34;x1\u0026#34;) ax.set_ylabel(\u0026#34;x2\u0026#34;) ax.set_aspect(\u0026#39;equal\u0026#39;) plt.show()   また、勾配をプロットする。\n1 2 3 4 5 6 7 8 9 10 11 12  x1 = np.linspace(-2, 2, 21) x2 = np.linspace(-2, 2, 21) x1_mesh, x2_mesh = np.meshgrid(x1, x2) grad = f_der(np.array((x1_mesh, x2_mesh))) U = grad[0] # x1方向の勾配 V = grad[1] # x2方向の勾配 fig, ax = plt.subplots(figsize=(6, 6)) ax.quiver(x1, x2, U, V, color=\u0026#39;blue\u0026#39;) ax.set_aspect(\u0026#39;equal\u0026#39;) plt.show()   前節のGradientDescentクラスを用いて、最急降下法を実行する。\n初期値は$ (x_1, x_2)=(1.5, 1.5)$とする。\n1 2 3  gd = GradientDescent(f, f_der) init = np.array([1.5, 1.5]) gd.minimize(init)   解の推移をプロットする。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  path = gd.path x1 = np.linspace(-2, 2, 21) x2 = np.linspace(-2, 2, 21) x1_mesh, x2_mesh = np.meshgrid(x1, x2) z = f(np.array((x1_mesh, x2_mesh))) fig, ax = plt.subplots(figsize=(6, 6)) ax.contour(x1, x2, z, levels=np.logspace(-0.3, 1.2, 10)) ax.plot(path[:,0], path[:,1], marker=\u0026#34;o\u0026#34;) ax.set_xlabel(\u0026#34;x1\u0026#34;) ax.set_ylabel(\u0026#34;x2\u0026#34;) ax.set_aspect(\u0026#39;equal\u0026#39;) plt.show()   発散せずに最適解へ収束しており、Armijo条件を用いた直線探索がうまく機能していることが分かる。\n参考 以下のページにステップ幅を固定した最急降下法のコードがあり、実装のベースにさせて頂いた。\n最急降下法の概要 - Qiita\n","description":"最急降下法と直線探索手法を解説し、Pythonで実装する。","id":33,"section":"posts","tags":["最適化"],"title":"直線探索を使った最急降下法をPythonで実装","uri":"https://helve2017.github.io/posts/math/gradient-descent-armijo/"},{"content":"はじめに 次元削減 (dimensionality reduction) とは、データの構造をなるべく保ったまま、特徴量の数を減らすことである。\n特徴量の数を減らすことにより、機械学習を高速に実行できたり、データの可視化をしやすくなる利点がある。\n次元削減には、射影と多様体学習という2つの主なアプローチがある。射影を使った手法としては、主成分分析 (PCA, Principal Components Analysis) が有名である。一方、本記事で扱うLLEは、多様体学習と呼ばれるアプローチに属する。\n多様体 多様体 (manifold) とは、簡単に表すと、局所的に低次元の超平面と見なせる図形のことである。\n例えば、以下に示すSwiss Rollは、3次元空間のデータであるが、局所的には2次元の平面と見なせる。\nすなわち、データから2次元平面をうまく見つけることができれば、構造を保ったまま3次元から2次元に圧縮できる。\nこのように、多様体のモデルを見つけることを多様体学習と呼ぶ。多様体学習には以下のように様々な手法がある。\n LLE 多次元尺度法 (multi-dimensional scaling, MDS) Isomap t-SNE (t-distributed Stochastic Neighbor Embedding) UMAP (Uniform Manifold Approximation and Projection)  LLEには大域的な位置関係を保存できる長所がある一方、以下の短所もある。\n 多様体が複数ある場合、互いの位置関係をうまく保存できない。 圧縮後のデータ位置を再構成する計算量がデータ数の2乗に比例するため、大規模なデータに適用しづらい。  LLEアルゴリズム LLEのアルゴリズムは、2つのステップでデータ間の局所的な線形モデルを構築し、次元を削減する。\n 局所的な関係の線形モデル化 関係を維持した次元削減  局所的な関係の線形モデル化 まず、データの各インスタンスに対して、近傍にあるk点のインスタンスを探し、それらインスタンスの線形結合で表すことを考える。ただし、kはハイパーパラメータである。\n例として、下図のように2次元空間において5つの点A～Eが与えられた場合に、点Cを近傍インスタンスの線形和として表すことを考える。\nk=2とすると、点Cの近傍インスタンスは点B, Dである。\nまた、点B, C, Dの位置は$\\boldsymbol{x^{(B)}, x^{(C)}, x^{(D)}}$で与えられるとする。\n次に、$\\boldsymbol{x^{(B)}, x^{(D)}}$の線形結合として次式を考える。\n$w_{C, B}\\boldsymbol{x^{(B)}} + w_{C, D}\\boldsymbol{x^{(D)}}$\nただし、$w_{C, B}, w_{C, D}$は点Cに対する点B, Dの重み係数である。\nまた、\n$w_{C, B}+w_{C, D}=1$\nである。\nさらに、点Cを点B, Dの線形結合で近似するため、次式が最小となる$w_{C, B}, w_{C, D}$を求める。\n$\\boldsymbol{x^{(C)}} - (w_{C, B}\\boldsymbol{x^{(B)}} + w_{C, D}\\boldsymbol{x^{(D)}})$\n$\\mathrm{subject\\ to\\ } w_{C, B}+w_{C, D}=1$\n下図は、上記の考えを幾何的に示したものである。\n図の点B, Dを結ぶ破線は、$\\boldsymbol{x^{(B)}, x^{(D)}}$の線形結合を表す。\nまた、求める係数$w_{C, B}, w_{C, D}$は、\n$w_{C, B}\\boldsymbol{x^{(B)}} + w_{C, D}\\boldsymbol{x^{(D)}}$\nと、\n$\\boldsymbol{x^{(C)}}$\nの距離を最小とする値となる。\n以上、ある点に対する線形モデル化を示したが、全ての点に対して一般化した式を示す。\nインスタンスの数を$N$として、重み係数を行列$W\\in\\mathbb{R}^{N\\times N}$にまとめる。\n重み係数$w_{i,j}$を$W$の$(i,j)$成分とする。\nこのとき、線形モデル化とは、次式を最小化する重み行列$W$を求める問題となる。\n$$ \\sum_{i=1}^{N} \\left( \\boldsymbol{x^{(i)}} - \\sum_{j=1}^{N} w_{i,j} \\boldsymbol{x^{(j)}} \\right)^2$$\n$$ \\mathrm{subject\\ to\\ } \\begin{cases} \\sum_{j=1}^{N} w_{i,j} = 1 \u0026amp; (\\mathrm{for\\ } i=1,2,\u0026hellip;,N) \\\\ w_{i,j} = 0 \u0026amp; (\\boldsymbol{x^{(j)}} が \\boldsymbol{x^{(i)}} の近傍点ではない) \\end{cases} $$\n関係を維持した次元削減 前節で得られた重み行列$W$を用いて、データの局所的な関係をなるべく維持できるように、圧縮後の次元におけるインスタンスの位置を求める。\n圧縮後のインスタンスの位置を$\\boldsymbol{y^{(i)} (i=1,2,\u0026hellip;,N)}$とする。\nただし、$\\boldsymbol{y^{(i)}}$の次元は$\\boldsymbol{x^{(i)}}$の次元より小さくなければならない。\nこのとき、$\\boldsymbol{y^{(i)}}$は次式を最小化する値として得られる。\n$$ \\sum_{i=1}^{N} \\left( \\boldsymbol{y^{(i)}} - \\sum_{j=1}^{N} w_{i,j} \\boldsymbol{y^{(j)}} \\right)^2 $$\n先程の例の続きで説明する。\n2次元空間上の点B, C, Dの位置$\\boldsymbol{x^{(B)}, x^{(C)}, x^{(D)}}$を1次元空間に圧縮するものとして、圧縮後の位置を$\\boldsymbol{y^{(B)}, y^{(C)}, y^{(D)}}$とする。\n得られた重み係数$w_{C, B}, w_{C, D}$を用いると、$\\boldsymbol{y^{(B)}}$の最適な位置は次式で与えられる（下図参照）。\n$$ w_{C, B}\\boldsymbol{y^{(B)}} + w_{C, D}\\boldsymbol{y^{(D)}} $$\n参考 LLEについて、以下のウェブサイトを参考にさせて頂いた。\n【多様体学習】LLEとちょっとT-SNE - HELLO CYBERNETICS\n","description":"非線形データを対象とする次元削減手法であるLLE (Locally Linear Embedding) について解説する。","id":34,"section":"posts","tags":["次元削減"],"title":"LLE (Locally Linear Embedding) による非線形データの次元削減","uri":"https://helve2017.github.io/posts/math/locally-linear-embedding/"},{"content":"はじめに 説明変数が2つ以上ある回帰モデル（重回帰モデル）を作成するとき、相関が強い説明変数があると、推定結果が不安定になる。この問題は多重共線性、あるいは英語のmulti-collinearityからマルチコと呼ばれる。\n本記事では、多重共線性が生じる原因について、数学的な厳密さを省いて直観的に説明する。\n多重共線性が発生する原因 3つの変数$x_1, x_2, x_3$を用いて、変数$y$を予測する重回帰モデルを考える。\nすなわち、回帰式は以下で表される。\n$ y=ax_1+bx_2+cx_3+d$\nただし、$a, b, c$は回帰係数、$d$は定数項である。\n次に、データが下図のように与えられたとする。\n図より、$y$は$x_1$と相関が高い一方で、$y$は$x_2, x_3$との相関は非常に低い。\nすなわち、$y$の変化は$x_1$によってほぼ説明できる。\n$y$の変化と$x_1$の変化は1:1であるので、回帰係数$a$は1である。\n問題となるのは、相関の高い$x_2, x_3$の回帰係数$b, c$である。$x_2$の変化を$x_3$により打ち消せれば$b, c$の値は何でも良いので、$(b, c)=(1, -1)$でも、極端な話、$(b, c)=(100, -100)$でも良い。\nすなわち、以下の回帰式が得られることもあり得る。\n$ y= x_1+ 100 x_2 - 100 x_3$\n（簡単のため、定数項は無視した）\nこのような係数が大きい回帰式を用いてしまうと、$x_2$または$x_3$にノイズが入った場合、$y$の推定値が非常に大きく変化してしまう。\n以上が、多重共線性により重回帰モデルの推定結果が不安定になる原因である。\n多重共線性への対策 多重共線性への対策として正則化 (regularization) が挙げられる。正則化とは係数の大きさに対して罰則を加え、係数の絶対値をなるべく小さくする方法である。\nすなわち、上記の例では係数$b, c$をともに0に近づけて、推定結果を安定させることができる。\n正則化の方法にはいくつか種類があり、リッジ (Ridge) 回帰、ラッソ (Lasso) 回帰、Elastic Netと呼ばれるモデルが良く用いられる。\nこれらのモデルはscikit-learnに実装されており、以下の記事で使い方を解説している。\nScikit-learnの正則化付き重回帰モデル\n","description":"重回帰モデルで多重共線性が生じる原因を直観的に説明する。","id":35,"section":"posts","tags":["統計学"],"title":"多重共線性（マルチコ）の直観的説明","uri":"https://helve2017.github.io/posts/math/multi-collinearity/"},{"content":"はじめに 前回の記事でscikit-learnのBaggingClassifierクラスについて解説したため、本記事では実際の使用例を示す。\n基本的な使い方と、分類確率を出力する方法、warm startによる追加学習について示す。\n前回の記事：\nscikit-learnのBaggingClassifierでバギングする\n本記事では、ライブラリを以下の通りインポートしていることを前提とする。\n1 2 3 4 5  import pandas as pd from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import BaggingClassifier   また、ライブラリのバージョンは以下の通りである。\n   ソフトウェア バージョン     pandas 0.25.0   scikit-learn 0.21.3    使用するデータ Irisデータセットを例として使用する。このデータセットは3種類の品種のアヤメを分類する問題である。\nまず、scikit-learnに付属しているデータを読み込む。\n1 2 3  data = load_iris() X = pd.DataFrame(data.data, columns=data.feature_names) # 説明変数 y = pd.Series(data.target) # 目的変数   次に、train_test_split関数を用いてデータを学習用 (train) と検証用 (val) に分割する。\n1  X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=0)   基本的な使い方 BaggingClassifierのbase_estimatorに弱学習器オブジェクトをセットするだけである。\n今回、弱学習器は決定木 (DecisionTreeClassifier) とした。\n学習と予測には、通常の分類器と同様にfitメソッドとpredictメソッドを用いる。\n1 2 3 4 5  base_clf = DecisionTreeClassifier(random_state=0) clf = BaggingClassifier(base_estimator=base_clf) clf.fit(X_train, y_train) bc_pred = clf.predict(X_val)   また、BaggingClassifierのパラメータを設定した例を以下に示す。\n1 2 3 4 5  clf1 = BaggingClassifier(base_estimator=base_clf, max_samples=0.5, n_estimators=40, random_state=0, n_jobs=-1)   パラメータの意味は次の通り。\n max_samples=0.5: 弱学習器1個当りの学習サンプル数をfitで与えたデータの50%とする。 n_estimators=40: 弱学習器の数を40にする。 random_state=0: 乱数シードを設定する。 n_jobs=-1: CPUの全コアを使って並列計算する。  分類確率を示す 検証インスタンスが各クラスに含まれる確率を出力したい場合は、predict_probaメソッドを使う。\n弱学習器にpredict_probaメソッドが実装されている場合、各弱学習器が出力した確率の平均が返される。\n一方、実装されていない場合、弱学習器が出力した分類結果の比率が返される。\n1 2  pred_proba = clf.predict_proba(X_val) print(pred_proba)   実行結果\n1 2 3 4 5 6 7 8 9 10 11  [[0. 0. 1. ] [0. 0.9 0.1] [1. 0. 0. ] [0. 0. 1. ] （中略） [0. 0.1 0.9] [1. 0. 0. ] [1. 0. 0. ] [0. 1. 0. ] [0. 1. 0. ] [1. 0. 0. ]]   弱学習器を追加して学習する BaggingClassifierのwarm_startを設定すると、追加した弱学習器のみを再学習することができる。\n例えば、グリッドサーチで弱学習器の数をチューニングしたい場合に計算時間を短縮できる。\n以下の例では、最初に弱学習器の数を10として学習した後、set_paramsメソッドで20にして、追加した10個の弱学習のみ学習させている。\n1 2 3 4 5 6 7  base_clf = DecisionTreeClassifier(random_state=0) clf = BaggingClassifier(base_estimator=base_clf, n_estimators=10, warm_start=True) clf.fit(X_train, y_train) clf.set_params(n_estimators=20) # 弱学習器の数を追加する clf.fit(X_train, y_train) # 追加した弱学習器のみ学習させる   実際に計算時間を比較する（IPythonで実行）。\n・追加で学習させる場合（1回の実行で20個の決定木を学習させる）。\n1 2 3 4 5 6 7 8 9 10  def warm_start(): base_clf = DecisionTreeClassifier(random_state=0) clf = BaggingClassifier(base_estimator=base_clf, n_estimators=10, warm_start=True) clf.fit(X_train, y_train) clf.set_params(n_estimators=20) clf.fit(X_train, y_train) %timeit warm_start()   実行結果\n1  17.8 ms ± 198 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)   ・別途学習させる場合（1回の実行で30個の決定木を学習させる）。\n1 2 3 4 5 6 7 8 9 10  def cold_start(): base_clf = DecisionTreeClassifier(random_state=0) clf = BaggingClassifier(base_estimator=base_clf, n_estimators=10) clf.fit(X_train, y_train) clf = BaggingClassifier(base_estimator=base_clf, n_estimators=20) clf.fit(X_train, y_train) %timeit cold_start()   実行結果\n1  25.4 ms ± 2.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)   計算時間は、追加学習した場合は17.8ms, 別途学習した場合は25.4msであった。\n17.8ms÷25.4ms=70.1%であるから、計算時間は学習した弱学習器（決定木）の数にほぼ比例している。\nしたがって、追加した弱学習器のみ学習させることで計算時間を短縮できることが示された。\n参考 sklearn.ensemble.BaggingClassifier — scikit-learn 0.24.0 documentation\n","description":"BaggingClassifierクラスの使用例を示す。","id":36,"section":"posts","tags":["Python","Scikit-learn"],"title":"BaggingClassifierの使用例","uri":"https://helve2017.github.io/posts/python/sklearn-bagging-classifier-example/"},{"content":"はじめに scikit-learnには、アンサンブル学習を行うためのBaggingClassifierが実装されている。\n本記事では、BaggingClassifierを用いた学習（バギング、ペースティング、ランダムサブスペース、ランダムパッチ）について解説する。\n環境 scikit-learn 0.21.3\nアンサンブル学習 アンサンブル学習は、複数の予測器（分類器や回帰器など）の予測結果を1つにまとめる手法である。アンサンブル学習には様々な手法があり、代表的なものを以下に示す。\n バギング：予測器ごとにランダムに選んだデータで学習させる。 ブースティング：逐次的に予測器を構築し、直前の予測器の誤差を修正するように学習させる。 スタッキング：複数の予測器の結果をまとめる予測器（メタ学習器）を用いる。  上記の手法は、完全に分類できるものではない。例えば、バギングで学習させた予測器の結果を、スタッキングでまとめることも可能である。\n本記事ではバギングおよび、それに類似する手法を扱う。\nBaggingClassifierを用いると、これらの手法を簡単に実装できる。\nバギング (bagging) に近い手法として、ペースティング (pasting)、ランダムサブスペース (random subspace)、ランダムパッチ (random patche) がある。\n各手法の違いを下表に示す。\n   手法 学習インスタンスの選択 特徴量の選択     バギング 重複ありランダムサンプリング 全て選択   ペースティング 重複なしランダムサンプリング 全て選択   ランダムサブスペース 全て選択 重複ありランダムサンプリング   ランダムパッチ 重複なしランダムサンプリング 重複なしランダムサンプリング    バギングでは学習インスタンスのサンプリングが重複ありで行われ、ペースティングでは重複なしで行われる。すなわち、バギングでは、同じ予測器に対して同じ学習インスタンスが複数回選ばれることがあり得る。\n一方、ペースティングでは同じ予測器は異なる学習インスタンスしか選ばれない。\nランダムサブスペースでは、特徴量の方向に、重複ありのランダムサンプリングを行う。この手法が有効なのは、以下のような場合である。\n 元データの特徴量が非常に多い 特徴量の数の2乗や3乗に比例して、予測器の計算負荷が増加する  ランダムパッチでは、学習インスタンスと特徴量の両方に対して、重複なしのランダムサンプリングを行う。\n各手法を実装するには、後述のBaggingClassifierのパラメータを下表のように設定する。\n    bootstrap max_samples bootstrap_features max_features     バギング True 1.0未満 False 1.0   ペースティング False 1.0未満 False 1.0   ランダムサブスペース False 1.0 True 1.0未満   ランダムパッチ False 1.0未満 False 1.0未満    BaggingClassifierクラスについて 前述の通り、scikit-learnに実装されているBaggingClassifierを用いると、バギング等を簡単に実装できる。\n1 2 3 4 5  BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)   引数 BaggingClassifierの引数の解説は以下の通り。\nbase_estimator: object or None\nバギング等を行う予測器のオブジェクト。Noneの場合は、決定木 (decision tree) となる。デフォルトはNone.\nn_estimators: int\n予測器の数。デフォルトは10。\nmax_samples: int or float\n個々の予測器に与える最大のインスタンス数。intの場合、最大インスタンス数そのものになる。floatの場合、データXのインスタンス数にmax_samplesを掛けた数になる。デフォルトは1.0。\nmax_features: int or float\n個々の予測器に与える最大の特徴量の数。intの場合、最大特徴量数そのものになる。floatの場合、データXの特徴量数にmax_featuresを掛けた数になる。デフォルトは1.0。\nbootstrap: boolean\nTrueの場合、個々の予測器に与える学習インスタンスの重複を許す。Falseの場合、学習インスタンスの重複を許さない。デフォルトはTrue.\nbootstrap_features: boolean\nTrueの場合、個々の予測器に与える特徴量の重複を許す。Falseの場合、特徴量の重複を許さない。デフォルトはFalse。\noob_score: boolean\nTrueの場合、OOB (out-of-bag) スコアを計算する。\nバギング (bagging) では個々の予測器の学習用インスタンスを重複ありサンプリングするため、\nそれぞれの学習器に対して、学習に用いられないインスタンスがある。これをOOBインスタンスと呼ぶ。\n各予測器のOOBインスタンスに対する予測精度を計算して平均すると、アンサンブル自体の予測精度を検証することができる。これがOOBスコアである。\nなお、oob_scoreで計算される「精度」は正解率 (Accuracy) であり、sklearn.metrics.accuracy_scoreと等価である。\nデフォルトはFalse。\nwarm_start: boolian\nTrueの場合、fitメソッドによる学習時に、以前の予測器を維持したまま、新たな予測器を追加する。例えば、グリッドサーチで予測器の数を増やしながら精度変化を検証したい場合に、追加の予測モデルのみ学習させれば良いので、計算時間を短縮できる。ただし、2回目以降のfitの前に、set_paramsメソッドでn_estimatorsの数を増やす必要がある。\nFalseの場合、fitメソッドを使う度に学習結果がリセットされ、0から学習が行われる。\nデフォルトはFalse。\nn_jobs: int or None\nintで並列計算数を指定する。-1の場合、CPUの全プロセッサを使用する。Noneの場合、プロセッサを1つだけ使用する。デフォルトはNone。\nrandom_state： int, RandomState instance or None\n乱数シードを指定する。デフォルトはNone。\nverbose: int\n学習時と予測時に、状況を表示するか設定する。数値が大きいほど詳細に表示される。\nversion 0.21.2では、0～2が有効である。デフォルトは0（表示しない）。\n変数 BaggingClassifierクラスのメンバ変数は以下の通り。\nbase_estimator_ : estimator\n予測器のオブジェクト。\nestimators_ : list of estimators\n学習した予測器オブジェクトのリスト。\nestimators_samples_ : list of arrays\n各予測器の学習に使用されたインスタンスの番号。\nestimators_features_ : list of arrays\n各予測器の学習に使用された特徴量の番号。\nclasses_ : array of shape = [n_classes]\n予測クラスのラベル\nn_classes_ : int or list\n予測クラスの数。\noob_score_ : float\nOOBスコア\noob_decision_function_ : array of shape = [n_samples, n_classes]\n学習データ中のOOBインスタンスが、どのクラスに分類されたかを表す配列。\nn_estimatorsの数が小さい場合は、oob_decision_function_にNaNが含まれる場合がある。\noob_scoreがTrueの場合に有効。\nメソッド BaggingClassifierクラスの主なメソッドは以下の通り。\nfit(X, y)\nXを説明変数、yを目的変数として学習する。\npredict(X)\n説明変数Xのクラスを予測する。\npredict_proba(X)\nXのインスタンスが各クラスに属する確率を出力する。\npredict_log_proba(X)\nXのインスタンスが各クラスに属する確率の対数を出力する。\nset_params(**params)\nBaggingClassifierオブジェクトのパラメータを変更する。\n参考 sklearn.ensemble.BaggingClassifier — scikit-learn 0.24.0 documentation\n","description":"BaggingClassifierを用いた学習（バギング、ペースティング、ランダムサブスペース、ランダムパッチ）について解説する。","id":37,"section":"posts","tags":["Python","Scikit-learn"],"title":"scikit-learnのBaggingClassifierでバギングする","uri":"https://helve2017.github.io/posts/python/sklearn-bagging-classifier/"},{"content":"はじめに Pythonの機械学習ライブラリScikit-learnに実装されている主成分分析のクラスを調べた。\n本記事では、PCAクラスのパラメータ、属性とメソッドについて解説する。\n主成分分析 (PCA, Principal Component Analysis)とは、データの分散をなるべく維持しつつ、データの次元を減らす手法である。\n主成分分析について解説しているサイトは多数あるため、ここでは説明を省略する。\n環境 Scikit-learn 0.20.3\n主成分分析のクラス Scikit-learnには、主成分分析はPCAというクラスで実装されている。\n1 2 3  sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False, svd_solver=\u0026#39;auto\u0026#39;, tol=0.0, iterated_power=\u0026#39;auto\u0026#39;, random_state=None)   以下、パラメータ、メソッド、属性を解説する。\nパラメータ パラメータの説明は以下の通り。\nn_components: int, float, None or string\n整数を指定すると、圧縮後の次元数になる。\nソルバがfullのとき、0～1の小数の指定が可能であり、n_componentsの割合で分散を維持できるだけの最小の次元数が自動で選ばれる。\nまた、デフォルトのNoneでは、fitメソッドに与えるデータの、サンプル数と次元数の小さい値が選ばれる。\ncopy: bool\nFalseならば、fitやfit_transformで変換するデータを上書きする（デフォルト値はTrue）。\nwhiten: bool\nTrueならば、白色化とよばれる、変数間の相関をなくす処理を行う（デフォルト値はFalse）。詳細は以下のページを参照。\n無相関化と白色化の意味と式 - 具体例で学ぶ数学\nsvd_solver : string\n特異値分解のソルバを選ぶ。\n\u0026lsquo;auto\u0026rsquo;, \u0026lsquo;full\u0026rsquo;, \u0026lsquo;arpack\u0026rsquo;, \u0026lsquo;randomized\u0026rsquo;の4つから選択できる。\u0026lsquo;full\u0026rsquo;と\u0026rsquo;arpack\u0026rsquo;は厳密解である。\u0026lsquo;randomized\u0026rsquo;は近似解であるが、データ数や入力次元が非常に多い場合は非常に高速である。\n各ソルバの計算速度等は、以下のページが詳しい。\n【python】sklearnのPCAでsvd_solverによる速度差を比較 - 静かなる名辞\ntol: float\u0026gt;= 0\nsvd_solverが'arpack'のとき、固有値の許容精度を指定する。\niterated_power: int\u0026gt;=0\nsvd_solverが'randomized'のときの計算反復回数を指定する。\nrandom_state: int, RandomState instance or None\n乱数シード。\nsvd_solverが'arpack'または'randomized'のときに使われる。\nメソッド 主なメソッドの説明は以下の通り。\nfit(X)\nPCAをあてはめる。\nXはサンプル数×特徴量数の2次元配列。\nfit_transform(X)\nPCAをあてはめて変換する。\n戻り値はサンプル数×n_componentsの2次元配列。\ntransform(X)\nfitやfit_transformで定義したPCAの変換を行う。\n戻り値はサンプル数×n_componentsの2次元配列。\ninverse_transform(X)\nPCAの逆変換を行う。\nXはサンプル数×n_componentsの2次元配列。\n戻り値はサンプル数×特徴量数の2次元配列。\n属性 PCAクラスの主な属性は以下の通り。\ncomponents_: (n_components)×(元の特徴量数)の2次元配列。\n元の行列をXとすると、transformメソッドは以下の変換に等しい。\n1  np.dot(X-X.mean(axis=0), PCA.components_)   すなわち、Xの平均を0として、n_componentsとの内積をとる。\nexplained_variance_ratio_:\n個々の主成分の因子寄与率を表す、長さn_componentsの1次元配列。\n因子寄与率とは、データ全体の分散に対する個々の主成分の分散の割合である。\nn_componentsをNoneとして全ての主成分を保存している場合、explained_variance_ratio_の合計は1になる。\n参考 sklearn.decomposition.PCA — scikit-learn 0.24.0 documentation\n","description":"Scikit-learnのPCAクラスのパラメータ、属性とメソッドについて解説する。","id":38,"section":"posts","tags":["Python","Scikit-learn"],"title":"Scikit-learnの主成分分析 (PCA)","uri":"https://helve2017.github.io/posts/python/sklearn-pca/"},{"content":"はじめに Pythonの機械学習ライブラリScikit-learnに実装されている重回帰モデルを調べた。\n通常の線形回帰に、回帰係数を正則化するRidge回帰、Lasso回帰、Elastic Netを加えた4種類の回帰モデルの基本的なロジックと使用方法をまとめた。\n通常の重回帰モデルは次式で表される。\n$ \\hat{y} = w_0 + w_1x_1 + w_2x_2 + \u0026hellip; + w_nx_n$\nここで、$\\hat{y}$は予測値、$w_0, w_1, \u0026hellip;, w_n$は回帰係数、$x_1, \u0026hellip;, x_n$は説明変数である。\nさらに、回帰係数と説明変数をそれぞれベクトル$\\boldsymbol{w, x}$として次式で表す。\n$ \\hat{y} = \\boldsymbol{w}^T \\boldsymbol{x}$\nここで、$\\boldsymbol{x}$は$x_0$から$x_n$を含み、$x_0$は常に1である。\n通常の重回帰モデルでは、説明変数$y$と予測値$\\hat{y}$の平均二乗誤差 (MSE, Mean Squared Error) を最小化する回帰係数ベクトル$\\boldsymbol{w}$を見つけることが目的となる。\nMSEは次式で表される。\n$$ {\\rm MSE}(\\boldsymbol{w})=\\frac{1}{m}\\sum_{i=1}^{m}(\\boldsymbol{w}^T \\boldsymbol{x}^i-y^i)$$\n複数の説明変数がある回帰モデル（重回帰モデル）は、特徴量ごとの影響を回帰係数から解釈しやすいため、広く用いられている。\nしかし、説明変数に似たような変数が2つ以上含まれる場合、回帰係数が正しく求められないことがある。\nこの問題は多重共線性と呼ばれる。詳細は以下を参照。\n多重共線性とは何？ Weblio辞書\n多重共線性の問題を回避するため、回帰係数の大きさに制限を加える方法（正則化）がある。\nScikit-learnには、異なる制限を加える重回帰モデルであるRidge回帰、Lasso回帰、Elastic Netが実装されている。\n環境 記事執筆時点でのバージョンは以下の通り。\n Scikit-learn 0.20.2  通常の重回帰 通常の重回帰（単回帰も含む）はLinearRegressionクラスで行う。\n1 2  sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)   引数の説明は以下の通り。\n   引数 説明     fit_intercept 切片を計算する   normalize 説明変数Xを事前に正規化する   copy_X FlaseならXが上書きされる   n_jobs=None 並列計算数。Noneは1コア、-1は全コアを使う    クラス変数 (attribute)は以下の通り。\n   変数 説明     coef_ 回帰係数   intercept_ 切片    主なメソッドは以下の通り。\n   メソッド 説明     fit(X, y) 回帰モデルをあてはめる（X: 説明変数。y:目的変数）   predict(X) 予測する（X: 説明変数）    Ridge回帰 Ridge回帰では、回帰係数の重みを制限するため、次式のコスト関数$J$を最小化する回帰係数$\\boldsymbol{w}$を求める。\n$$ J(\\boldsymbol{w})={\\rm MSE}(\\boldsymbol{w}) + \\alpha \\frac{1}{2} \\sum_{i=1}^{n} \\boldsymbol{w}_i^2$$\n右辺の第二項は正則化項と呼ばれる。\nRidge回帰で加える正則化をL2正則化という。\nまた、$\\alpha$はハイパーパラメータであり、望ましい値を探す必要がある。\n$\\alpha=0$のとき通常の重回帰と同じである。一方、$\\alpha$が非常に大きい場合、全ての係数が0に近づくため、データの平均を出力するようになる。\nRidge回帰はRidgeクラスで行う。\n1 2 3  sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, random_state=None)   引数の説明は以下の通り。\n   引数 説明     alpha 正則化項のハイパーパラメータ   fit_intercept 切片を計算する   normalize 説明変数Xを事前に正規化する   copy_X FlaseならXが上書きされる   max_iter コスト関数の勾配計算の最大反復回数   tol 解の許容精度   random_state 乱数シード    クラス変数 (attribute)は以下の通り。\n   変数 説明     coef_ 回帰係数   intercept_ 切片   n_ite_ 反復計算回数    主なメソッドは以下の通り。\n   メソッド 説明     fit(X, y) 回帰モデルをあてはめる（X: 説明変数。y:目的変数）   predict(X) 予測する（X: 説明変数）    Lasso回帰 Lasso回帰では、回帰係数の重みを制限するため、次式のコスト関数$J$を最小化する回帰係数$\\boldsymbol{w}$を求める。\n$$ J(\\boldsymbol{w})={\\rm MSE}(\\boldsymbol{w}) + \\alpha \\sum_{i=1}^{n} | \\boldsymbol{w}_i |$$\nLasso回帰で加える正則化をL1正則化という。\nまた、$\\alpha$はハイパーパラメータであり、望ましい値を探す必要がある。\nLassoはLeast Absolute Shrinkage and Selection Operatorの略である。\nLasso回帰では、重要度の低い説明変数の係数は0となる。\nLasso回帰はLassoクラスで行う。\n1 2 3 4 5  sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection=\u0026#34;cyclic\u0026#34;)   引数の説明は以下の通り。\n   引数 説明     alpha 正則化項のハイパーパラメータ   fit_intercept 切片を計算する   normalize 説明変数Xを事前に正規化する   copy_X FlaseならXが上書きされる   max_iter コスト関数の計算の最大反復回数   tol 解の許容精度   warm_start Trueなら前回の解を初期値とする   positive Trueなら係数を全て正とする   random_state 乱数シード   selection \u0026quot;cyclic\u0026quot;なら係数を順番に更新。\u0026quot;random\u0026quot;ならランダムに更新    主なクラス変数 (attribute)は以下の通り。\n   変数 説明     coef_ 回帰係数   intercept_ 切片   n_ite_ 反復計算回数    主なメソッドは以下の通り。\n   メソッド 説明     fit(X, y) 回帰モデルをあてはめる（X: 説明変数。y:目的変数）   predict(X) 予測する（X: 説明変数）    Elastic Net Elastic NetはLasso回帰のL1正則化とRidge回帰のL2正則化を合わせたもので、次式のコスト関数$J$を最小化する回帰係数$\\boldsymbol{w}$を求める。\n$$ J(\\boldsymbol{w})={\\rm MSE}(\\boldsymbol{w}) + \\alpha r \\sum_{i=1}^{n} | \\boldsymbol{w}_i | + \\frac{\\alpha(1-r)}{2} \\sum_{i=1}^{n} \\boldsymbol{w}_i^2 $$\nここで、$\\alpha$と$r$はハイパーパラメータである。\nElastic NetはElasticNetクラスで行う。\n1 2 3 4 5 6  sklearn.linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection=\u0026#39;cyclic\u0026#39;)   引数の説明は以下の通り。\n   引数 説明     alpha ハイパーパラメータ   l1_ratio ハイパーパラメータ   fit_intercept 切片を計算する   normalize 説明変数Xを事前に正規化する   max_iter コスト関数の計算の最大反復回数   copy_X FlaseならXが上書きされる   tol 解の許容精度   warm_start Trueなら前回の解を初期値とする   positive Trueなら係数を全て正とする   random_state 乱数シード   selection \u0026quot;cyclic\u0026quot;なら係数を順番に更新。\u0026quot;random\u0026quot;ならランダムに更新    主なクラス変数 (attribute)は以下の通り。\n   変数 説明     coef_ 回帰係数   intercept_ 切片   n_ite_ 反復計算回数    主なメソッドは以下の通り。\n   メソッド 説明     fit(X, y) 回帰モデルをあてはめる（X: 説明変数。y:目的変数）   predict(X) 予測する（X: 説明変数）    参考 sklearn.linear_model.LinearRegression — scikit-learn 0.24.0 documentation\nsklearn.linear_model.Ridge — scikit-learn 0.24.0 documentation\nsklearn.linear_model.Lasso — scikit-learn 0.24.0 documentation\nsklearn.linear_model.ElasticNet — scikit-learn 0.24.0 documentation\n","description":"Scikit-learnに実装されている重回帰、Ridge回帰、Lasso回帰、Elastic Netのロジックと使用方法をまとめた。","id":39,"section":"posts","tags":["Python","Scikit-learn"],"title":"Scikit-learnの正則化付き重回帰モデル","uri":"https://helve2017.github.io/posts/python/sklearn-regularized-regression/"},{"content":"はじめに Windows10のPowerShellでAnaconda Pythonを使えるようになるまでに苦労したので、備忘録として残す。\nPowerShellが起動時に読み込むスクリプトに、Anacondaが使えるようになる設定を記述しておく。なお、本記事の設定に管理者権限は不要である。\n環境  Windows 10 Home Ver. 1809 Anaconda3 Ver. 2019.03  設定方法のまとめ 始めに、実施方法を簡潔にまとめる。\nAnacondaはすでにインストールされているものとする。\nまず、PowerShell起動時に読み込まれるスクリプトのパスを確認するため、PowerShellを起動して以下を実行する。\u0026quot;$\u0026ldquo;の入力も必要。\n1  $profile   実行すると、以下のようなパスが表示される。\nC:\\Users\\（ユーザ名）\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 フォルダが存在しない場合は作成してから、\n1  notepad $profile   を実行して、メモ帳で設定ファイルMicrosoft.PowerShell_profile.ps1を開いておく（ファイルがない場合は作成される）。\n次に、Windowsのスタートメニュー → アプリ一覧 → Anaconda3 (64-bit) → Anaconda Powershell Prompt を右クリックして、「その他」 →　「ファイルのある場所を開く」をクリックする。\n以下のようなAnacondaのショートカットのあるフォルダがエクスプローラで開かれる。\nC:\\Users\\（ユーザ名）\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Anaconda3 (64-bit) さらに、Anaconda Powershell Prompt のショートカットアイコンを右クリックして、プロパティを開くと、「リンク先」は以下のようになっているはずである（見やすいように改行した）。\n1 2 3 4  %windir%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -ExecutionPolicy ByPass -NoExit -Command \u0026#34;\u0026amp; \u0026#39;C:\\Users\\（ユーザ名）\\Anaconda3\\shell\\condabin\\conda-hook.ps1\u0026#39; ; conda activate \u0026#39;C:\\Users\\（ユーザ名）\\Anaconda3\u0026#39; \u0026#34;   この中の\n1  C:\\Users\\（ユーザ名）\\Anaconda3\\shell\\condabin\\conda-hook.ps1   をメモ帳で開き、中身をすべて先程のMicrosoft.PowerShell_profile.ps1にコピーし、その後ろに、\n1  conda activate   というコマンドを追加する（下図参照）。\nMicrosoft.PowerShell_profile.ps1とconda-hook.ps1を閉じる。\nPowerShellを再起動すると、スクリプトの実行が無効になっているため、Microsoft.PowerShell_profile.ps1を読み込めないとエラーが出る。\nそこで、現在のユーザがスクリプトを実行できるように以下のコマンドを入力する。\n1  Set-ExecutionPolicy RemoteSigned -Scope CurrentUser   入力すると実行ポリシーを変更するか確認されるので、さらにYを入力する。\n以上で設定は完了である。もう一度PowerShellを再起動すると、PythonとIPythonを自由に使えるようになる。\nPythonの実行例\n1 2 3 4  (base) PS C:\\Users\\（ユーザ名）\\Documents\u0026gt; python Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32 Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt;   IPythonを実行するには、ipythonと入力する。\n設定の詳細 上記の設定方法について補足する。\nWindows 7では、OSの環境変数にAnacondaのパスを追加するだけで、コマンドプロンプトからPythonを実行できた。\nそのため、Explorer上でShift+右クリックでコマンドプロンプトを起動し、現在のパスでPythonスクリプトを実行することが可能であった。\nしかし、後述のようにWindows 10ではこの方法が使えなくなったので、代わりの方法を探した。\nまた、Windows 10ではShift+右クリックでPowerShellが起動するようになり、コマンドプロンプトに戻すには管理者権限が必要である。\n管理者権限がない環境でも設定できるようにしたいため、PowerShellで実行できるようにする。\nまず、既にAnacondaのインストールが終わっているものとして、PowerShellからPythonを実行できるか確認する。\n1 2 3 4 5 6 7 8 9  PS C:\\Users\\（ユーザ名）\\Documents\u0026gt; python python : 用語 \u0026#39;python\u0026#39; は、コマンドレット、関数、スクリプト ファイル、または操作可能なプログラムの名前として認識されま せん。名前が正しく記述されていることを確認し、パスが含まれている場合はそのパスが正しいことを確認してから、再試行してく ださい。 発生場所 行:1 文字:1 + python + ~~~~~~ + CategoryInfo : ObjectNotFound: (python:String) [], CommandNotFoundException + FullyQualifiedErrorId : CommandNotFoundException   やはり実行できない。\n次に、Windowsの環境変数に、Pythonの実行フォルダを追加してみた（実際に追加しても上手くいかないので注意）。\nAnaconda Powershell PromptにはPythonのパスが通っているはずなので、以下のコマンドでパスを表示する。\n1 2 3 4 5 6 7 8 9  (base) PS C:\\Users\\（ユーザ名）\u0026gt; $env:Path.split(\u0026#34;;\u0026#34;) C:\\Users\\（ユーザ名）\\Anaconda3 C:\\Users\\（ユーザ名）\\Anaconda3\\Library\\mingw-w64\\bin C:\\Users\\（ユーザ名）\\Anaconda3\\Library\\usr\\bin C:\\Users\\（ユーザ名）\\Anaconda3\\Library\\bin C:\\Users\\（ユーザ名）\\Anaconda3\\Scripts C:\\Users\\（ユーザ名）\\Anaconda3\\bin C:\\Users\\（ユーザ名）\\Anaconda3\\condabin （以下略）   以上のAnaconda関係のフォルダを全てWindowsのパスに追加する。追加する方法は以下を参照。\n環境変数の設定方法\t| 若葉プログラミング塾\n追加すると一応Pythonを起動できるが、環境がactivateされず、ライブラリが読み込めていないというエラーが出る。\n実際、NumPyなどをインポートできず実質的にPythonを使えない。\n1 2 3 4 5 6 7 8 9 10  PS C:\\Users\\（ユーザ名）\\Documents\u0026gt; python Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32 Warning: This Python interpreter is in a conda environment, but the environment has not been activated. Libraries may fail to load. To activate this environment please see https://conda.io/activation Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;   そこで、Anaconda 2019.03 for Windows Installerから実装されたAnaconda Powershell Promptがどのように起動されているか確認する。\n前述のように、Windowsのスタートメニュー → プログラム → Anaconda3 (64-bit) → Anaconda Powershell Prompt のプロパティの「リンク先」は以下のようになっていた。\n1 2 3 4  %windir%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -ExecutionPolicy ByPass -NoExit -Command \u0026#34;\u0026amp; \u0026#39;C:\\Users\\（ユーザ名）\\Anaconda3\\shell\\condabin\\conda-hook.ps1\u0026#39; ; conda activate \u0026#39;C:\\Users\\（ユーザ名）\\Anaconda3\u0026#39; \u0026#34;   すなわち、\npowershell.exe\nを起動し、\nC:\\Users\\（ユーザ名）\\Anaconda3\\shell\\condabin\\conda-hook.ps1\nのスクリプトを実行した後、\nconda activate\nコマンドを実行していることが分かる。\nこれをPowerShell起動時に実行してやれば、Anaconda Powershell Promptと同じ環境になる。\nPowerShellは、起動時にprofile変数にある設定ファイル（初期設定ではMicrosoft.PowerShell_profile.ps1）を読み込みに行くので、以上のコマンドを設定ファイルに記述する。\nただし、Windows10の初期設定では、セキュリティポリシーによって設定ファイルの読み込みが制限されている。\nそこで、以下のコマンドでローカルにあるスクリプトを実行可能にする。\n-Scope CurrentUserでセキュリティポリシーの変更を現在のユーザのみに限ることで、管理者権限が不要になる。\n1  Set-ExecutionPolicy RemoteSigned -Scope CurrentUser   以上の設定で、Shift+右クリックでPythonを実行可能なPowerShellが起動するようになる。\n参考 下2つののサイトでは、パスを追加するだけでPythonを実行できるとあったが、筆者の環境では出来なかった。\n2018年の記事なので、それ以降のWindows10のアップデートにより出来なくなった可能性がある。\nPowerShellでAnacondaを使う方法 | 山本隆の開発日誌\nWindowsでPythonがうまく動かないとき(PATHの設定) - Qiita\nPowerShellのセキュリティポリシーについては、以下を参照。\nPowerShellのExecutionPolicyのスコープとかについて詳しく - Qiita\n","description":"Windows10のPowerShellでAnaconda Pythonを使うための手順をまとめた。","id":40,"section":"posts","tags":["Python","PowerShell"],"title":"Windows10のPowerShellでAnaconda Pythonを使う方法","uri":"https://helve2017.github.io/posts/python/powershell-anaconda-python/"},{"content":"はじめに Python 3.6で実装されたf-stringsと呼ばれる数字や文字列の表記法について、学術計算で最低限必要な範囲でまとめた。\n本記事では、整数・小数の桁数指定や、指数表示を扱う。\nf-stringsの基本 f-stringsでは、変数の桁数などを指定してprint文による表示やファイル保存できる。\n基本的な使い方は以下の通り。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; a = 123 # 変数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a}\u0026#34;) # フォーマット指定なし 123 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:08.2f}\u0026#34;) # フォーマット指定あり 00123.00   fの後にクオーテーションを2つ置き、その中で波括弧を閉じる。\n波括弧内に変数を記述する。\nオプションで、変数の後にコロン:を挟んでフォーマットを指定する。\nなお、クオーテーションは、シングルクォート'でもダブルクォート\u0026quot;でも可。\n全体の桁数を指定する場合 書式フォーマットを整数にすると、数値全体の桁数を指定できる。\n小数点は1桁として扱われる。\n先頭を0埋めする場合は、最初に0を置く。\n1 2 3 4 5 6 7 8 9 10 11  \u0026gt;\u0026gt;\u0026gt; a = 123 # 整数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:5}\u0026#34;) # 5桁で表示 123 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:05}\u0026#34;) # 0埋め 00123 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; b = 12.3456 # 小数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:10}\u0026#34;) # 10桁で表示 12.3456 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:010}\u0026#34;) # 0埋め 00012.3456   なお、変数よりも少ない桁数を指定すると、変数を最低限表示するのに必要な桁数で表示される。\n1 2 3 4 5 6 7  \u0026gt;\u0026gt;\u0026gt; a = 123 # 3桁の整数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:1}\u0026#34;) # 1桁に指定-\u0026gt;3桁で表示される 123 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; b = 12.3456 # 7桁の小数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:2}\u0026#34;) # 2桁に指定-\u0026gt;7桁で表示される 12.3456   小数点以下の桁数を指定する場合 書式フォーマットの末尾にfを追加すると、小数点以下の桁数を指定できる。\n.[数値]fとすると小数点以下の桁数が数値になる。\n変数が整数型でも小数型でも同じ動作をする。\nまた、小数の末尾は四捨五入される。\n小数点を含む全体の桁数をさらに指定する場合、小数点の前に記述する。\n先頭を0埋めする場合は、さらに最初に0を置く。\nただし、小数点以下の桁数を0にすると、小数点は出力されない。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  \u0026gt;\u0026gt;\u0026gt; a = 123 # 整数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:.2f}\u0026#34;) # 小数点以下2桁 123.00 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:8.2f}\u0026#34;) # 小数点以下2桁、全体は8桁 123.00 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:08.2f}\u0026#34;) # さらに先頭を0埋めする 00123.00 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:08.0f}\u0026#34;) # 小数点以下0桁 00000123 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; b = 12.3456 # 小数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:.2f}\u0026#34;) # 小数点以下2桁 12.35 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:8.2f}\u0026#34;) # 小数点以下2桁、全体は8桁 12.35 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:08.2f}\u0026#34;) # さらに先頭を0埋めする 00012.35 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:08.0f}\u0026#34;) # 小数点以下0桁 00000012   指数表示の場合 書式フォーマットの末尾にeまたはEを追加すると、指数表示になる。\n表示される指数記号の大文字・小文字は、書式フォーマットと同じになる。\nデフォルトの表示桁数は12桁（指数部分込み）でである。\n変数が整数型でも小数型でも同じ動作をする。\n1 2 3 4 5 6 7 8 9 10 11  \u0026gt;\u0026gt;\u0026gt; a = 123 # 整数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:e}\u0026#34;) # 小文字 1.230000e+02 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:E}\u0026#34;) # 大文字 1.230000E+02 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; b = 12.3456 # 小数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:e}\u0026#34;) # 小文字 1.234560e+01 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{b:E}\u0026#34;) # 大文字 1.234560E+01   桁数の指定はfと同じ方法。\n.[数値]e, .[数値]Eとすると小数点以下の桁数が数値になる。\nまた、小数の末尾は四捨五入される。\n小数部と指数部を含む全体の桁数をさらに指定する場合、小数点の前に記述する。\n先頭を0埋めする場合は、さらに最初に0を置く。\nただし、小数点以下の桁数を0にすると、小数点は出力されない。\n1 2 3 4 5 6 7 8 9  \u0026gt;\u0026gt;\u0026gt; a = 123 # 整数 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:.3e}\u0026#34;) # 小数点以下3桁 1.230e+02 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:10.3e}\u0026#34;) # 小数点以下3桁、全体は10桁 1.230e+02 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:010.3e}\u0026#34;) # さらに先頭を0埋めする 01.230e+02 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a:10.0e}\u0026#34;) # 小数点以下0桁 1e+02   複数の変数や通常の文字列も表示する 1個のf-strings内に、複数の変数を表示できる。\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; a = 123 \u0026gt;\u0026gt;\u0026gt; b = 12.3456 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;{a}{b}\u0026#34;) 12312.3456   上記のように変数を並べるとスペースが付かず、見づらい。変数ではない文字列を表示したい場合は、波括弧の外側に文字列を置く。\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; a = 123 \u0026gt;\u0026gt;\u0026gt; b = 12.3456 \u0026gt;\u0026gt;\u0026gt; print(f\u0026#34;figure1: {a}, figure2: {b}\u0026#34;) figure1: 123, figure2: 12.3456   参考 f-stringsの詳細をより知りたい方は、以下のページを参考のこと。\nPython, formatで書式変換（0埋め、指数表記、16進数など） | note.nkmk.me\nf-strings の使用例 - Qiita\n","description":"Python 3.6で実装されたf-stringsと呼ばれる数字や文字列の表記法を使った、整数・小数の桁数指定や指数表示の方法をまとめた。","id":41,"section":"posts","tags":["Python"],"title":"Pythonのf-stringsで文字列を扱う","uri":"https://helve2017.github.io/posts/python/python-f-strings/"},{"content":"はじめに 情報処理技術者試験の高度試験の1つである、エンベデッドシステムスペシャリスト試験 (ES) の2018年午後Iの計算問題を解説する。\nこのページでは解説のみ載せるため、問題文は以下のIPA（情報処理推進機構）のページから取得されたい。\nIPA 独立行政法人 情報処理推進機構：過去問題\n問1（ドローン） 設問2(2)\n図2のドローンに対し、表1のf, gに入る数値を答える。\n図2より、プロペラa1, a3は左回転、プロペラa2, a4は右回転している。\nすなわち、プロペラa1, a3の反作用により機体は右回転し、プロペラa2, a4の反作用により機体は左回転する。\n機体を右回転させるためには、プロペラa1とa3の合計回転数が、プロペラa2とa4の合計回転数を上回る必要がある。\n次に、ドローンがホバリングするという条件を考える。\nドローンが上昇や下降をしないための4枚のプロペラの合計回転数は40である。\nすなわち、fとgの和は20である。\nまた、ドローンが横滑りをしないためには、隣り合う2つのプロペラの合計回転数を、残り2つのプロペラの合計回転数と等しくする必要がある。\n以上より、fは9, gは11となる。\n問2（冠水防止システム） 設問1(3)(a)\nポンプに稼働指示を送信する時刻を求める。\n8ページ下部より、ポンプが停止中で稼働指示を出していない場合、5分後の貯水槽の予測水位が3m以上のとき、水位が3mとなる時刻を算出し、その時刻にポンプに稼働指示を出す。ここで、水位の変化率は一定と仮定している。\nまた、問題文より、貯水槽の5分前の水位が0.5m, 現在の水位が2.5mである。水位計の水位は5分前から同じであるから、5分後の水位は4.5mと予測される。\nよって、水位が3mとなる時刻を求める。水位の増加率は5分で2mであるから、水位が3mになる、すなわち0.5m増加する時刻は、\n(5(分)/2(m)) × 0.5(m)=1.25分\nしたがって、解は1.25分後である（下図参照）。\n設問1(3)(b)\n5分後の予測水位を求める。現在の水位が2.5mである。また、雨水管からの流入量は5分で2m、すなわち0.4(m/分)である。\nまた、設問1(3)(a)で求めたように、1.25分にポンプに稼働指示が出される。8ページの表1より、ポンプが稼働指示を受けてから排水を開始するまでに3分掛かるため、排水が開始されるのは4.25分後である。\nよって、4.25分後の水位は、\n2.5(m) + 0.4(m/分)×4.25(分) = 4.2(m)\nである。\n次に、ポンプ稼働後の水位の変化を求めるため、ポンプの排水能力を求める。表1より、ポンプが稼働指示を受けてから満杯の貯水槽の水を全て排水するのに28分掛かる。7ページ下段より、貯水槽の深さは10mである。\nまた、実際に排水を行うのは25分間であるから、稼働時の排水能力は、\n10(m)/25(分) = 0.4(m/分)\nである。この値は雨水管からの流入量に等しいため、ポンプ稼働後は貯水槽の水位は変化しない。\nしたがって、5分後の予測水位は4.2(m)である。\n設問2(4)\n各タスクが更新した履歴情報のデータサイズの合計を求める。\n10ページの図2より、履歴情報を更新するタスクは、ポンプ制御タスク、貯水槽水位予測タスク、水位センサタスクの3つである。各タスクが更新する履歴情報のデータサイズは表2に記載されている。\nポンプ制御タスクは、メインタスクからポンプの稼働指示または停止指示を受けたときに処理を行う。問題文より、ポンプは稼働も停止もしていないので、ポンプ制御タスクは履歴情報を更新していない。\n貯水槽水位予測タスクは、2バイトのデータ2つ、5分周期で更新する。\n2時間の間に24回更新するので、合計データサイズは、\n2×2×24 =96(バイト)\n水位センサタスクは、5分周期で水位センサ計測値と貯水槽予測流入量のデータの計測値を更新する。水位センサ計測値は、1台あたり2バイトで、水位計は50台あるため、\n2×50×24 = 2400(バイト)\nまた、貯水槽予測流入量は4バイトであるから、\n4×24 = 96(バイト)\nよって、合計は、\n2400+96 = 2496(バイト)\nである。\nしたがって、解は各タスクのデータサイズを合計して、\n96+2496 = 2592(バイト)\nである。\n問3（トラック隊列走行システム） 後日、解説を載せます。\n参考 午前I, 午前IIの解説は以下のウェブサイトをご参考のこと。\n情報処理技術者試験の勉強をやり直し −ITパスポート、情報セキュリティマネジメント、基本情報技術者、応用情報技術者、情報処理安全確保支援士・高度試験の過去問題の解説−\n","description":"情報処理技術者試験の高度試験の1つである、エンベデッドシステムスペシャリスト試験 (ES) の2018年午後Iの計算問題を解説する。","id":42,"section":"posts","tags":["エンベデッドシステムスペシャリスト試験"],"title":"エンベデッドシステムスペシャリスト試験　2018年午後Iの計算問題解説","uri":"https://helve2017.github.io/posts/it-engineers-exam/embedded-systems-2018-pm1/"},{"content":"はじめに 情報処理技術者試験の高度試験の1つである、エンベデッドシステムスペシャリスト試験 (ES) の2017年午後IIの計算問題を解説する。\nこのページでは解説のみ載せるため、問題文は以下のIPA（情報処理推進機構）のページから取得されたい。\nIPA 独立行政法人 情報処理推進機構：過去問題\n問1（スマートグリッド） 設問1(2)\nFCから電力コントローラに出力できる最大電力量を求める問題。\n表2より、水素タンクの最大貯蔵量は100m3である。\nまた、FCは1m3の水素から4kWhの電力量を発生し、定格運転時には発電電力の2%を消費して冷却器で冷却する必要がある。\n図3より、冷却電力はFCから直接取得されており、残りの電力が電力コントローラに出力される。\nすなわち、FCから電力コントローラに出力できる電力は、発生した電力の98%である。\nしたがって、解は、\n100[m3]×4[kWh/m3]×0.98=392.04[kWh]\n小数第1位を四捨五入して、392[kWh]となる。\n設問1(4)\n表1より、FCは起動指示を受けると出力が直線的に上昇し、20kWの出力に達するまでに12分間掛かる。\nすなわち、10kWの出力に達するまでに6分間（0.1時間）掛かる（下図参照）。\nよって、FCの起動時に必要な蓄電池の残量は、\n(10[kW]×0.1[h])/2=0.5[kWh]\nであるから、全体の容量に対する割合は、\n0.5[kWh]/100[kWh]=0.5[%]\nとなる。\n設問1(5)(a)\nWG部：\n表1より、WG部の出力電力は風速10m/秒以下のとき風速に比例する。\nまた、風速10m/秒のとき最大出力となり、最大出力は20kWである。\n図8より、10～11時の風速は6m/秒であるから、WG部の発電出力は次の通り。\n6[m/秒]×(20[kW]/10[m/秒])×1[h]=12[kWh]\nPV部：\n表1より、PV部の出力電力は日射強度1000W/m2以下のとき日射強度に比例する。\nまた、日射強度1000W/m2のとき最大出力となり、最大出力は20kWである。\n図9より、10～11時の日射強度は1000W/m2であるから、PV部の発電出力は次の通り。\n1000[W/m2]×(20[kW]/1000[W/m2])×1[h]=20[kWh]\n解はWG部とPV部の各発電出力の和であるから、以下の通り。\n12+20=32[kWh]\n設問1(5)(b)\nまず、発電ステーションの余剰電力を求める。\n設問1(5)(a)と同様に、13～14時におけるWG部とPV部の出力電力を求めると、それぞれ8[kW], 20[kW]であり、合計は28[kW]である。\nまた、問題文より、13～14時における外部出力への電力の供給は10[kW]であるから、28-10=18[kW]の電力が余剰となる。\np. 6の管理CPUの制御より、発電した電力に余剰がある場合は、蓄電池の充電、水電解装置の運転、商用電力網への売電の優先順位で電力を使用する。\n問題文より、蓄電池の充電率は100%, 水素の貯蔵率は100%であるから、蓄電池の充電と、水電解装置の運転は不可能である。\nまた、図2の短期売電情報より、13～14時に売電可能な電力は12[kW]である。\n余剰電力18[kW]は12[kW]より大きいため、売電可能な電力は12[kW]である。\nよって、13～14時に売電可能な電力量は次の通り。\n12[kW]×1[h]=12[kWh]\n設問2(1)(a)\n図10, 11より、0～6時のWG部の出力は10[kW], PV部の出力は0[kW]である。\nまた、図12より、外部出力への電力の供給予測は4[kW]である。\nよって、(10[kW]-4[kW])×6[h]=36[kWh]の電力量が余剰となる。\n表1より蓄電池の容量は100[kWh]であり、問題より充電率は64%である.\nすなわち、蓄電池の空き容量は36[kWh]である。\np. 6の管理CPUの制御より、発電した電力に余剰がある場合は、蓄電池の充電を優先して電力を使用する。\n余剰電力は全て蓄電可能である。\nよって、電力コントローラへの指示は、次の通り。\n「WG部で発電した電力を外部出力し、余剰電力で蓄電池を充電する。」\n設問2(2)\n管理CPUがタイマ割込み1の周期の間に、メインプログラムの演算を実行できる時間を求める。\n表2より、タイマ割込み1の周期は1ミリ秒である。\nこの間、伝送受信割込みと伝送送信割込みが、合計5回発生する。\nまた、タイマ割込み2が最大1回発生する。\n次に、各割込み処理の実行時間を求める。\n実行ステップ数は表2に示されている。\nまた、表1より、管理CPUのクロック周期は1GHzであり、2クロックで1ステップのプログラムを実行する。\nよって、管理CPUで1ステップの実行に掛かる時間は、\n2[クロック/ステップ]÷(1×10^9[クロック/秒])=2×10^(-9)[秒/ステップ]\nとなる。\n各割込み処理の実行時間を計算すると、下表の通り。\n   処理名 実行ステップ数 実行時間(マイクロ秒)     タイマ割込み1 2k 4   伝送受信割込み 2k 4   伝送送信割込み 2k 4   タイマ割込み2 20k 40    よって、1ミリ秒の間に、割込み処理が実行される最大の時間は、\n4+4×5+40=64[マイクロ秒]\nとなる。\nしたがって、メインプログラムの演算を実行できる時間は次の通り。\n1000-64=936.0[マイクロ秒]\n問2（駐輪場管理システム） 計算問題は含まれない。\n参考 午前I, 午前IIの解説は以下のウェブサイトを参考のこと。\n情報処理技術者試験の勉強をやり直し −ITパスポート、情報セキュリティマネジメント、基本情報技術者、応用情報技術者、情報処理安全確保支援士・高度試験の過去問題の解説−\n","description":"情報処理技術者試験の高度試験の1つである、エンベデッドシステムスペシャリスト試験 (ES) の2017年午後IIの計算問題を解説する。","id":43,"section":"posts","tags":["エンベデッドシステムスペシャリスト試験"],"title":"エンベデッドシステムスペシャリスト試験　2017年午後IIの計算問題解説","uri":"https://helve2017.github.io/posts/it-engineers-exam/embedded-systems-2017-pm2/"},{"content":"はじめに 情報処理技術者試験の高度試験の1つである、エンベデッドシステムスペシャリスト試験 (ES) の2017年午後Iの計算問題を解説する。\nこのページでは解説のみ載せるため、問題文は以下のIPA（情報処理推進機構）のページから取得されたい。\nIPA 独立行政法人 情報処理推進機構：過去問題\n問1（観光案内用ロボット） 設問1 (1)\nLCDの表示データを情報サーバから取得し、表示バッファへの書き込みを完了する時間を求める。\n表2の「表示コントローラ」の項より、LCDの表示は1画素が16ビットで、1画面が500,000画素である。\nすなわち、1画面のデータは、\n16[ビット]×500,000=8,000,000[ビット]=8[Mビット]\nである。\n問題文より、表示データをLANで転送する際の転送速度は40[Mビット/秒]なので、LANの転送時間は次の通り。\n8[Mビット]/40[Mビット/秒]=0.2[秒]=200[ミリ秒]\nまた、LANコントローラから表示バッファへの転送速度は80[Mバイト/秒]であるから、転送時間は次の通り。\n8[Mビット]/(80×8[Mビット/秒])=0.0125[秒]=12.5[ミリ秒]\nしたがって、解は、これらの転送時間の和の小数第二位を四捨五入し、\n200+12.5=212.5[ミリ秒]\nとなる。\n設問2 (1) (a)\nロボットの体を、モータの200度の位置で停止させるPWMのデューティ比を求める。\n表3, 4より、モータの角度はデューティ比に比例して変化し、さらにデューティ比を0から1まで変化させると、0度から360度まで回転することが分かる。\nよって、モータを200度の位置に停止させるデューティ比は、\n200[度]/360[度] = 5/9\nである。\n設問2 (1) (b)\nタイマを使用して、体をモータの200度に最も近い位置で停止させるタイマの設定値を求める。また、このときの角度の誤差も求める。\n表1より、PWM信号の周期は1ミリ秒で、あるアクティブHighである。\nまた、表2より、タイマは240kHzのクロックでカウントアップし、設定したHighの幅とタイマのカウンタが同じ値になると、出力はLowになる。\n設定した周期とタイマのカウンタが同じ値になると、カウンタが0になり、出力はHighになる。\n解答の方針として、まずタイマの設定周期を求めてから、Highの設定値を求める。\nタイマの設定周期は、240[kHz]でカウントしたときに1[ミリ秒]になる回数であるから、\n0.001[秒]×(240×10^3[Hz]) = 240\nである。\n次に、Highの設定値を求める。\nモータを200度の位置に停止させるデューティ比は5/9であると、(a)で既に求めた。\nよって、求めるHighの設定値は、整数であることに注意して、\n240×(5/9) = 133.33\u0026hellip; ≒ 133\nである。\n次に、角度の誤差を求める。先程、Highの設定値を133.33\u0026hellip;を四捨五入して133としたが、切り捨てた0.33\u0026hellip;, すなわち1/3に相当するデューティ比が角度の誤差になる。\nしたがって角度の誤差は、\n360[度]×((1/3)/240)=0.5[度]\n解は小数第3位を四捨五入して、0.50[度]である。\n問2（カメラ付き防犯灯） 設問1 (2)\n画像データの記憶に必要なフラッシュメモリの容量を計算する。\np. 8の下段より、カメラユニットは1秒間に4フレームの画像を撮影している。\nまた、p. 9の下段より、画像を圧縮して、6分間の画像を1つのファイルにして、フラッシュメモリに240時間保存することが分かる。\nさらに、問題文より、1フレームの画像は1Mバイトで、圧縮すると元データの1%の容量になり、暗号化すると圧縮したデータから5%容量が増加することが分かる。\nしたがって、以下の通りに計算すると、回答が得られる。\n1フレームの画像を圧縮すると、\n1[Mバイト]×0.01=0.01[Mバイト]\nであり、さらに暗号化すると、\n0.01[Mバイト]×1.05=0.0105[Mバイト]\nとなる。\n240時間に撮影されるフレーム数は、\n(240×3600)[秒]×4[フレーム/秒]=3456000[フレーム]\nである。\nしたがって、求めるフラッシュメモリの容量は、\n0.0105[Mバイト/フレーム]×3456000[フレーム]=36288[Mバイト]\nすなわち、36.288[Gバイト]。\n解は小数点以下を切り上げて37[Gバイト]である。\n問3（病院内資料配送システム） 設問1 (1)\n配送車が通信点でやり取り可能なデータ量を求める。\np. 17の上段より、NFCの通信速度は400kビット/秒である。\nまた、通信可能領域に入ったことを検知するのに、10ミリ秒、通信準備が完了するのにさらに10ミリ秒掛かる。\n問題文より、配送車は1メートル/秒で走行しており、通信点の前後4センチメートルで通信できる。\nよって、配送車が通信可能な時間は、\n0.08[m]÷1[m/s] = 0.08[s]\nである。\nさらに、通信できるまでに、10[ミリ秒]+10[ミリ秒]掛かるため、実際にデータをやり取りできるのは、\n0.08-(0.01+0.01)=0.06[s]\nとなる。\nNFCの通信速度は400kビット/秒であるから、通信されるデータ量は次の通り。\n0.06[s]×400[kビット/秒]=24[kビット]\nさらに、NFCは16バイトのデータを200ビットで通信するので、\n実際にやり取りされるデータ量は、\n24×10^3[ビット]×(16[バイト]/200[ビット])=1920[バイト]\nとなる。\nすなわち、1.92[kバイト]の小数第二位を四捨五入して、解は1.9[kバイト]である。\n参考 午前I, 午前IIの解説は以下のウェブサイトを参考のこと。\n情報処理技術者試験の勉強をやり直し −ITパスポート、情報セキュリティマネジメント、基本情報技術者、応用情報技術者、情報処理安全確保支援士・高度試験の過去問題の解説−\n","description":"情報処理技術者試験の高度試験の1つである、エンベデッドシステムスペシャリスト試験 (ES) の2017年午後Iの計算問題を解説する。","id":44,"section":"posts","tags":["エンベデッドシステムスペシャリスト試験"],"title":"エンベデッドシステムスペシャリスト試験　2017年午後Iの計算問題解説","uri":"https://helve2017.github.io/posts/it-engineers-exam/embedded-systems-2017-pm1/"},{"content":"はじめに KerasのステートフルRNNおよび、Kerasのコードについて解説する。\nステートフルRNNは、学習バッチ間で内部状態を保持するため、学習を高速化できる。\n再帰型ニューラルネットワーク(RNN)は、時系列データや言語データなど、過去のデータに対して、何らかの依存性を持つデータを扱うことが出来る。\nこれは、RNNがレイヤの内部に隠れ変数を持つことで、過去の変数を記憶しているためである。\n通常のRNNでは、学習バッチごとに隠れ変数はリセットされるが、ステートフルRNNでは隠れ変数を保持することで、学習を高速化できる。\nKerasには、単純なRNNであるSimpleRNNのほかに、LSTMやGRUといったRNNレイヤが実装されているが、これら3つのRNNレイヤは全てステートフルを利用できる。\nなお、本記事では、Tensorflow統合版のKeras(tf.keras)を用いたが、単独版のKerasでもステートフルRNNを利用できる。\n本記事では、以下の通りライブラリをインポートしていることを前提とする。\n1 2 3 4 5  import numpy as np import pandas as pd from sklearn.preprocessing import StandardScaler from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, SimpleRNN, GRU, LSTM   また、使用したコードは以下のGistにまとめている。\nKerasでステートフルRNNを使ったサンプルコード · GitHub\n環境    ソフトウェア バージョン     Python 3.7.3   NumPy 1.16.2   Pandas 0.24.2   sklearn 0.20.3   TensorFlow 1.14.0    ステートフルRNN ステートフルRNNについて解説する。\n単純なRNN(SimpleRNN)やLSTM, GRUといったRNNレイヤは、過去の変数を記憶するため、内部に変数を持っている。例として、SimpleRNNの概念を下図に示す。\n時刻tにおけるSimpleRNNへの入力をx[t], 出力をo[t], 内部の隠れ状態をh[t]とする。このとき、h[t]は1ステップ前の隠れ状態h[t-1]を用いて、\nh[t] = tanh( Vh[t-1] + Ux[t] )\nと更新される。\nただし、V, Uは重み行列である。\nまた、出力o[t]は、次式で表される。\no[t] = f( Wh[t] )\nただし、Wは重み行列、fは活性化関数（ReLUやシグモイド関数など）である。\n図の出典：Wikipedia\n通常のRNNで内部状態が保持されるのは、連続したデータが与えられた期間のみである。データが途切れると、内部状態hはリセットされる。\nここで、次に与えられるデータが、前のデータに連続している場合を考える。\n以下の図は、説明変数の数が1で、バッチサイズも1の場合である。一度に入力が3つ連続する場合、x[0]～x[2]が与えられた後に、x[3]～x[5]が与えられる（下図参照）。\nx[2]が与えられたとき、内部状態はh[2]であるが、その次にx[3]以降のデータが連続して与えられるのであれば、内部状態をリセットせずにそのまま引き継ぐ方が良い。\nこれは、以下の理由による。\n 内部状態を引き継ぐことで、学習（重み行列の更新）を高速化できる。 バッチごとに内部状態をリセットする処理が不要になる。  このように、バッチ間で内部状態を保持するRNNをステートフルRNNという。\nステートフルRNNと区別するため、従来のバッチごとに内部状態をリセットするRNNをステートレス (stateless) RNNと呼ぶ。\n最後に、データがバッチで与えられる場合を考える。\n下図ではバッチサイズを5とした。2番目のバッチで与えるデータは、それぞれ1番目のバッチで与えられたデータに対して、時間的に連続している必要がある。\nKerasのステートフルRNN Kerasに実装されているステートフルRNNを使う場合には、以下の点に留意する。\n データの並びは時系列順とする（シャッフル禁止） エポック毎にモデルの内部状態をリセットする データの長さはバッチサイズの整数倍でなければならない\n具体的なコードについては後述する。  対象データ 気温の予測を対象として、ステートフルRNNとステートレスRNNを比較する。\n気温のデータは、気象庁から取得した2009年1月1日から2018年12月31日までの大阪の気温である。1時間周期であり、データ点数は87,648点になる。\nPythonで扱いやすいようにデータを加工し、CSV形式とした。以下のDropboxからダウンロードできる（Dropboxのアカウント登録は不要）。\nDropbox - osaka_temperature2009_2018.csv\nグラフにすると以下の通り。ただし、欠損値があるので線形補間している。\n1 2 3 4  df = pd.read_csv(\u0026#34;osaka_temperature2009_2018.csv\u0026#34;, index_col=0, parse_dates=True) df = df.interpolate(method=\u0026#34;linear\u0026#34;) df.plot()   また、ニューラルネットワークで扱えるように、StandardScalerであらかじめ標準化しておく。\n1 2 3  ss = StandardScaler() std = ss.fit_transform(df) std = std.astype(np.float32)   StandardScalerについては以下の記事を参考。\nScikit-learnでデータをスケール変換する\n次に、説明変数と目的変数を定義する。\nここでは、過去6時間のデータを用いて、1時間後の気温を予測する。すなわち、timestepsは6とする。\nバッチサイズに特に制約はないが、配列を変形するだけで簡単に学習データを作れるように、バッチサイズはtimestepsと同じ6とする。\n※バッチサイズが6より大きいと、同じ時系列データが複数のバッチに含まれる。そのため、ジェネレータを使って、逐次的に学習データを生成した方がメモリ消費が少ない。RNN用のジェネレータについては以下の記事を参考。\nKerasの時系列予測でgeneratorを使って大容量データを扱う 前編\nKerasの時系列予測でgeneratorを使って大容量データを扱う 後編\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  timesteps = 6 batch_size = timesteps x = np.empty([len(std)-timesteps, timesteps], dtype=np.float32) y = np.empty(len(std)-timesteps, dtype=np.float32) for i in range(len(x)): x[i] = std[i:i+timesteps].T y[i] = std[i+timesteps] data_len = batch_size*int(len(x)/batch_size) x = x[:data_len].reshape(data_len,timesteps,-1) y = y[:data_len].reshape(data_len,-1)   また、ステートフルRNNでは内部状態が保存されるため、各バッチのサイズは同じでなければならない。そのため、最後のバッチでデータが余らないように、データの長さをbatch_sizeの整数倍としている。\nモデルの定義・学習 用意した気温データを用いて、RNNを学習させる。\nステートレスとステートフルの2つのモデルを比較する。どちらのモデルも、1層目はノード数10のSimpleRNN, 2層目はノード数10の全結合(Dense)層とする。また、活性化関数はtanh, エポック数は3とする。\nステートレス ステートレスRNNのモデルを定義・実行する。\nまた、ステートフルモデルと条件をそろえるため、fit関数でshuffle=Falseとした。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  actfunc = \u0026#34;tanh\u0026#34; N_EPOCH = 3 model = Sequential() model.add(SimpleRNN(10, activation=actfunc, stateful=False, input_shape=(timesteps, 1))) model.add(Dense(10, activation=actfunc)) model.add(Dense(1)) model.compile(optimizer=\u0026#39;RMSprop\u0026#39;, loss=\u0026#39;mean_squared_error\u0026#39;) history = model.fit(x, y, epochs=N_EPOCH, batch_size=batch_size, verbose=1, shuffle=False)   実行結果：\n1 2 3 4 5 6  Epoch 1/3 87642/87642 [==============================] - 33s 374us/sample - loss: 0.0112 Epoch 2/3 87642/87642 [==============================] - 32s 366us/sample - loss: 0.0063 Epoch 3/3 87642/87642 [==============================] - 31s 354us/sample - loss: 0.0062   ステートフル ステートフルRNNのモデルを定義・実行する。\nSimpleRNNレイヤでstateful=Trueとすると、ステートフルになる。また、SimpleRNNとfitの両方でbatch_sizeを定義する。ステートフルモデルでは内部状態が自動でリセットされないため、エポック毎にmodel.reset_states()でリセットする。\n1 2 3 4 5 6 7 8 9 10 11 12 13  model = Sequential() model.add(SimpleRNN(10, activation=actfunc, stateful=True, input_shape=(timesteps, 1), batch_size=batch_size)) model.add(Dense(10, activation=actfunc)) model.add(Dense(1)) model.compile(optimizer=\u0026#39;RMSprop\u0026#39;, loss=\u0026#39;mean_squared_error\u0026#39;) for i in range(N_EPOCH): history = model.fit(x, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False) model.reset_states()   1 2 3  87642/87642 [==============================] - 30s 343us/sample - loss: 0.0074 87642/87642 [==============================] - 30s 337us/sample - loss: 0.0061 87642/87642 [==============================] - 30s 339us/sample - loss: 0.0061   ステートレスとステートフルを比較すると、ステートフルが1エポックの実行時間がやや短い。また、1エポック目の損失関数が小さくなっており、学習が速いことが分かる。\nまとめ 気温のデータを対象として、ステートフルRNNで学習を高速にできることを示した。\n参考 気象庁\n気象庁｜過去の気象データ検索\n大阪の気温データ(Dropbox)\nDropbox - osaka_temperature2009_2018.csv\n使用したコード(Gist)\nKerasでステートフルRNNを使ったサンプルコード · GitHub\n","description":"KerasのステートフルRNNについて解説する。","id":45,"section":"posts","tags":["Python","Keras"],"title":"KerasのステートフルRNNで学習を高速化する","uri":"https://helve2017.github.io/posts/python/keras-stateful-rnn/"},{"content":"はじめに この記事は前編の続きである。作成したgeneratorクラスを使った時系列予測の方法を解説する。\n学習データ 図のように、\n[-1, -1, 0, 0, 1, 1, 0, 0, \u0026hellip;]\nを繰り返す時系列データが与えられたとき、次のステップの値を予測させる。\n正しく予測するためには、最低でも3個以上の過去のデータを記憶する必要がある。\n例えば、[0, 0]とデータが与えられても、次の値は1か-1か分からない。\nさらに1ステップ前から[-1, 0, 0]と連続して初めて、次の値が1と予測できる。\n説明変数x_setと目的変数y_setを以下のように作成する。\nここで、x_setとy_setは行数が等しい2次元配列であり、同じ行のデータは同じ時刻のデータである。\n（実務で得られることが多いデータ形式であると思う）\n1 2 3 4 5 6 7  x_base = np.array([-1,-1,0,0,1,1,0,0], dtype=np.float32).reshape(-1, 1) x_set = np.empty([0, 1], dtype=np.float32) for i in range(10): x_set = np.vstack([x_set, x_base]) # 説明変数 y_set = x_set.copy() # 目的変数   学習 初めに、x_setとy_setを、自作した学習用ジェネレータReccurentTrainingGeneratorに与える。\nここで、batch_sizeは10, timestepsは5とした。\nまた、次のステップを予測するため、delayは1とした。\n1 2 3 4  timesteps = 5 RTG = ReccurentTrainingGenerator(x_set, y_set, batch_size=10, timesteps=timesteps, delay=1)   次に、ニューラルネットモデルを作成し、学習させる。\n1層目はSimpleRNNレイヤ、2層目は全結合レイヤとする。ともにノード数は10である。\nまた、学習には通常のfitメソッドではなく、fit_generatorメソッドとして、引数にReccurentTrainingGeneratorオブジェクトをとる。\n1 2 3 4 5 6 7 8 9 10 11  actfunc = \u0026#34;tanh\u0026#34; model = Sequential() model.add(SimpleRNN(10, activation=actfunc, batch_input_shape=(None, timesteps, 1))) model.add(Dense(10, activation=actfunc)) model.add(Dense(1)) model.compile(optimizer=\u0026#39;sgd\u0026#39;, loss=\u0026#39;mean_squared_error\u0026#39;) history = model.fit_generator(RTG, epochs=20, verbose=1) # 学習する   予測 検証データとして、以下の配列x_testを与える。これに続くデータ（正解データ）は1である。\nx_testをReccurentPredictingGeneratorクラスに与える。\n予測には、通常のpredictメソッドではなく、predict_generatorメソッドを用いる。\n1 2 3 4 5 6 7 8  x_test = np.array([-1,-1,0,0,1], dtype=np.float32).reshape(-1, 1) # 検証データ RPG = ReccurentPredictingGenerator(x_test, batch_size=1, timesteps=5) # 予測用ジェネレータ pred = model.predict_generator(RPG) # 予測する print(pred)   実行結果\n1  [[1.011917]]   予測値は1.012となり、正解(1)に近い値となった。\n参考 前回と今回の記事のコードをまとめたものをGithubにおいている。\nhttps://gist.github.com/helve2017/c20d6106a5dab00a8afa942584b60580\nKerasの公式リファレンス。\nSequentialモデル - Keras Documentation\nユーティリティ - Keras Documentation\n","description":"前編で作成した時系列予測用generatorクラスを使って予測を行う。","id":46,"section":"posts","tags":["Python","Keras"],"title":"Kerasの時系列予測でgeneratorを使って大容量データを扱う 後編","uri":"https://helve2017.github.io/posts/python/keras-rnn-generator-2/"},{"content":"はじめに 前回、KerasのRecurrentレイヤを使った時系列予測を扱った。\nKerasを使ったRNN, GRU, LSTMによる時系列予測\nこのとき、Reccurent層に入力するデータを下図のように変形していたが、この方法ではデータサイズが約timesteps倍に増加してしまう。\nそこで、Pythonのジェネレータ (generator) を使い、データを呼び出すときに必要なデータだけ変形することで、大容量のデータを扱う場合でもメモリが不足しないようにする。\nなお、ジェネレータとは、for文などを使って要素を逐次的に出力できるオブジェクトであり、なおかつ、1要素を取り出そうとする度に処理を行うものである。本記事ではジェネレータに関する知識は必要ないが、詳細を知りたい方は以下の記事を参照のこと。\nPythonのイテレータとジェネレータ - Qiita\n環境    ソフトウェア バージョン     Anaconda3 2019.03   Python 3.7.3   TensorFlow 1.13.1   keras 2.2.4   NumPy 1.16.2    本記事では、Pythonで以下の通りライブラリをインポートしていることを前提とする。\n1 2 3 4  import numpy as np from keras.utils import Sequence from keras.models import Sequential from keras.layers import Dense, SimpleRNN   Sequentialモデルのgeneratorに関するメソッド KerasのSequentialモデルには、generatorを使った学習・検証・予測がサポートされている。\n学習はfit_generatorメソッド、検証はevaluate_generatorメソッド、予測はpredict_generatorメソッドをそれぞれ用いる。\nfit_generatorメソッドとpredict_generatorメソッドについて簡単に解説する。ここでは一部の引数しか記載していないため、全ての引数を知りたい方は以下のページを参考のこと。\nSequentialモデル - Keras Documentation\nfit_generatorメソッド 1 2  fit_generator(self, generator, epochs=1, validation_data=None, shuffle=True)   引数の説明は以下の通り。\ngenerator: 学習データのgeneratorクラス。呼び出す度に(inputs, targets)のタプルを返す。\nepochs: エポック数 (int). デフォルト値は1.\nvalidation_data: 検証データのgeneratorクラスまたは(inputs, targets)のタプル（任意）。\nshuffle: 各試行の初めにバッチの順番をシャッフルするかどうか。デフォルト値はTrue.\npredict_generatorメソッド 1  predict_generator(self, generator)   引数の説明は以下の通り。\ngenerator: 説明変数を返すgeneratorクラス。\ngeneratorクラスの作成 Recurrentレイヤに入力するためのデータを生成するgeneratorクラスを実装する。\ngenaratorクラスは、keras.utils.Sequence()クラスを基底クラスとする。\nまた、学習(fit_generatorメソッド)では説明変数と目的変数の両方、予測(predict_generatorメソッド)では説明変数のみ扱うため、それぞれ異なるgeneratorクラスを作る。\n学習用generatorクラス 次のReccurentTrainingGeneratorクラスを実装した。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  class ReccurentTrainingGenerator(Sequence): \u0026#34;\u0026#34;\u0026#34; Reccurent レイヤーを訓練するためのデータgeneratorクラス \u0026#34;\u0026#34;\u0026#34; def _resetindices(self): \u0026#34;\u0026#34;\u0026#34;バッチとして出力するデータのインデックスを乱数で生成する \u0026#34;\u0026#34;\u0026#34; self.num_called = 0 # 同一のエポック内で __getitem__　メソッドが呼び出された回数 all_idx = np.random.permutation(np.arange(self.num_samples)) remain_idx = np.random.choice(np.arange(self.num_samples), size=(self.steps_per_epoch*self.batch_size-len(all_idx)), replace=False) self.indices = np.hstack([all_idx, remain_idx]).reshape(self.steps_per_epoch, self.batch_size) def __init__(self, x_set, y_set, batch_size, timesteps, delay): \u0026#34;\u0026#34;\u0026#34; x_set : 説明変数 (データ点数×特徴量数)のNumPy配列 y_set : 目的変数 (データ点数×1)のNumPy配列 batch_size: バッチサイズ timesteps : どの程度過去からデータをReccurent層に与えるか delay : 目的変数をどの程度遅らせるか \u0026#34;\u0026#34;\u0026#34; self.x = np.array(x_set) self.y = np.array(y_set) self.batch_size = batch_size self.steps = timesteps self.delay = delay self.num_samples = len(self.x)-timesteps-delay+1 self.steps_per_epoch = int(np.ceil( self.num_samples / float(batch_size))) self._resetindices() def __len__(self): \u0026#34;\u0026#34;\u0026#34; 1エポックあたりのステップ数を返す \u0026#34;\u0026#34;\u0026#34; return self.steps_per_epoch def __getitem__(self, idx): \u0026#34;\u0026#34;\u0026#34; データをバッチにまとめて出力する \u0026#34;\u0026#34;\u0026#34; indices_temp = self.indices[idx] batch_x = np.array([self.x[i:i+self.steps] for i in indices_temp]) batch_y = self.y[indices_temp+self.steps+self.delay-1] if self.num_called==(self.steps_per_epoch-1): self._resetindices() # 1エポック内の全てのバッチを返すと、データをシャッフルする else: self.num_called += 1 return batch_x, batch_y   以下、簡単な解説である。\nKerasの仕様上、Sequenceを継承するクラスは、__len__, __getitem__メソッドを備えなければならない。\n__len__メソッドは1エポックで生成するバッチ数を返す。\nまた、__getitem__メソッドはReccurentTrainingGeneratorクラスを呼び出す度に実行され、説明変数と目的変数をバッチで返す。\n__getitem__メソッドで返されるbatch_xとbatch_yのイメージは以下の図の通りである。\nここで、x1, x2, x3は異なる説明変数であり、括弧内の数字は時刻を示す。\nまた、batch_sizeは5, timestepsは3, delayは1である。\ndelayが1とは、時刻tまでのデータを用いて、時刻t+1のデータを予測することを意味する。\nbatch_xは（バッチサイズ×timesteps×特徴量数）の3次元配列、\nbatch_yは（バッチサイズ×1）の2次元配列である。\nただし、実際にはバッチ方向の時系列の並びはシャッフルされる。\n学習データを格納したReccurentTrainingGeneratorをfit_generatorメソッドに渡してやればよい。\n予測用generatorクラス 次のReccurentPredictingGeneratorクラスを実装した。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class ReccurentPredictingGenerator(Sequence): \u0026#34;\u0026#34;\u0026#34; Reccurent レイヤーで予測するためのデータgeneratorクラス \u0026#34;\u0026#34;\u0026#34; def __init__(self, x_set, batch_size, timesteps): \u0026#34;\u0026#34;\u0026#34; x_set : 説明変数 (データ点数×特徴量数)のNumPy配列 batch_size: バッチサイズ timesteps : どの程度過去からデータをReccurent層に与えるか \u0026#34;\u0026#34;\u0026#34; self.x = np.array(x_set) self.batch_size = batch_size self.steps = timesteps self.num_samples = len(self.x)-timesteps+1 self.steps_per_epoch = int(np.floor( self.num_samples / float(batch_size))) def __len__(self): \u0026#34;\u0026#34;\u0026#34; 1エポックあたりのステップ数を返す \u0026#34;\u0026#34;\u0026#34; return self.steps_per_epoch def __getitem__(self, idx): \u0026#34;\u0026#34;\u0026#34; データをバッチにまとめて出力する \u0026#34;\u0026#34;\u0026#34; start_idx = idx*self.batch_size batch_x = [self.x[start_idx+i : start_idx+i+self.steps] for i in range(self.batch_size)] return np.array(batch_x)   目的変数を出力せず、データをシャッフルする必要がない以外は、ReccurentTrainingGeneratorクラスと同じである。\n__getitem__メソッドでは先程の図のbatch_xのみ返される。\nただし、バッチ方向の時系列の並びはシャッフルされない。\n予測用データを格納したReccurentPredictingGeneratorをpredict_generatorメソッドに渡してやればよい。\n記事が長くなったため、generatorの使い方は後編に分けた。\nKerasの時系列予測でgeneratorを使って大容量データを扱う 後編\n参考 今回と次回の記事のコードをまとめたものをGithubにおいている。\nhttps://gist.github.com/helve2017/c20d6106a5dab00a8afa942584b60580\nKerasの公式リファレンス。\nSequentialモデル - Keras Documentation\nユーティリティ - Keras Documentation\n","description":"Kerasの時系列予測で、Recurrentレイヤに入力するためのデータを生成するgeneratorクラスの作り方について述べる。","id":47,"section":"posts","tags":["Python","Keras"],"title":"Kerasの時系列予測でgeneratorを使って大容量データを扱う 前編","uri":"https://helve2017.github.io/posts/python/keras-rnn-generator-1/"},{"content":"はじめに KerasのRNN, GRU, LSTMレイヤを使って時系列データを学習させる。Kerasを初めて使われる方は、以下の記事を参考にして下さい。\nKeras入門 ニューラルネットワークによる正弦波の回帰\n環境    ソフトウェア バージョン     Anaconda3 5.2.0   Python 3.6.5   TensorFlow 1.12.0   keras 2.2.4   NumPy 1.14.3   matplotlib 2.2.2    KerasとTensorFlowがインストールされていなければ、Anaconda Promptで以下の通りインストールする。\n1 2  conda install tensorflow conda install keras   次に、Pythonで以下の通りライブラリをインポートする。\n1 2 3 4  import numpy as np import matplotlib.pyplot as plt from keras.models import Sequential from keras.layers import Dense, SimpleRNN, GRU, LSTM   Recurrentレイヤ Kerasには、いくつかのRecurrent（再帰）レイヤが実装されている。本稿ではRNN, GRU, LSTMを使って、学習速度を簡単に比較する。\nRNN (Recurrent Neural Network) は、1ステップ前の出力を自身の入力として与えることで、過去の情報を利用できる。ただし、RNNでは長期間のデータを扱えないため、GRU (Gated Recurrent Unit) やLSTM (Long Short Term Memory) が使われることが多い。\nGRUとLSTMは、RNNを改良したレイヤであり、より長期間のデータの依存関係を学習できる。GRUはLSTMに比べて学習パラメータが少なく、計算時間が短い特徴がある。\n学習データ 図のように、\n[-1, -1, 0, 0, 1, 1, 0, 0, \u0026hellip;]\nを繰り返す時系列データが与えられたとき、次のステップの値を予測させる。正しく予測するためには、最低でも3個以上の過去のデータを記憶する必要がある。\n例えば、[0, 0]とデータが与えられても、次の値は1か-1か分からない。さらに1ステップ前から[-1, 0, 0]と連続して初めて、次の値が1と予測できる。\nKerasで学習するためのデータの配列の形状は以下のイメージ。\n左側の時系列データを、説明変数xdataと目的変数ydataに変換する。\n1個の目的変数に対して、予測に用いるステップ数がtimestepsである。\n以下のコードで時系列データの生成と変換を行う。\n1 2 3 4 5 6 7 8 9 10 11 12  timesteps = 5 x_base = np.array([-1,-1,0,0,1,1,0,0], dtype=np.float32) x = np.empty(0, dtype=np.float32) for i in range(1000): x = np.hstack([x, x_base]) xdata = np.array([x[i:i+timesteps] for i in range(len(x)-timesteps)]) xdata = xdata.reshape(xdata.shape[0], timesteps, -1) ydata = x[timesteps:].reshape(xdata.shape[0], -1)   timestepsは5とした。\nまた、reshapeメソッドを使って、\nxdataは（データ数×timesteps×説明変数の数）の3次元配列、\nydataは（データ数×目的変数の数）の2次元配列\nにそれぞれ変換している。\nkerasによる学習 NNモデル 説明変数と目的変数の次元はともに1なので、入力層と出力層のノード数は1となる。\n1層目をRNNレイヤ、2層目を全結合(Dense)レイヤとする。\n中間ノード数はそれぞれ10とし、活性化関数はtanhとする。\n1 2 3 4 5 6 7  actfunc = \u0026#34;tanh\u0026#34; model = Sequential() model.add(SimpleRNN(10, activation=actfunc, batch_input_shape=(None, timesteps, 1))) model.add(Dense(10, activation=actfunc)) model.add(Dense(1))   なお、SimpleRNNレイヤのbatch_input_shapeには、\n（バッチ数、学習データのステップ数、説明変数の数）\nをタプルで指定する。\nバッチ数は学習時に指定するので、ここではNoneとする。\nまた、GRUレイヤやLSTMレイヤに変更する場合は、以下のようにSimpleRNNをGRU, LSTMに変更するだけでよい。\n1 2  model.add(GRU(10, activation=actfunc, batch_input_shape=(None, timesteps, 1)))   1 2  model.add(LSTM(10, activation=actfunc, batch_input_shape=(None, timesteps, 1)))   学習の実行 NNモデルにデータを学習させる。PCの性能によるが、数十秒程度で終了する。\n1 2 3 4 5 6 7  model.compile(optimizer=\u0026#39;sgd\u0026#39;, loss=\u0026#39;mean_squared_error\u0026#39;) history = model.fit(xdata, ydata, batch_size=100, epochs=500, verbose=1)   学習モデルの評価 学習したモデルから予測値を出力する（簡単のため、学習データから予測させる）。\n1 2 3 4 5 6 7 8 9 10  pred = model.predict(xdata) fig, ax = plt.subplots() ax.plot(ydata[:20, :].reshape(-1), linewidth=0, marker=\u0026#34;o\u0026#34;, markersize=8) ax.plot(pred[:20, :].reshape(-1), linewidth=0, marker=\u0026#34;o\u0026#34;, markersize=5) ax.set_xticks(np.arange(0, 20, 2)) ax.set_yticks([-1, 0, 1]) ax.legend([\u0026#34;training\u0026#34;, \u0026#34;prediction\u0026#34;]) ax.grid() plt.show()   出力\n学習データと予測値の最初の20点を比較する（予測値はRNNで学習したモデルから出力したもの）。学習データと予測値は一致しており、うまく学習できたことが分かる。\n次に、RNN, GRU, LSTMの損失関数の変化を比較する。損失関数の履歴は、historyから次のように取得できる。\n1  loss = history.history[\u0026#34;loss\u0026#34;]   各モデルの損失関数の変化をプロットする。\n1 2 3 4 5 6  fig, ax = plt.subplots() ax.plot(loss_rnn) ax.plot(loss_gru) ax.plot(loss_lstm) ax.legend([\u0026#34;RNN\u0026#34;, \u0026#34;GRU\u0026#34;, \u0026#34;LSTM\u0026#34;]) plt.show()   出力\n縦軸が損失関数、横軸がエポック数である。RNN, GRU, LSTMの順に損失関数の減少が速い。実際、各レイヤの学習パラメータはこの順に多くなっており、今回の学習速度と比較して妥当な結果である。\n※今回の学習データではRNNでも十分に精度の高い予測ができたが、当然、学習パラメータが多いほどレイヤの表現力が高いため、より複雑な時系列データの特徴を抽出できる可能性が高い。\n参考 Recurrentレイヤー - Keras Documentation\n再帰型ニューラルネットワーク: RNN入門 - Qiita\n初心者のRNN(LSTM) | Kerasで試してみる - Qiita\n","description":"KerasのRNN, GRU, LSTMレイヤを使って時系列データを学習させる。","id":48,"section":"posts","tags":["Python","Keras"],"title":"Kerasを使ったRNN, GRU, LSTMによる時系列予測","uri":"https://helve2017.github.io/posts/python/keras-recurrent-neural-network/"},{"content":"はじめに 以前、Chainerの入門記事を書いたが、実装が容易なKerasを試してみた。ニューラルネットワーク (NN) による回帰の実装例として、正弦波を学習させる。KerasのバックエンドにはTensorFlowを使う。\n環境 ソフトウェアのバージョンは以下の通り。\n   ソフトウェア バージョン     Anaconda3 5.2.0   Python 3.6.5   TensorFlow 1.12.0   Keras 2.2.4   NumPy 1.14.3   matplotlib 2.2.2    Anaconda Promptにて以下の通りインストールする。\n1 2  conda install tensorflow conda install keras   次に、Pythonで以下の通りライブラリをインポートする。\n1 2 3 4  import numpy as np import matplotlib.pyplot as plt from keras.models import Sequential from keras.layers import Dense   学習データ x=-5～5の範囲で正弦波を生成する。データ数は10,000点である。\nなお、学習を高速化するためには扱う変数を全て標準化する必要があるが、簡単のため今回はそのままの値を用いる。\n1 2 3 4 5 6  x = np.arange(-5, 5, 0.001).astype(np.float32) y = np.sin(x) fig, ax = plt.subplots() ax.plot(x, y) plt.show()   出力\nKerasによる学習 NNモデル 説明変数と目的変数の次元はともに1なので、入力層と出力層のノード数は1となる。\n隠れ層の数は4、ノード数は全て20とした。また、活性化関数はtanhとする。\n1 2 3 4 5 6 7 8  actfunc = \u0026#34;tanh\u0026#34; model = Sequential() model.add(Dense(20, activation=actfunc, input_dim=1)) model.add(Dense(20, activation=actfunc)) model.add(Dense(20, activation=actfunc)) model.add(Dense(20, activation=actfunc)) model.add(Dense(1))   以上の様に、Sequentialインスタンスを作成し、addメソッドで層を追加していく。なお、Denseは全結合層である。\n学習の実行 modelのcomplieメソッドで最適化手法と損失関数を指定する。\n最適化手法にはSGD (Stochastic Gradient Descent, 確率的勾配降下法) を用い、損失関数は予測値と真値の二乗平均誤差 (mean squared error) とする。\n次に、fitメソッドで学習を実行する。\n学習データx, yを与え、バッチサイズ、エポック数を指定する。\nverbose引数は、下表の通り学習の進行状況の表示に関するオプション。\n   verbose ログの表示     0 出力しない   1 プログレスバーで出力   2 損失関数のみの簡易表示    また、historyには学習時のログが格納される。\n1 2 3 4 5 6 7  model.compile(optimizer=\u0026#39;sgd\u0026#39;, loss=\u0026#39;mean_squared_error\u0026#39;) history = model.fit(x, y, batch_size=100, epochs=50, verbose=1)   出力\n実行すると、以下の通り学習の進行状況が表示される。\nPCの性能によるが、数秒程度で学習は終了する。\n1 2 3 4 5 6 7 8 9 10 11 12 13  Epoch 1/50 10000/10000 [==============================] - 1s 109us/step - loss: 0.2431 Epoch 2/50 10000/10000 [==============================] - 0s 9us/step - loss: 0.0159 Epoch 3/50 10000/10000 [==============================] - 0s 8us/step - loss: 0.0104 Epoch 4/50 10000/10000 [==============================] - 0s 8us/step - loss: 0.0091 Epoch 5/50 10000/10000 [==============================] - 0s 8us/step - loss: 0.0087 （略） Epoch 50/50 10000/10000 [==============================] - 0s 8us/step - loss: 0.0032   学習モデルの評価 evaluateメソッドで検証用データに対する損失関数の値を出力する。\n本来は学習データと検証データを分ける必要があるが、簡単のため同じデータとしている。\n1 2  score = model.evaluate(x, y) print(score)   出力\n学習データと検証データが同じため、学習の最終エポックの損失関数に近い値が表示されるはずである。\n1 2  10000/10000 [==============================] - 0s 13us/step 0.0034303181435687293   また、predictメソッドで説明変数に対する予測値を出力する。\n1 2 3 4 5 6  pred = model.predict(x) fig, ax = plt.subplots() ax.plot(x, y) ax.plot(x, pred) plt.show()   出力\n青が学習データ、黄色がNNの出力である。xが-5や5に近い領域でやや異なる値となっているが、概ね正弦波の形状を学習できている。\nまた、学習中の損失関数の推移は、以下のように取得できる。\n1 2 3 4 5  loss = history.history[\u0026#34;loss\u0026#34;] fig, ax = plt.subplots() ax.plot(loss) plt.show()   出力\n横軸がエポック数、縦軸が（学習データに対する）損失関数である。最初の1～2エポックで急激に損失関数が減少し、その後は緩やかに単調減少していることが分かる。\n参考 Home - Keras Documentation\n","description":"Kerasを使い、ニューラルネットワーク (NN) に正弦波を学習させる。","id":49,"section":"posts","tags":["Python","Keras"],"title":"Keras入門 ニューラルネットワークによる正弦波の回帰","uri":"https://helve2017.github.io/posts/python/keras-introduction/"},{"content":"はじめに Pythonの機械学習用ライブラリScikit-learnに実装されている、スケール変換について調べた。スケール変換を行うクラス3つのパラメータとメソッドをまとめ、各変換の結果を比較した。\nスケール変換は、扱う数値データを何らかの規則で変換するものである。機械学習で桁数の異なるデータをまとめて扱うときには、スケール変換がほぼ必須となる。\n通常、ニューラルネットワークやSVM（サポートベクターマシン）では、スケール変換をしないとなかなか学習が進まない。ただし、ランダムフォレスト等の決定木を使う手法ではスケール変換は不要である。\nこの記事では、以下3つのスケール変換方法を扱う。\n StandardScaler: 標準化（平均0, 分散1） RobustScaler: 外れ値に頑健な標準化 MinMaxScaler: 正規化（最大1, 最小0）  環境 記事執筆時点で使用したライブラリのバージョンは以下の通り。\n   ソフトウェア バージョン     Python 3.6.5   Scikit-learn 0.19.1   NumPy 1.14.3   matplotlib 2.2.2    Pythonで以下の通りライブラリをインポートする。Scikit-learnのpreprocessingモジュールにスケール変換処理がまとめられている。\n1 2 3  import numpy as np import matplotlib.pyplot as plt from sklearn import preprocessing   以下、各スケール変換のパラメータとメソッドについてまとめた結果を記す。\n標準化（平均0, 分散1）する データの平均値と分散を変換する操作を標準化と呼ぶ。平均値を0, 分散を1とすることが多い。変換操作は以下の式で表される。\n$$ Y = \\frac{X-\\mu}{\\sigma} $$\nここで、$Y$は変換後のデータ、$X$は変換前のデータである。また、$\\mu, \\sigma$は、それぞれ$X$の平均、分散である。\nScikit-learnで標準化は、\n関数としてはscale,\nクラスとしてはStandardScaler\nという名前で用意されている。\nStandardScalerクラスを使うと、あるデータに対して行った変換を別のデータに対して適用できる。\n機械学習の場合、学習データに対して行った変換を、検証データに対して行うので、実用上はStandardScalerを使う機会が多いと思う。そのため、本記事ではStandardScalerのみ扱う。\nStandardScalerのパラメータ 1  preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)   StandardScalerクラスの主なパラメータの説明は以下の通り。基本的に全てデフォルトのまま使う。\ncopy\nブール型。デフォルト値はTrue.\nFalseの場合、transformやfit_transformメソッドで変換時に、変換元のデータを破壊的に変換する。Trueの場合、元のデータは変換されない。\nwith_mean\nブール型。デフォルト値はTrue.\nTrueの場合、平均値を0とする。\nFalseの場合、以下の変換になる。\n$Y = \\frac{X}{\\sigma}$\n分散は1になるが、平均が維持されるとは限らない。\nwith_std\nブール型。デフォルト値はTrue.\nTrueの場合、分散を0とする。\nFalseの場合、以下の変換になる。\n$Y = X-\\mu$\n分散は変化せず、平均は0となる。\nStandardScalerのメソッド 良く使うメソッドは次の3つ。\nfit(X)\n配列Xの平均と分散を計算して、記憶する（変換は行わない）。\ntransform(X)\n配列Xに変換を施して、変換後の配列を返す。\nfit_transform(X)\n配列Xに対して、fitとtransformを同時に行う。\nなお、2次元配列を変換する場合、縦 (axis=0) 方向に変換が行われる。\nStandardScalerの使用例 以下の2次元配列xを用意する。\n1 2 3 4  x = np.arange(0, 8, 1.).reshape(-1, 2) print(x) print(x.mean(axis=0)) print(x.std(axis=0))   実行結果\n1 2 3 4 5 6  [[0. 1.] [2. 3.] [4. 5.] [6. 7.]] [3. 4.] [2.23606798 2.23606798]   第0列目の平均は3, 分散は2.24,\n第1列目の平均は4, 分散は2.24である。\n次に、xを標準化する。\n1 2 3 4 5 6 7 8  sscaler = preprocessing.StandardScaler() # インスタンスの作成 sscaler.fit(x) # xの平均と分散を計算 y = sscaler.transform(x) # xを変換 print(y) print(y.mean(axis=0)) print(y.std(axis=0))   実行結果\n以下の通り、変換後の配列yは各列とも平均は0, 分散は1となった。\n1 2 3 4 5 6  [[-1.34164079 -1.34164079] [-0.4472136 -0.4472136 ] [ 0.4472136 0.4472136 ] [ 1.34164079 1.34164079]] [0. 0.] [1. 1.]   ここで、\n1 2  sscaler.fit(x) # xの平均と分散を計算 y = sscaler.transform(x) # xを変換   は、以下と同じである。\n1  y = sscaler.fit_transform(x) # xを変換した結果が返る   外れ値に頑健な標準化 変換前のデータに極端に大きな値または小さな値が含まれていた場合、標準化を行うと大きく結果が変わってしまう。これを避けるため、データの四分位点を基準にして標準化を行う方法がある。\nScikit-learnでこのような変換は、\n関数としてはrobust_scale,\nクラスとしてはRobustScaler\nという名前で用意されている。\n本記事ではRobustScalerのみ扱う。\nRobustScalerの変換操作は以下の式で表される。\n$$ Y = \\frac{X-Q_2}{Q_3-Q_1} $$\nここで、$Y$は変換後のデータ、$X$は変換前のデータである。\nまた、$Q_1, Q_2, Q_3$は、それぞれ$X$の第1～第3四分位点である。\n標準化と比較すると、元のデータの平均が$Q_2$（中央値）、分散が$Q_3-Q_1$であると仮定しているとも考えられる。\nなお、上の式の分母で、どの範囲（パーセンタイル）のデータを使うかは設定で変更可能である。\nRobustScalerのパラメータ 1 2  preprocessing.RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True)   RobustScalerクラスの主なパラメータの説明は以下の通り。\n外れ値の多さに対して、quantile_rangeを変更する。\nwith_centering\nブール型。デフォルト値はTrue.\nTrueの場合、データから中央値を引いて、平均を0とする。\nwith_std\nブール型。デフォルト値はTrue.\nTrueの場合、quantile_rangeで選択したパーセンタイルのデータの差でデータを割る。\nquantile_range\nタプル型。デフォルト値は(25.0, 75.0).\n標準化を行うデータの範囲をパーセンテージで指定する。\n(25.0, 75.0)の場合、下位25%と上位25%にある値の差でデータ全体を割る。\nまた、特徴量が複数ある場合、それぞれの特徴量に対して数値が選ばれる。\nなお、データの値は、NumPyのpercentile関数で取得している。\nこの関数は、パーセンタイルとデータ数が一致しない場合、補間して返す。そのため、データ数が少ない場合や、離散的な場合は注意する。\ncopy\nブール型。デフォルト値はTrue.\nFalseの場合、transformやfit_transformメソッドで変換時に、変換元のデータを破壊的に変換する。\nTrueの場合、元のデータは変換されない。\nRobustScalerのメソッド StandardScalerと同じく、良く使うメソッドは次の3つ。\nfit(X)\ntransform(X)\nfit_transform(X)\nRobustScalerの使用例 以下の2次元配列xを用意する。\n1 2 3 4  x = np.arange(0, 8, 1.).reshape(-1, 2) print(x) print(x.mean(axis=0)) print(x.std(axis=0))   実行結果\n1 2 3 4 5 6  [[0. 1.] [2. 3.] [4. 5.] [6. 7.]] [3. 4.] [2.23606798 2.23606798]   第0列目の平均は3, 分散は2.24,\n第1列目の平均は4, 分散は2.24である。\n次に、xを標準化する。下位25%と上位25%、すなわち[0. 1.]と[6. 7.]が無視される。\n1 2 3 4 5 6 7 8  rscaler = preprocessing.RobustScaler(quantile_range=(25., 75.)) rscaler.fit(x) y = rscaler.transform(x[1:3]) print(y) print(y.mean(axis=0)) print(y.std(axis=0))   実行結果\n以下の通り、変換後の配列yは各列とも平均は0, 分散は0.745となった。\n1 2 3 4 5 6  [[-1. -1. ] [-0.33333333 -0.33333333] [ 0.33333333 0.33333333] [ 1. 1. ]] [0. 0.] [0.74535599 0.74535599]   正規化（最大1, 最小0）する データの最大値と最小値を制限する変換を正規化と呼ぶ。最大値を1, 最小値を0とすることが多い。\n変換操作は以下の式で表される。\n$$Y = \\frac{X-x_{\\min}}{x_{\\max}-x_{\\min}}$$\nここで、$Y$は変換後のデータ、$X$は変換前のデータである。\nまた、$x_{\\min}, x_{\\max}$は、それぞれ$X$の最小値、最大値である。\nScikit-learnで正規化は、\n関数としてはminmax_scale,\nクラスとしてはMinMaxScaler\nという名前で用意されている。\n標準化と同様に、本記事ではMinMaxScalerクラスのみ扱う。\nMinMaxScalerのパラメータ 1  preprocessing.MinMaxScaler(feature_range=(0, 1), copy=True)   MinMaxScalerクラスの主なパラメータの説明は以下の通り。\nfeature_range\nタプル型。デフォルト値は(0, 1).\n変換後の最大値、最小値を設定する。\ncopy\nブール型。デフォルト値はTrue.\nFalseの場合、transformやfit_transformメソッドで変換時に、\n変換元のデータを破壊的に変換する。\nTrueの場合、元のデータは変換されない。\nMinMaxScalerのメソッド StandardScalerと同じく、良く使うメソッドは次の3つ。\nfit(X)\ntransform(X)\nfit_transform(X)\nMinMaxScalerの使用例 標準化と同じ2次元配列xを用意する。\n1 2 3 4  x = np.arange(0, 6, 1.).reshape(-1, 2) print(x) print(x.min(axis=0)) print(x.max(axis=0))   実行結果\n1 2 3 4 5  [[0. 1.] [2. 3.] [4. 5.]] [0. 1.] [4. 5.]   第0列目の最小値は0, 最大値は4,\n第1列目の最小値は1, 最大値は5である。\n次に、xを正規化する。\n1 2 3 4 5 6 7 8  mmscaler = preprocessing.MinMaxScaler() # インスタンスの作成 mmscaler.fit(x) # xの最大・最小を計算 y = mmscaler.transform(x) # xを変換 print(y) print(y.min(axis=0)) print(y.max(axis=0))   実行結果\n以下の通り、変換後の配列yは各列とも最小値は0, 最大値は1となった。\n1 2 3 4 5  [[0. 0. ] [0.5 0.5] [1. 1. ]] [0. 0.] [1. 1.]   ここで、\n1 2  mmscaler.fit(x) # xの平均と分散を計算 y = mmscaler.transform(x) # xを変換   としたのは、以下のようにしても同じ結果となる。\n1  y = mmscaler.fit_transform(x) # xを変換した結果が返る   各変換の比較 2次元のデータを対象として、スケール変換の効果を散布図で確認する。\n各変換のパラメータはデフォルトとした。\nケース1：平均(0, 0), 分散1 平均が原点、分散が各方向に1の正規分布データ200点を変換する。\nStandardScalerは、変換前とほとんど変わらない。\nRobustScalerは、StandardScalerよりも分散が小さくなっている。\nまた、MinMaxScalerは縦方向・横方向ともに0～1の範囲に収まっている。\nケース2：平均(5, -5), 分散1 平均が(5, -5), 分散が各方向に1の正規分布データ200点を変換する。\nStandardScalerは、データの分布形状をほぼ保ったまま変換できている。\nケース3：平均(0, 0), 分散2 平均が(0, 0), 分散が各方向に2とした正規分布データ200点を変換する。\n分散が2なので、各方向とも-2～2の範囲に約65%, -4～4の範囲に約95%のデータがある。\nStandardScalerでは分散が約半分となり、-1～1の範囲に約65%, -2～2の範囲に約95%のデータがあることになる。\nケース4：外れ値を加えた場合 ケース1のデータに、平均(5, 5), 分散1のデータを10点追加する。\nケース1の散布図をスケールを揃えて比較する。\nRobustScalerでは、外れ値を除く分布の形状が、外れ値を加える前と後で変化していない。\n一方、StandardScaler, MinMaxScalerでは、分布の形状が外れ値によって変化している。\nケース1（外れ値なし）\nケース4（外れ値あり）\nケース1～4のソースコードは以下の通り。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  def plotScaler(x, xlim=(None, None), ylim=(None, None)): sscaler = preprocessing.StandardScaler() rscaler = preprocessing.RobustScaler() mmscaler = preprocessing.MinMaxScaler() xs = sscaler.fit_transform(x) xr = rscaler.fit_transform(x) xm = mmscaler.fit_transform(x) fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(8,8)) ax[0,0].scatter(x[:,0], x[:,1]) ax[0,0].set_title(\u0026#34;Default\u0026#34;) ax[0,1].scatter(xs[:,0], xs[:,1]) ax[0,1].set_title(\u0026#34;StandardScaler\u0026#34;) ax[1,0].scatter(xr[:,0], xr[:,1]) ax[1,0].set_title(\u0026#34;RobustScaler\u0026#34;) ax[1,1].scatter(xm[:,0], xm[:,1]) ax[1,1].set_title(\u0026#34;MinMaxScaler\u0026#34;) for i in range(ax.shape[0]): for j in range(ax.shape[1]): ax[i,j].axis(\u0026#34;square\u0026#34;) ax[i,j].grid() ax[1,1].set_xlim(xlim) ax[1,1].set_ylim(ylim) plt.show() np.random.seed(0) # ケース1: 平均(0,0), 分散１ x1 = np.random.randn(200, 2) plotScaler(x1, xlim=(-3, 3), ylim=(-3, 3)) # ケース2: 平均(5,-5), 分散１ x2_0 = np.random.randn(200, 1)+5 x2_1 = np.random.randn(200, 1)-5 x2 = np.hstack([x2_0, x2_1]) plotScaler(x2) # ケース3: 平均(0,0), 分散2 x3 = np.random.randn(200, 2)*2 plotScaler(x3) # ケース4: ケース1に(5, 5), 分散１の外れ値を10点追加 x4_0 = np.random.randn(10, 2)+5 x4 = np.vstack([x1, x4_0]) plotScaler(x1, xlim=(-3, 8), ylim=(-3, 8)) plotScaler(x4, xlim=(-3, 8), ylim=(-3, 8))   参考 sklearn.preprocessing.StandardScaler — scikit-learn 0.24.0 documentation\nsklearn.preprocessing.RobustScaler — scikit-learn 0.24.0 documentation\nsklearn.preprocessing.MinMaxScaler — scikit-learn 0.24.0 documentation\nSklearnのpreprocessingの全メソッドを解説 | 自調自考の旅\nFeature Scaling with scikit-learn – Ben Alex Keen\n","description":"Pythonの機械学習用ライブラリScikit-learnに実装されている、スケール変換について調べた。","id":50,"section":"posts","tags":["Python","Scikit-learn"],"title":"Scikit-learnでデータをスケール変換する","uri":"https://helve2017.github.io/posts/python/scikit-learn-feature-scaling/"},{"content":"はじめに Scikit-learnの回帰木やランダムフォレスト回帰のクラスには、Feature Importances (FI) という説明変数の重要度を示す指標があるが、導出について公式のリファレンスに書かれていなかったため調べた。\n結論から述べると、各説明変数による予測誤差の二乗平均の減少量に対して、データ点数の重みを掛けて求めた値である。\n記事執筆時点でのバージョンは以下の通り。\n   ソフトウェア バージョン     Python 3.6.5   Scikit-learn 0.19.1    回帰木のFI ランダムフォレスト回帰は、複数の回帰木の集合であるので、初めに回帰木のFIを確認する。\n公式リファンレスには、FIについて以下のように記述されている。\n The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance.\nsklearn.tree.DecisionTreeRegressor — scikit-learn 0.24.0 documentation\n すなわち、説明変数ごとに、ジニ重要度 (Gini importance) と呼ばれる基準量の減少量を（正規化したものを）合算して得られる、とある。\nしかし、ネット上にはGini importanceに関する目ぼしい資料は見つからなかった（ジニ係数やジニ特徴量に関する資料はあるが）。\nそこで、自分でプログラムを動かして動作を確認する。\nまず、3つの説明変数X0, X1, X2と、目的変数Yを用意し、\nDecisionTreeRegressorで学習させる。\n1 2 3 4 5 6 7 8 9 10 11 12  import numpy as np import pandas as pd from sklearn import tree X0 = np.array([0,0,1,1]).reshape(-1, 1) X1 = np.array([0,1,0,0]).reshape(-1, 1) X2 = np.array([0,0,0,1]).reshape(-1, 1) X = np.hstack([X0, X1, X2]) Y = np.array([1,2,3,4]) t = tree.DecisionTreeRegressor(max_depth=3, random_state=0) t.fit(X, Y)   回帰木をGraphVizで可視化する。\n1  tree.export_graphviz(t, \u0026#34;tree.dot\u0026#34;)   図の四角は、回帰木の各ノードを示す。\n四角の中の説明は以下の通り。\n 1行目の不等式が成り立つ場合は、左側のノードに進む。成り立たない場合は、右のノードに進む。 mse は平均二乗誤差 (MSE, Mean Squared Error) 。 samples はデータ点数。 value は予測値。  この中で、mseとsamplesに着目する。\n1段目のノードでは、X0 (X[0])によって、4点のデータのMSEが1.25から0.25に減少している。\nまた、2段目のノードでは、X1 (X[1]), X2 (X[2])によって、それぞれ分岐後の2点のデータのMSEが0.25から0に減少している。\n次にFIを表示する。\n1  print(pd.Series(t.feature_importances_, index=[\u0026#34;X0\u0026#34;, \u0026#34;X1\u0026#34;, \u0026#34;X2\u0026#34;]))   実行結果\n1 2 3  X0 0.8 X1 0.1 X2 0.1   ここで、X0, X1, X2によるMSEの減少量に対してデータ点数を掛けると、それぞれ、\nX0: (1.25 - 0.25)*4 = 4\nX1: (0.25 - 0)*2 = 0.5\nX2: (0.25 - 0)*2 = 0.5\nとなる。\n減少量の合計が1となるように正規化すると、\nX0: 4/(4+0.5+0.5) = 0.8\nX1: 0.5/(4+0.5+0.5) = 0.1\nX2: 0.5/(4+0.5+0.5) = 0.1\nとなり、FIと一致している。\nすなわち、FIは予測誤差の二乗平均の減少量に対して、データ点数の重みを掛けて正規化した値となる。\nランダムフォレスト回帰のFI ランダムフォレストのFIの計算方法についても、Scikit-learnの公式リファレンスには書かれていない。\nしかし、ソースコードを見ると、決定木ごとにFIが計算され、それらの平均がランダムフォレストのFIとなっている（scikit-learnのforest.py 359～375行目、BaseForestクラスより。このクラスは、RandomForestRegressorが継承している）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @property def feature_importances_(self): \u0026#34;\u0026#34;\u0026#34;Return the feature importances (the higher, the more important the feature). Returns ------- feature_importances_ : array, shape = [n_features] \u0026#34;\u0026#34;\u0026#34; check_is_fitted(self, \u0026#39;estimators_\u0026#39;) all_importances = Parallel(n_jobs=self.n_jobs, backend=\u0026#34;threading\u0026#34;)( delayed(getattr)(tree, \u0026#39;feature_importances_\u0026#39;) for tree in self.estimators_) return sum(all_importances) / len(self.estimators_)   ","description":"Scikit-learnの回帰木やランダムフォレスト回帰のクラスには、Feature Importances (FI) という説明変数の重要度を示す指標がある。これは、各説明変数による予測誤差の二乗平均の減少量に対して、データ点数の重みを掛けて求めた値である。","id":51,"section":"posts","tags":["Python","Scikit-learn"],"title":"Scikit-learn ランダムフォレスト回帰のfeature_importances_の定義","uri":"https://helve2017.github.io/posts/python/scikit-learn-feature-importances/"},{"content":"はじめに ディープラーニングのライブラリKerasを導入した。\nこのとき、Kerasがバックエンドで使用するTensorflowのインストールにやや詰まったため、備忘録として手順を残す。\nNehalem以前のCPUを持つPCでは、Tensorflowのバージョンを1.5とする必要がある。\n環境 サブのノートPC（2010年製）にインストールした。PythonのインストールにはAnacondaを使用している。\n OS: Linux Mint Ver. 19 CPU: Intel Core 2 Duo U9400  ソフトウェアのバージョンは以下の通り。\n   ソフトウェア バージョン     Conda 4.5.8   Python 3.6.5   Tensorflow 1.5   Keras 2.2.4    Tensorflowのインストール KerasのバックエンドとしてTensorflowが必要なため、まずTensorflowからインストールする。CPUが古いのでTensorflowのバージョンを1.5に落とす。ターミナルに以下を入力する。\n1  $ pip install tensorflow==1.5   次にPythonを起動してTensorflowをインポートし、インストールが成功したか確認する。\n1  $ python   1 2 3 4 5 6 7 8 9  \u0026gt;\u0026gt;\u0026gt; import tensorflow /home/ysd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters \u0026gt;\u0026gt;\u0026gt; hello = tf.constant(\u0026#39;Hello, TensorFlow!\u0026#39;) \u0026gt;\u0026gt;\u0026gt; sess = tf.Session() 2018-10-28 21:16:18.140490: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 \u0026gt;\u0026gt;\u0026gt; sess = tf.Session() \u0026gt;\u0026gt;\u0026gt; print(sess.run(hello)) b\u0026#39;Hello, TensorFlow!\u0026#39;   NumpyのFutureWarningが出たが、ひとまず成功した。\nちなみに、Tensorflowの最新版(v1.11)をインストールすると、pipインストール時は問題がなさそうに見えるが、Pythonでインポート時にエラーが発生してPythonが矯正終了していまう。\n1 2 3 4 5 6 7 8 9  $ pip install tensorflow （中略） $ python Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import tensorflow Illegal instruction (コアダンプ) $   原因は、Tensorflowの1.5.1以降でAVXという命令セットを使用してコンパイルしており、これにNehalem世代以前のCPUが対応していないためらしい。\nTensorflowを1.6以上にすると、CPUによっては実行できなくなる／tensorflowのバージョン指定インストールの方法 - \u0026lsquo;BOKU\u0026rsquo;のITな日常\nIntel AVX ‐ 通信用語の基礎知識\nこれを回避するため、GitからTensorflowのソースコードを落として自分でコンパイルすると、古いPCUでも最新のTensorflowを使えそうだが、本稿では扱わない。\nKerasのインストール Kerasの最新版をインストールしても特に問題はなかった。\n1 2 3 4 5 6 7 8 9 10  $ pip install keras （中略） $ python Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import keras /home/ysd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters Using TensorFlow backend.   ","description":"Nehalem以前のCPUを持つPCでは、Tensorflowのバージョンを1.5とする。","id":52,"section":"posts","tags":["Python","TensorFlow"],"title":"TensorflowをNehalem以前のPCへの導入する方法","uri":"https://helve2017.github.io/posts/python/tensorflow-nehalem-install/"},{"content":"はじめに 「ベイズ推論による機械学習入門」を読んだので、ベイズ推論（ベイズ推定）への理解を深めるため、多次元ガウス分布の学習をPythonで実装した。\n参考にしたのは、講談社 機械学習スタートアップシリーズの「ベイズ推論による機械学習入門」（須山敦志 著）。3.4節「多次元ガウス分布の学習と予測」から、平均と精度（分散共分散行列）が共に未知の場合における学習について実装した。\nまた、学習したパラメータを用いて、未観測データを予測するための分布（予測分布）も構築した。\nなお、以下のブログに離散確率分布（ベルヌーイ分布・カテゴリ分布・ポアソン分布）と1次元ガウス分布の学習の実装例があったため、併せて参考にさせて頂いた。\n「ベイズ推論による機械学習入門」を読んだので実験してみた (その1)\n環境    ソフトウェア バージョン     python 3.6.5   numpy 1.14.3   scipy 1.1.0   matplotlib 2.2.2    以下では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2 3 4  import math import numpy as np import scipy.stats import matplotlib.pyplot as plt   ベイズ学習について ベイズ学習は、観測データと未知パラメータに対する同時確率分布を構築し、観測データが得られたときの未知パラメータの事後分布を求める手法である。\nここでは、多次元ガウス分布の平均と精度が未知パラメータとなる。\n多次元ガウス分布のベイズ推論 $D$次元の多次元ガウス分布は、次式で表される。\n$$ \\mathcal{N}(x|\\mu, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^D|\\Sigma|}} \\exp \\biggl( -\\frac{1}{2} (x-\\mu)^\\top \\Sigma^{-1} (x-\\mu) \\biggl) $$\nここで、$ \\mu \\in \\mathbb{R}^D$ は平均、$ \\Sigma \\in \\mathbb{R}^{D \\times D}$は分散共分散行列である。\nただし、$\\Sigma$は正定値行列（固有値が全て非負）でなければならない。\n後々の数式を簡単にするため、精度行列$\\Lambda = \\Sigma^{-1}$を導入する。\n$\\mu, \\Lambda$が推定したいパラメータになる。\n$\\mu, \\Lambda$の確率分布を表現する共役事前分布は、ガウス・ウィシャート分布となる。\n$$ \\begin{array}{rl} p(\\mu, \\Lambda) \u0026amp;=\u0026amp; NW(\\mu, \\Lambda | m, \\beta, \\nu, W) \\\\ \u0026amp;=\u0026amp; \\mathcal{N}(\\mu | m, (\\beta \\Lambda)^{-1}) \\mathcal{W}(\\Lambda | \\nu, W) \\end{array} $$\nここで、$m, \\beta, \\nu, W$はガウス・ウィシャート分布のパラメータである。初期値は以下の条件を満たすように適当に与える。\n $m \\in \\mathcal{R}^{D}$: 実数ベクトル $\\beta \\in \\mathcal{R}$: 実数 $\\nu \\in \\mathcal{R}$: $\\nu \u0026gt; D-1$を満たす実数 $W \\in \\mathcal{R}^{D \\times D}$: 正定値行列（固有値が全て非負）  事後分布を計算すると、ガウス・ウィシャート分布のパラメータはそれぞれ以下のように与えられる（詳細は本を参照）。\n$$ \\hat{\\beta} = N + \\beta $$\n$$ \\hat{m} = \\frac{1}{\\hat{\\beta}} \\left( \\sum_{n=1}^N x_n + \\beta m \\right) $$\n$$ \\hat{W}^{-1} = \\sum_{n=1}^N x_n x_n^{\\top} + \\beta mm^{\\top} - \\hat{\\beta} \\hat{m} \\hat{m}^{\\top} + W^{-1} $$\n$$ \\hat{\\nu} = N + \\nu $$\n学習したガウス・ウィシャート分布のパラメータを使って、未観測のデータ$x$を予測する。予測分布は$x\\in \\mathbb{R}^D$上の多次元版のスチューデントのt分布となる。\n$$ \\mathrm{St} (x|\\mu_s, \\Lambda_s, \\nu_s) = \\frac{\\Gamma( \\frac{\\nu_s+D}{2}) }{\\Gamma( \\frac{\\nu_s}{2})} \\frac{|\\Lambda_s|^{\\frac{1}{2}}}{(\\pi \\nu_s)^{\\frac{D}{2}}} \\biggl( 1+\\frac{1}{\\nu_s} (x-\\mu_s)^{\\top} \\Lambda_s (x-\\mu_s) \\biggl)^{-\\frac{\\nu_s +D}{2} } $$\nここで、スチューデントのt分布のパラメータは、ガウス・ウィシャート分布のパラメータを使って次式で与えられる。\n$$ \\mu_s = m $$\n$$ \\Lambda_s = \\frac{(1-D+\\nu)\\beta}{1+\\beta}W $$\n$$ \\nu_s = 1-D+\\nu $$\nまた、$\\Gamma(\\bullet)$はガンマ関数と呼ばれる関数である。\n学習が進むにつれて、スチューデントのt分布の形状は、元の多次元ガウス分布の形状に近づいていく。\n実装 ガウス・ウィシャート分布のパラメータ推定 観測データXから、ガウス・ウィシャート分布のパラメータの推定値$\\hat{m}, \\hat{\\beta}, \\hat{\\nu}, \\hat{W}$を推定する関数を以下のように実装する。\nただし、計算効率は重視せず、数式通りに実装することを優先している。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  def multivariate_normal_fit(X): N = X.shape[0] # Number of samples D = X.shape[1] # Dimension of sample beta = 1 m = np.zeros(D) W_inv = np.linalg.inv(np.diag(np.ones(D))) nu = D beta_hat = N + beta m_hat = (X.sum(axis=0)+beta*m)/beta_hat X_sum = np.zeros([D, D]) for i in range(N): X_sum += np.dot(X[i].reshape(-1,1), X[i].reshape(1,-1)) W_hat_inv = X_sum + beta*np.dot(m.reshape(-1,1), m.reshape(1,-1)) \\ - beta_hat*np.dot(m_hat.reshape(-1,1), m_hat.reshape(1,-1)) + W_inv nu_hat = N + nu return m_hat, beta_hat, nu_hat, W_hat_inv   多次元版のスチューデントのt分布 学習後の確率分布を確認するため、多次元版のスチューデントのt分布をクラスとして実装する。\n確率密度関数 (Probability Density Function, PDF) を求めるため、pdfメソッドを用意した。pdfメソッドに配列を引数として与えると、その配列に対応する確率を返す。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class multivariate_student_t(): def __init__(self, mu, lam, nu): # mu: D size array, lam: DxD matrix, nu: scalar self.D = mu.shape[0] self.mu = mu self.lam = lam self.nu = nu def pdf(self, x): temp1 = np.exp( math.lgamma((self.nu+self.D)/2) - math.lgamma(self.nu/2) ) temp2 = np.sqrt(np.linalg.det(self.lam)) / (np.pi*self.nu)**(self.D/2) if x.shape[0]==1: temp3 = 1 + np.dot(np.dot((x-self.mu).T, self.lam), x-self.mu)/self.nu else: temp3 = [] for a in x: temp3 += [1 + np.dot(np.dot((a-self.mu).T, self.lam), a-self.mu)/self.nu] temp4 = -(self.nu+self.D)/2 return temp1*temp2*(np.array(temp3)**temp4)   ここで、ガンマ関数の自然対数を返すmath.lgammaで実装した。\nガンマ関数math.gammaは大きな値を取り得ることがあり、以下のようにオーバーフローが生じる場合があるためである。\n1 2 3 4 5 6 7  \u0026gt;\u0026gt;\u0026gt; math.gamma(200) Traceback (most recent call last): File \u0026#34;\u0026lt;ipython-input-31-4fa9aaaad750\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; math.gamma(200) OverflowError: math range error   パラメータの学習 学習の結果を確認する。図示できるように、データの次元は$D=2$とする。\nまず、多次元ガウス分布に従うサンプルデータを生成する。\nここで、データの平均は$(x_1, x_2)=(0, 1)$であり、正の相関を持つ。\n1 2 3 4 5 6 7 8  np.random.seed(0) mean = np.array([0, 1]) cov = np.array([[2, 1], [1, 2]]) Ns = 100 # Number of samples X = np.random.multivariate_normal(mean, cov, Ns) # Sample data   サンプルデータを散布図にプロットする。\n1 2 3 4 5 6 7 8 9 10  fig, ax = plt.subplots(figsize=(8, 4)) ax.scatter(X[:,0], X[:,1]) ax.axis(\u0026#39;square\u0026#39;) ax.set_xlim(-5,5) ax.set_ylim(-5,5) ax.grid() ax.set_xlabel(\u0026#34;x1\u0026#34;) ax.set_ylabel(\u0026#34;x2\u0026#34;) fig.tight_layout() plt.show()   次に、関数multivariate_normal_fitから、ガウス・ウィシャート分布のパラメータを求める。\n1  m_hat, beta_hat, nu_hat, W_hat_inv = multivariate_normal_fit(X)   得られたパラメータをスチューデントのt分布のパラメータに変換し、\nmultivariate_student_tオブジェクトを作成する。\n1 2 3 4 5 6  D = m_hat.shape[0] mu_hat = m_hat lam_hat = (1-D+nu_hat)*beta_hat*np.linalg.inv(W_hat_inv) / (1+beta_hat) nu_hat = 1 - D + nu_hat mt = multivariate_student_t(mu_hat, lam_hat, nu_hat)   最後に、元のガウス分布の形状と、推定したスチューデントのt分布の形状を比較する。\n両確率分布の確率を、x1, x2とも-5～5の範囲で求める。\n1 2 3 4 5 6 7 8  X1, X2 = np.meshgrid(np.arange(-5, 5, 0.1), np.arange(-5, 5, 0.1)) Y = np.vstack([X1.ravel(), X2.ravel()]).T mn_pdf = scipy.stats.multivariate_normal.pdf(Y, mean=mean, cov=cov) mn_pdf = mn_pdf.reshape(X1.shape[0], -1) mt_pdf = mt.pdf(Y) mt_pdf = mt_pdf.reshape(X1.shape[0], -1)   これらをヒートマップに表示する。色が濃いほど確率が高いことを表す。\nこのように、推定した確率密度関数と、元の確率密度関数はほぼ一致している。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  fig, ax = plt.subplots(ncols=2, figsize=(10, 4)) ax0 = ax[0].pcolor(X1, X2, mn_pdf, cmap=\u0026#34;Blues\u0026#34;, vmin=0, vmax=0.1) ax1 = ax[1].pcolor(X1, X2, mt_pdf, cmap=\u0026#34;Blues\u0026#34;, vmin=0, vmax=0.1) for i in range(2): ax[i].axis(\u0026#39;equal\u0026#39;) ax[i].grid() ax[i].set_xlabel(\u0026#34;x1\u0026#34;) ax[i].set_ylabel(\u0026#34;x2\u0026#34;) ax[0].set_title(\u0026#34;Original PDF\u0026#34;) ax[1].set_title(\u0026#34;Inferred PDF\u0026#34;) plt.colorbar(ax=ax[0], mappable=ax0) plt.colorbar(ax=ax[1], mappable=ax1) fig.tight_layout() plt.show()   以上をまとめたコードは以下の通り。\n\r\rクリックして展開\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102  import math import numpy as np import scipy.stats import matplotlib.pyplot as plt class multivariate_student_t(): def __init__(self, mu, lam, nu): # mu: D size array, lam: DxD matrix, nu: scalar self.D = mu.shape[0] self.mu = mu self.lam = lam self.nu = nu def pdf(self, x): temp1 = np.exp( math.lgamma((self.nu+self.D)/2) - math.lgamma(self.nu/2) ) temp2 = np.sqrt(np.linalg.det(self.lam)) / (np.pi*self.nu)**(self.D/2) if x.shape[0]==1: temp3 = 1 + np.dot(np.dot((x-self.mu).T, self.lam), x-self.mu)/self.nu else: temp3 = [] for a in x: temp3 += [1 + np.dot(np.dot((a-self.mu).T, self.lam), a-self.mu)/self.nu] temp4 = -(self.nu+self.D)/2 return temp1*temp2*(np.array(temp3)**temp4) def multivariate_normal_fit(X): N = X.shape[0] # Number of samples D = X.shape[1] # Dimension of sample beta = 1 m = np.zeros(D) W_inv = np.linalg.inv(np.diag(np.ones(D))) nu = D beta_hat = N + beta m_hat = (X.sum(axis=0)+beta*m)/beta_hat X_sum = np.zeros([D, D]) for i in range(N): X_sum += np.dot(X[i].reshape(-1,1), X[i].reshape(1,-1)) W_hat_inv = X_sum + beta*np.dot(m.reshape(-1,1), m.reshape(1,-1)) \\ - beta_hat*np.dot(m_hat.reshape(-1,1), m_hat.reshape(1,-1)) + W_inv nu_hat = N + nu return m_hat, beta_hat, nu_hat, W_hat_inv if __name__==\u0026#34;__main__\u0026#34;: np.random.seed(0) mean = np.array([0, 1]) cov = np.array([[2, 1], [1, 2]]) Ns = 100 # Number of samples X = np.random.multivariate_normal(mean, cov, Ns) # Sample data fig, ax = plt.subplots(figsize=(8, 4)) ax.scatter(X[:,0], X[:,1]) ax.axis(\u0026#39;square\u0026#39;) ax.set_xlim(-5,5) ax.set_ylim(-5,5) ax.grid() ax.set_xlabel(\u0026#34;x1\u0026#34;) ax.set_ylabel(\u0026#34;x2\u0026#34;) fig.tight_layout() plt.show() m_hat, beta_hat, nu_hat, W_hat_inv = multivariate_normal_fit(X) D = m_hat.shape[0] mu_hat = m_hat lam_hat = (1-D+nu_hat)*beta_hat*np.linalg.inv(W_hat_inv) / (1+beta_hat) nu_hat = 1 - D + nu_hat mt = multivariate_student_t(mu_hat, lam_hat, nu_hat) X1, X2 = np.meshgrid(np.arange(-5, 5, 0.1), np.arange(-5, 5, 0.1)) Y = np.vstack([X1.ravel(), X2.ravel()]).T mn_pdf = scipy.stats.multivariate_normal.pdf(Y, mean=mean, cov=cov) mn_pdf = mn_pdf.reshape(X1.shape[0], -1) mt_pdf = mt.pdf(Y) mt_pdf = mt_pdf.reshape(X1.shape[0], -1) fig, ax = plt.subplots(ncols=2, figsize=(10, 4)) ax0 = ax[0].pcolor(X1, X2, mn_pdf, cmap=\u0026#34;Blues\u0026#34;, vmin=0, vmax=0.1) ax1 = ax[1].pcolor(X1, X2, mt_pdf, cmap=\u0026#34;Blues\u0026#34;, vmin=0, vmax=0.1) for i in range(2): ax[i].axis(\u0026#39;equal\u0026#39;) ax[i].grid() ax[i].set_xlabel(\u0026#34;x1\u0026#34;) ax[i].set_ylabel(\u0026#34;x2\u0026#34;) ax[0].set_title(\u0026#34;Original PDF\u0026#34;) ax[1].set_title(\u0026#34;Inferred PDF\u0026#34;) plt.colorbar(ax=ax[0], mappable=ax0) plt.colorbar(ax=ax[1], mappable=ax1) fig.tight_layout() plt.show()   \r\r また、学習データのサンプル数Nsを5, 10, 100と変えて、推定精度に与える影響を調べる。下図のように、Nsが増えるほど、元の確率密度分布（左上）に近づいている。\n","description":"ベイズ推論（ベイズ推定）への理解を深めるため、多次元ガウス分布の学習をPythonで実装した。","id":53,"section":"posts","tags":["統計学"],"title":"ベイズ推論による多次元ガウス分布の学習","uri":"https://helve2017.github.io/posts/math/bayesian-inference-multivariate-gaussian-distribution/"},{"content":"はじめに 前回の記事で、ChainerのChainクラスとOptimizerを使って最小限のニューラルネットワーク (NN) を実装した。今回は、データセットから学習用ミニバッチを作成してくれるIteratorクラスの動作を確認する。\n環境    ソフトウェア バージョン     Spyder 3.2.8   Python 3.6.5   NumPy 1.14.3   Chainer 4.2.0    以下では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2 3 4 5 6 7  import numpy as np import matplotlib.pyplot as plt import chainer import chainer.links as L import chainer.functions as F from chainer import optimizers, Chain, dataset, datasets, iterators import matplotlib.pyplot as plt   Iteratorクラス Iteratorクラスは、データセットの説明変数と目的変数を束ねたミニバッチ作成や、データ順序のシャッフルを行ってくれるクラスである。Chainer 4.2.0では以下3つのIteratorが利用可能である。\n   クラス 説明     SerialIterator 最も単純なIterator   MultiprocessIterator multiprocessingモジュールにより並列化   MultithreadIterator threadingモジュールにより並列化    本記事ではSerialIteratorクラスを扱う。\n1 2  chainer.iterators.SerialIterator(dataset, batch_size, repeat=True, shuffle=True)   パラメータの説明は以下の通り。\ndataset:\n反復させるデータセット。\nbatch_size: int型\n各ミニバッチのサンプル数。\nrepeat: bool型\nTrueの場合、無限に反復させる。\nFalseの場合、全てのデータ(1エポック分)を返すと反復を終える。\nshuffle: bool型\nTrueの場合、ランダムな順序でデータを返す。\nFalseの場合、datasetと同じ順序で返す。\nSerialIteratorの動作を確認する。\nスクリプト\n1 2 3 4 5 6 7 8 9  np.random.seed(0) data = np.arange(3) data = chainer.Variable(data) ite = chainer.iterators.SerialIterator(data, batch_size=2, repeat=True, shuffle=True) for i in range(5): print(ite.next())   上のスクリプトでは、データの順序を固定するため、np.random.seed(0)としてNumPyの乱数シードを設定している。\n0, 1, 2の3つの数字からなる配列をVariableオブジェクトとして、SerialIteratorにセットする。\nバッチ数は2として、データを返す順序はランダムとする。\nSerialIteratorオブジェクトiteのnext()メソッドを実行すると、バッチ数だけデータが返される。\n実行結果\n1 2 3 4 5  [variable(2), variable(1)] [variable(0), variable(0)] [variable(2), variable(1)] [variable(0), variable(1)] [variable(2), variable(2)]   実行結果を見ると、Variableオブジェクトがbatch_size数だけリスト形式で返されている。\nデータ(0, 1, 2)を一通り返すと、同じリストであっても継続してデータを返している。\nTupleDatasetによるデータセット作成 Iteratorクラスにセットするデータセットを用意する場合、TupleDatasetを用いると便利である。\n1  chainer.datasets.TupleDataset(*datasets)   datasetsは任意の数のデータ変数である。ただし、データは全て同じ長さ（行数）でなければならない。\nTupleDatasetの主なメソッドは次の2つ。\ngetitem(index):\nindexで指定した要素をタプルで返す。\nlen:\nデータの長さ（行数）を返す。\n例えば、2つのNumPy配列d1, d2を引数として、次のようにTupleDatasetオブジェクトを作る。\n1 2 3 4 5 6 7 8 9 10 11 12  d1 = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float32) d2 = np.array([[7], [9], [8]], dtype=np.float32) dataset = datasets.TupleDataset(d1, d2) print(dataset.__len__()) for i in range(3): print(dataset.__getitem__(i))   実行結果\n1 2 3 4  3 (array([1., 2.], dtype=float32), array([7.], dtype=float32)) (array([3., 4.], dtype=float32), array([9.], dtype=float32)) (array([5., 6.], dtype=float32), array([8.], dtype=float32))   データの長さは3, また、__getitem__メソッドにより、d1, d2の要素が1行ずつ取り出されている。\n次に、TupleDatasetオブジェクトをSerialIteratorにセットしてみる。バッチ数は2とする。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  d1 = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float32) d2 = np.array([[7], [9], [8]], dtype=np.float32) data_set = datasets.TupleDataset(d1, d2) ite = iterators.SerialIterator(data_set, batch_size=2, repeat=True, shuffle=True) for i in range(5): print(ite.next())   実行結果\n1 2 3 4 5  [(array([5., 6.], dtype=float32), array([8.], dtype=float32)), (array([1., 2.], dtype=float32), array([7.], dtype=float32))] [(array([3., 4.], dtype=float32), array([9.], dtype=float32)), (array([5., 6.], dtype=float32), array([8.], dtype=float32))] [(array([1., 2.], dtype=float32), array([7.], dtype=float32)), (array([3., 4.], dtype=float32), array([9.], dtype=float32))] [(array([3., 4.], dtype=float32), array([9.], dtype=float32)), (array([5., 6.], dtype=float32), array([8.], dtype=float32))] [(array([1., 2.], dtype=float32), array([7.], dtype=float32)), (array([3., 4.], dtype=float32), array([9.], dtype=float32))]   このように、各ite.next()毎に、d1とd2の各行がネストされたタプルで得られる。\nite.next()の結果をd1, d2毎にまとめるためには、chainer.dataset.concat_examples()を用いる。（評価関数にデータを与えるときに必要）\n1  dataset.concat_examples(ite.next())   実行結果\n1 2 3 4  (array([[5., 6.], [3., 4.]], dtype=float32), array([[8.], [9.]], dtype=float32))   実装例 Iteratorを使った学習例を示す。前回の記事のスクリプトを改良した。\n学習するデータの順序をランダムに入れ替える以外、前回と同じ学習条件である。\n線形モデル y=x-5 を学習させる。\n説明変数 x は0～9.9まで0.1刻みで100点とする。\nまた、教師データの目的変数には、平均0, 分散0.1の正規分布に従う信号をノイズとして加えた。\nこの教師データを100回反復させて学習させる（エポック数100）。\nまた、教師データを2点ずつ与えるバッチ処理を行う。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  import numpy as np import chainer import chainer.links as L import chainer.functions as F from chainer import optimizers, Chain, dataset, datasets import matplotlib.pyplot as plt class MyChain(Chain): def __init__(self): super(MyChain, self).__init__() with self.init_scope(): self.l1 = L.Linear(None, 3) self.l2 = L.Linear(3, 1) def __call__(self, x): h = F.relu(self.l1(x)) return self.l2(h) def lossfun(train_y, pred_y): loss = F.mean_squared_error(train_y, pred_y) return loss np.random.seed(0) batch_size = 2 # バッチ数 n_epoch = 100 # エポック数 model = MyChain() optimizer = optimizers.SGD().setup(model) x_data = np.arange(0, 10, 0.1, dtype=np.float32).reshape(-1,1) # 説明変数 y_data = x_data-5 + 0.1*np.random.randn(len(x_data)).reshape(-1,1) y_data = y_data.astype(np.float32) # 目的変数 data_set = datasets.TupleDataset(x_data, y_data) ite = chainer.iterators.SerialIterator(data_set, batch_size=batch_size, repeat=True, shuffle=True) pred_y_before = model(x_data) # 学習前の予測値 mean_err = [] # 平均予測誤差 for epoch in range(n_epoch): err_temp = 0 for i in range(0, x_data.shape[0], batch_size): batch = ite.next() train_x, train_y = dataset.concat_examples(batch) pred_y = model(train_x) optimizer.update(lossfun, train_y, pred_y) err_temp += F.mean_squared_error(train_y, pred_y).data*batch_size mean_err += [err_temp/x_data.shape[0]] pred_y_after = model(x_data) # 学習後の予測値 fig, ax = plt.subplots() ax.plot(x_data, y_data, label=\u0026#34;True values\u0026#34;) ax.plot(x_data, pred_y_before.data, label=\u0026#34;Before learning\u0026#34;) ax.plot(x_data, pred_y_after.data, label=\u0026#34;After learning\u0026#34;) ax.set_xlabel(\u0026#34;x\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) ax.legend() ax.grid() plt.show() fig, ax = plt.subplots() ax.plot(mean_err) ax.set_xlabel(\u0026#34;Epoch\u0026#34;) ax.set_ylabel(\u0026#34;Mean squared error\u0026#34;) ax.grid() plt.show()   学習前後のモデルの予測値は次のようになった（青が教師データ、黄色が学習前の予測値、緑が学習後の予測値）。\n学習によって、予測値が教師データに近づいている。\nまた、エポックごとの予測の二乗平均誤差は以下の通り。\nデータをシャッフルしなかった前回と比べ、誤差の減少が速くなっている。\n参考リンク chainer.iterators.SerialIterator — Chainer 7.7.0 documentation\n","description":"データセットから学習用ミニバッチを作成してくれるIteratorクラスの動作を確認する。","id":54,"section":"posts","tags":["Python","Chainer"],"title":"ChainerのIteratorクラスによる学習用ミニバッチ作成","uri":"https://helve2017.github.io/posts/python/chainer-iterator-class/"},{"content":"はじめに ディープラーニング用のライブラリChainerの使い方を理解するため、ChainerのChainクラスとOptimizerを使って最小限のニューラルネットワーク (NN) を実装する。実装後、1次関数を学習させる。\n環境    ソフトウェア バージョン     Spyder 3.2.8   Python 3.6.5   NumPy 1.14.3   Chainer 4.2.0    以下では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2 3 4 5 6  import numpy as np import matplotlib.pyplot as plt import chainer import chainer.links as L import chainer.functions as F from chainer import optimizers, Chain   Chainクラスを使ったNNの構造定義 GPUで並列計算を行う場合などに再利用性を高めるため、NNの構造はクラスを定義して書かれることが多い。\n例えば、2層のNNをMyChainクラスとして次のように記述する。\n1 2 3 4 5 6 7 8 9 10  class MyChain(Chain): def __init__(self): super(MyChain, self).__init__() with self.init_scope(): self.l1 = L.Linear(1, 2) self.l2 = L.Linear(2, 1) def __call__(self, x): h = F.relu(self.l1(x)) return self.l2(h)   MyChainはChainerのChainクラスを親クラスとして継承している。\n2行目の__init__関数は、MyChainクラスのオブジェクトが作成されるときに、実行される関数である。\n6, 7行目のL.Linearは全結合層のクラスであり、第1引数は入力信号の数、第2引数は出力信号の数である。\n8行目の__call__関数は、MyChainオブジェクトに引数を与えて呼び出すと、実行される関数である。ここでは、NNの順方向の計算を定義している。\nOptimizer（最適化ルーチン） NNのパラメータを更新するには、optimizersオブジェクトを用いる。\n以下に、実装の主要部分を示す。\n1 2 3 4 5 6 7 8 9 10  def lossfun(train_y, pred_y): loss = F.mean_squared_error(train_y, pred_y) return loss model = MyChain() optimizer = optimizers.SGD() optimizer.setup(model) pred_y = model(train_x) optimizer.update(lossfun, train_y, pred_y)   1～3行目のlossfunは、NNの学習に使用する損失関数である。ここでは、評価指標を教師データと推定値の二乗平均誤差 (Mean squared errors) としている。\n次に、5～7行目で、MyChainオブジェクトを作成し、optimizersオブジェクトに渡している。ここでは、パラメータの更新規則は確率的勾配降下法 (SGD, stochastic gradient descent)とした。\n9行目では、NNに説明変数train_xを渡して、予測値pred_yを得ている。\n10行目では、optimizersのupdateメソッドに、評価関数lossfunとその引数（pred_yと目的変数の真値train_y）を渡して、modelのパラメータを更新している。\nなお、updateに引数を渡さない方法もあるが、modelの勾配を消去する (cleargrads) 操作が必要になるため、今回は簡単なこちらの方法を用いた。\n実装例 上記のMyChainクラスと、Optimizerを使って、実際に学習を行う。\nここでは、線形モデル y=x-5 を学習させる。\n説明変数 x は0～9.9まで0.1刻みで100点とする。\nまた、教師データの目的変数には、平均0, 分散0.1の正規分布に従う信号をノイズとして加えた。\nこの教師データを100回反復させて学習させる（エポック数100）。\nまた、教師データを2点ずつ与えるバッチ処理を行う。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69  import numpy as np import chainer import chainer.links as L import chainer.functions as F from chainer import optimizers, Chain import matplotlib.pyplot as plt class MyChain(Chain): def __init__(self): super(MyChain, self).__init__() with self.init_scope(): self.l1 = L.Linear(1, 2) self.l2 = L.Linear(2, 1) def __call__(self, x): h = F.relu(self.l1(x)) return self.l2(h) def lossfun(x, y): loss = F.mean_squared_error(x, y) return loss np.random.seed(0) model = MyChain() x_data = np.arange(0, 10, 0.1, dtype=np.float32).reshape(-1,1) x = chainer.Variable(x_data) y = chainer.Variable(x_data-5) optimizer = optimizers.SGD().setup(model) n_epoch = 200 batch_size = 2 pred_y_before = model(x_data) # Prediction before learning mean_err = [] for epoch in range(n_epoch): err_temp = 0 for i in range(0, x.shape[0], batch_size): train_y = y[i:i+batch_size] train_x = x[i:i+batch_size] pred_y = model(train_x) optimizer.update(lossfun, train_y, pred_y) err_temp += F.mean_squared_error(train_y, pred_y).data*batch_size mean_err += [err_temp/x.shape[0]] pred_y_after = model(x_data) # Prediction after learning fig, ax = plt.subplots() ax.plot(x_data.data, y.data, label=\u0026#34;True values\u0026#34;) ax.plot(x_data.data, pred_y_before.data, label=\u0026#34;Before learning\u0026#34;) ax.plot(x_data.data, pred_y_after.data, label=\u0026#34;After learning\u0026#34;) ax.legend() ax.grid() plt.show() fig, ax = plt.subplots() ax.plot(mean_err) ax.set_xlabel(\u0026#34;Epoch\u0026#34;) ax.set_ylabel(\u0026#34;Mean squared error\u0026#34;) ax.grid() plt.show()   何もしなければL.Linearの重み行列Wは毎回ランダムに初期化されるため、np.random.seed(0)によって、Wの初期値を固定している。\nまた、mean_errには各エポックにおける予測値の二乗誤差平均を格納している。\n学習前後のモデルの予測値は次のようになった（青が教師データ、黄色が学習前の予測値、緑が学習後の予測値）。学習によって、予測値が教師データに近づいている。\nまた、エポックごとの予測の二乗平均誤差は以下の通り。\n時折増加しつつも、学習回数が増えるにつれて減少している。\n参考リンク Creating Models — Chainer 7.7.0 documentation\nOptimizer — Chainer 7.7.0 documentation\n","description":"ディープラーニング用のライブラリChainerの使い方を理解するため、Chainerの`Chain`クラスと`Optimizer`を使って最小限のニューラルネットワーク (NN) を実装する。","id":55,"section":"posts","tags":["Python","Chainer"],"title":"Chainer入門 最小限のニューラルネットワーク実装","uri":"https://helve2017.github.io/posts/python/chainer-introduction/"},{"content":"はじめに SciPyを使って、FIR (Finite Impulse Response, 有限インパルス応答) フィルタによる離散信号の波形を整形する。ローパス、ハイパス、バンドパス、バンドエリミネイトの各フィルタの設計から、信号への適用まで行う。\n環境    ソフトウェア バージョン     Python 3.6.5   NumPy 1.14.2   SciPy 1.0.1    元の離散信号 次の3つの信号を合成して、フーリエ変換を行う離散信号とする。\n 周波数30[Hz], 振幅3の正弦波 周波数50[Hz], 振幅0.3の正弦波 周波数120[Hz], 振幅0.2の正弦波  信号のデータ点数は2048, サンプリング周期は0.001[s]とする。\n1 2 3 4 5 6 7 8 9 10  import numpy as np import matplotlib.pyplot as plt from scipy import signal N = 1024 # サンプル数 dt = 0.001 # サンプリング周期 [s] f1, f2, f3 = 10, 60, 300 # 周波数 [Hz] t = np.arange(0, N*dt, dt) # 時間 [s] x = 3*np.sin(2*np.pi*f1*t) + 0.3*np.sin(2*np.pi*f2*t) + 0.2*np.sin(2*np.pi*f3*t) # 信号   SciPyの関数 フィルタの設計 まず、関数scipy.signal.firwin()によりフィルタを設計する。\n1 2 3  scipy.signal.firwin(numtaps, cutoff, width=None, window=\u0026#39;hamming\u0026#39;, pass_zero=True, scale=True, nyq=None, fs=None)   主な引数の説明は以下の通り。\nnumtaps: int\nFIRフィルタの長さ。\ncutoff: float or 1D array_like\nカットオフ周波数。\nローパス、ハイパスの場合はfloat,\nバンドパス、バンドエリミネイトの場合は1D array_likeとする。\ncutoffは0からfs/2の間にしなければならない。\nwindow: string\n窓関数を指定する。デフォルトは\u0026rsquo;hamming' （ハミング窓）。\npass_zero: bool\n周波数0（直流成分）が通過するか指定。\nデフォルトはTrue.\nfs: float\n信号のサンプル周波数。デフォルト値は2.\nscipy.signal.firwin()の戻り値は、長さnumtapsのFIRフィルタの係数配列となる。\nフィルタの適用 次に、関数scipy.signal.lfilter()により信号にフィルタを適用する。\n1  scipy.signal.lfilter(b, a, x, axis=-1, zi=None)   主な引数の説明は以下の通り。\nb: array\n分子の係数。\na: array\n分母の係数。\nx: array\n入力信号。\n戻り値は、フィルタを掛けた信号の配列となる。\nこの関数では、フィルタが以下の式で表されているものとする。\n$$ H(z)=\\frac{\\sum_{k=0}^{M} b_k z^{-k} } {\\sum_{k=0}^{N} a_k z^{-k} } $$\n引数bが右辺の分子の係数、引数aが右辺の分母の係数に対応する。今回はFIRフィルタを扱うので、分母のaを1とおく。\n波形整形 基本的なフィルタを信号に適用して、波形や振幅の変化を確認する。\nローパスフィルタ カットオフ周波数を40[Hz]としたローパスフィルタ。\n1 2 3 4 5  filter1 = signal.firwin(numtaps=21, cutoff=40, fs=1/dt) y1 = signal.lfilter(filter1, 1, x) F1 = np.fft.fft(y1) Amp1 = np.abs(F1/(N/2))   60, 300[Hz]の高周波成分が減衰・除去されている。\nハイパスフィルタ カットオフ周波数を100[Hz]としたハイパスフィルタ。\n1 2 3 4 5  filter2 = signal.firwin(numtaps=51, cutoff=100, fs=1/dt, pass_zero=False) y2 = signal.lfilter(filter2, 1, x) F2 = np.fft.fft(y2) Amp2 = np.abs(F2/(N/2))   10, 60[Hz]の低周波成分が除去されている。\nバンドパスフィルタ 通過周波数を30～100[Hz]としたバンドパスフィルタ。\n1 2 3 4 5  filter3 = signal.firwin(numtaps=51, cutoff=[30, 100], fs=1/dt, pass_zero=False) y3 = signal.lfilter(filter3, 1, x) F3 = np.fft.fft(y3) Amp3 = np.abs(F3/(N/2))   10, 300[Hz]の信号が減衰・除去されいている。\nバンドエリミネイトフィルタ 通過周波数を30[Hz]以下、100[Hz]以上としたバンドエリミネイトフィルタ。\n1 2 3 4 5  filter4 = signal.firwin(numtaps=31, cutoff=[30, 100], fs=1/dt) y4 = signal.lfilter(filter4, 1, x) F4 = np.fft.fft(y4) Amp4 = np.abs(F4/(N/2))   60[Hz]の信号が除去されいている。\n参考リンク scipy.signal.firwin — SciPy v1.5.4 Reference Guide\nscipy.signal.lfilter — SciPy v1.5.4 Reference Guide\n","description":"SciPyを使って、FIR (Finite Impulse Response, 有限インパルス応答) フィルタによる離散信号の波形を整形する。ローパス、ハイパス、バンドパス、バンドエリミネイトの各フィルタの設計から、信号への適用まで行う。","id":56,"section":"posts","tags":["Python","SciPy"],"title":"SciPyを使ったFIRフィルタによる波形整形","uri":"https://helve2017.github.io/posts/python/scipy-finite-impulse-response-filter/"},{"content":"はじめに NumPyのempty関数を用いて、np.empty(0), np.empty([0, 0]), \u0026hellip;とすることで、空の（要素を持たない）任意の次元の配列を作成できる。本記事では、空の配列の作り方、使い方について簡単に考察する。\n環境    ソフトウェア バージョン     NumPy 1.19    本記事では、以下の通りライブラリをインポートしていることを前提とする。\n1  import numpy as np   numpy.emptyについて numpy.emptyは、中身を初期化せずに配列を作成する関数である。\n主な引数は次の通り。\n1  numpy.empty(shape, dtype=float)   shapeは配列の形状を決める引数であり、\n int intを格納するタプル intを格納するリスト  のいずれかをとる。\ndtypeは配列の数値の型を決める引数であり、\n int float np.float32 np.int8  などを指定する（デフォルトはfloat）。\n要素数が5つの1次元配列を生成するには、shapeを5、または(5)、または[5]とする。ただし、配列の中身は変わる場合がある。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; np.empty(5) array([0. , 0.25, 0.5 , 0.75, 1. ]) \u0026gt;\u0026gt;\u0026gt; np.empty((5)) array([0. , 0.25, 0.5 , 0.75, 1. ]) \u0026gt;\u0026gt;\u0026gt; np.empty([5]) array([0. , 0.25, 0.5 , 0.75, 1. ])   要素数が2×3の2次元配列を生成するには、shapeを(2, 3)、または[2, 3]とする。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; np.empty((2, 3)) array([[0.93137112, 0.92761264, 0.98531337], [0.28813119, 0.49620105, 0.41308828]]) \u0026gt;\u0026gt;\u0026gt; np.empty([2, 3]) array([[0.93137112, 0.92761264, 0.98531337], [0.28813119, 0.49620105, 0.41308828]])   numpy.emptyは、中身が全て0の配列を生成するnumpy.zeros()や、中身が全て1の配列を生成するnumpy.ones()と比較すると、配列を高速に生成できる利点がある。\n空の配列の生成 冒頭に記したように、numpy.emptyのshapeを0や[0, 0], \u0026hellip;とすると、任意の次元の空の配列を生成できる。\n1次元配列の場合\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; a1 = np.empty(0) \u0026gt;\u0026gt;\u0026gt; a1 array([], dtype=float64) \u0026gt;\u0026gt;\u0026gt; a1.ndim # 次元数 1   2次元配列の場合\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; a2 = np.empty([0, 0]) \u0026gt;\u0026gt;\u0026gt; a2 array([], shape=(0, 0), dtype=float64) \u0026gt;\u0026gt;\u0026gt; a2.ndim # 次元数 2   同様に、\n np.empty([0, 0, 0])で3次元の空の配列 np.empty([0, 0, 0, 0])で4次元の空の配列  がそれぞれ生成できる。\nなお、zeros関数やones関数を使って、\n np.zeros(0) np.ones([0, 0])  としても、同様に空の配列を作成できる。\nしかし、関数名と異なり要素に0や1を含まない配列が生成されて紛らわしいため、empty関数を使うべきだと個人的に思う。\n空の配列の使い方 空の配列は、「配列を結合したいが、最終的に得られる配列のサイズが分からない場合」、あるいは「計算の規模が小さく、かつプログラムの可読性を重視したい場合」に用いるべきである。\n配列を逐次的に結合すると、その都度メモリを確保する必要があるため、実行速度が低下する。\nそのため、最終的な配列のサイズが分かっている場合には、初めに必要なサイズの配列を確保して、逐次的に配列を代入した方が速く実行できる。\n比較のため、配列を結合する関数stack()と、最初に配列を確保する関数substitute()を作成した。両者とも、長さが1000で要素が全て1の配列を返す。関数stack()では長さ1の配列を1000回結合し、関数substitute()では最初に確保した配列に長さ1の配列を1000回代入している。\n1 2 3 4 5 6 7 8 9 10 11  def stack(): a = np.empty(0) for i in range(1000): a = np.hstack([a, np.array(1)]) return a def substitute(): a = np.empty(1000) for i in range(1000): a[i] = np.array(1) return a   IPythonの%timeitマジックコマンドで実行速度を測定する。\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; %timeit stack() 5.93 ms ± 147 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) \u0026gt;\u0026gt;\u0026gt; %timeit substitute() 436 µs ± 17.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)   すなわち、stack()関数とsubstitute()関数の平均実行時間はそれぞれ5.93ミリ秒と436マイクロ秒である。したがって、最初に配列を確保したsubstitute()の方が約14倍高速に実行できた。\n参考 numpy.empty — NumPy v1.19 Manual\n","description":"NumPyのempty関数を用いて、空の（要素を持たない）任意の次元の配列を作成できる。本記事では、空の配列の作り方、使い方について簡単に考察する。","id":57,"section":"posts","tags":["Python","NumPy"],"title":"NumPyのemptyで空（長さ0）の配列を作る","uri":"https://helve2017.github.io/posts/python/numpy-empty-array/"},{"content":"はじめに NumPyのfftパッケージを使って、FFT (Fast Fourier Transform, 高速フーリエ変換) による離散信号の周波数解析を行い、信号の振幅を求める。\n環境    ソフトウェア バージョン     NumPy 1.19    FFTの前処理 信号にFFTを掛ける前に、ローパスフィルタと窓関数を掛ける必要がある。詳細は以下のサイトを参照のこと。\n11. スペクトル解析と窓関数 (やる夫で学ぶディジタル信号処理)\n本記事では簡単のため、これらの前処理を省略する。\nFFTを掛ける離散信号 次の3つの信号を合成して、フーリエ変換を行う離散信号とする。\n 周波数50[Hz], 振幅1.5の正弦波 周波数120[Hz], 振幅1の正弦波 定数項3  信号のデータ点数は1024, サンプリング周期は0.001[s]とする。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import numpy as np import matplotlib.pyplot as plt N = 1024 # サンプル数 dt = 0.001 # サンプリング周期 [s] f1, f2 = 50, 120 # 周波数 [Hz] t = np.arange(0, N*dt, dt) # 時間 [s] x = 1.5*np.sin(2*np.pi*f1*t) + np.sin(2*np.pi*f2*t) + 3 # 信号 fig, ax = plt.subplots() ax.plot(t, x) # ax.set_xlim(0, 0.1) ax.set_xlabel(\u0026#34;Time [s]\u0026#34;) ax.set_ylabel(\u0026#34;Signal\u0026#34;) ax.grid() plt.show()   信号の波形を次のグラフに示す。\n信号を0～0.1[s]の範囲に拡大した図は次の通り。\nフーリエ変換の関数 前章の信号に対して、関数numpy.fft.fft()によりフーリエ変換を行う。\n1  numpy.fft.fft(a, n=None, axis=-1, norm=None)   引数の説明は以下の通り。\na: FFTを行う配列。\nn: FFTを行うデータ点数。Noneとするとaの長さに等しくなる。\naxis: FFTを行う配列の軸方向。指定しなければ、配列の最大次元の方向となる。\nnorm: \u0026ldquo;ortho\u0026quot;とすると正規化する。正規化すると変換値が1/√Nになる（Nはデータ点数）。\nnumpy.fft.fft()の戻り値は、長さnの複素数配列である。\nまた、フーリエ変換の周波数は、関数numpy.fft.fftfreq()により取得する。\n1  numpy.fft.fftfreq(n, d=1.0)   引数の説明は以下の通り。\nn: FFTを行うデータ点数。\nd: サンプリング周期（デフォルト値は1.0）。\nnumpy.fft.fftfreq()戻り値は、周波数を表す配列となる。\n先程の信号xに対してFFTを行い、変換結果の実部、虚部、周波数をプロットする。\n1 2 3 4 5 6 7 8 9 10 11 12  F = np.fft.fft(x) # 変換結果 freq = np.fft.fftfreq(N, d=dt) # 周波数 fig, ax = plt.subplots(nrows=3, sharex=True, figsize=(6,6)) ax[0].plot(F.real, label=\u0026#34;Real part\u0026#34;) ax[0].legend() ax[1].plot(F.imag, label=\u0026#34;Imaginary part\u0026#34;) ax[1].legend() ax[2].plot(freq, label=\u0026#34;Frequency\u0026#34;) ax[2].legend() ax[2].set_xlabel(\u0026#34;Number of data\u0026#34;) plt.show()   周波数freqにおいて、\n 最初の要素freq[0]は0[Hz] 2～N/2 (=512) 番目の要素freq[1:512]は正の周波数 (N/2+1)番目以降の要素freq[512:]は負の周波数  である。\n元の信号の周波数が1000[Hz]であるから、サンプリング定理（または標本化定理）より、その1/2以下の周波数 (500[Hz]以下) でフーリエ変換の結果は有効である。\nグラフより、周波数が0, 50, 120, -120, -50[Hz]のときに、実部や虚部がピーク値を持つことが分かる。\n最後に、元の信号の振幅を求める。FをN/2で割り、絶対値をとると振幅になる。正の周波数領域 について振幅をプロットする。\n1 2 3 4 5 6 7 8  Amp = np.abs(F/(N/2)) # 振幅 fig, ax = plt.subplots() ax.plot(freq[1:int(N/2)], Amp[1:int(N/2)]) ax.set_xlabel(\u0026#34;Freqency [Hz]\u0026#34;) ax.set_ylabel(\u0026#34;Amplitude\u0026#34;) ax.grid() plt.show()   結果は以下の通り。\n振幅は、周波数50[Hz]で約1.42, 120[Hz]で約0.98となっており、元の値（50[Hz]で約1.5, 120[Hz]で1.0）に近い値となっている。\n参考リンク Discrete Fourier Transform (numpy.fft) — NumPy v1.19 Manual\n","description":"NumPyのfftパッケージを使って、FFT (Fast Fourier Transform, 高速フーリエ変換) による離散信号の周波数解析を行い、信号の振幅を求める。","id":58,"section":"posts","tags":["Python","NumPy"],"title":"NumPyを使った高速フーリエ変換による周波数解析","uri":"https://helve2017.github.io/posts/python/numpy-fast-fourier-transform/"},{"content":"はじめに matplotlibにはスタイルと呼ばれる、グラフの見た目を変更できるプリセットが用意されている。\nスタイルを活用することで、グラフの見た目を簡単に変更できる。\n環境    ソフトウェア バージョン     Anaconda3 5.2.0   Python 3.6.5   matplotlib 2.2.2    はじめに 本記事では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2  import matplotlib as mpl import matplotlib.pyplot as plt   スタイルの設定 以下のコマンドでmatplotlibで利用できるスタイルの一覧をリスト形式で取得できる。\n1  plt.style.available   実行結果\nmatplotlibのバージョンや、他にインストールしているライブラリによって異なる場合がある。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  [\u0026#39;bmh\u0026#39;, \u0026#39;classic\u0026#39;, \u0026#39;dark_background\u0026#39;, \u0026#39;fast\u0026#39;, \u0026#39;fivethirtyeight\u0026#39;, \u0026#39;ggplot\u0026#39;, \u0026#39;grayscale\u0026#39;, \u0026#39;seaborn-bright\u0026#39;, \u0026#39;seaborn-colorblind\u0026#39;, \u0026#39;seaborn-dark-palette\u0026#39;, \u0026#39;seaborn-dark\u0026#39;, \u0026#39;seaborn-darkgrid\u0026#39;, \u0026#39;seaborn-deep\u0026#39;, \u0026#39;seaborn-muted\u0026#39;, \u0026#39;seaborn-notebook\u0026#39;, \u0026#39;seaborn-paper\u0026#39;, \u0026#39;seaborn-pastel\u0026#39;, \u0026#39;seaborn-poster\u0026#39;, \u0026#39;seaborn-talk\u0026#39;, \u0026#39;seaborn-ticks\u0026#39;, \u0026#39;seaborn-white\u0026#39;, \u0026#39;seaborn-whitegrid\u0026#39;, \u0026#39;seaborn\u0026#39;, \u0026#39;Solarize_Light2\u0026#39;, \u0026#39;tableau-colorblind10\u0026#39;, \u0026#39;_classic_test\u0026#39;]   この中の1つをplt.style.useで設定すると、グラフの見た目を変更できる。\n例\n1 2 3 4 5 6 7 8 9 10 11  plt.style.use(\u0026#39;ggplot\u0026#39;) fig, ax = plt.subplots() ax.plot([1,2], [6,3]) ax.plot([1,2], [4,5]) ax.plot([1,2], [3,4]) ax.set_xlabel(\u0026#34;x label\u0026#34;) ax.set_ylabel(\u0026#34;y label\u0026#34;) ax.set_title(style+\u0026#34; style\u0026#34;) ax.legend([\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;], title=\u0026#34;Legend\u0026#34;) plt.show()   実行結果\nなお、デフォルトのグラフは以下の通り。\n注意したいのが、あるスタイルを設定した後に、別のスタイルを設定しても、グラフの表示に関するパラメータが全て上書きされないこと。例えば、\u0026quot;fast\u0026quot;スタイルで上書きされるパラメータは、わずか3個である。\nグラフの見た目を試行錯誤して所望の表示になったとしても、Pythonを再び立ち上げると、同じ表示にならない場合がある。\nスタイルの表示例 主なグラフを描画してみる（いずれもデフォルトから直接変更した場合）。\ngrayscale モノクロ印刷する場合に。\nseaborn seabornから逆輸入されたのかもしれない。\nなお、公式リファレンスに各スタイルで出力したグラフの一覧がある。\nStyle sheets reference — Matplotlib 3.3.3 documentation\nさらにグラフの見た目を変更する スタイルのパラメータ設定ファイルは以下のディレクトリにある。\nAnaconda3\\Lib\\site-packages\\matplotlib\\mpl-data\\stylelib\n拡張子がmplstyleとなっているが、テキストエディタで編集可能である。\n自分でスタイル設定ファイルを作成すれば、スクリプトを描くたびに細かい設定を変更する手間が省ける。\nまた、現在の設定は以下のコマンドで確認できる。\n1  mpl.rcParams   実行結果\n1 2 3 4 5 6  RcParams({\u0026#39;_internal.classic_mode\u0026#39;: False, \u0026#39;agg.path.chunksize\u0026#39;: 0, \u0026#39;animation.avconv_args\u0026#39;: [], \u0026#39;animation.avconv_path\u0026#39;: \u0026#39;avconv\u0026#39;, \u0026#39;animation.bitrate\u0026#39;: -1, （以下略）   RcParamsを変更することで、スタイル設定ファイルを書き換えずにグラフの見た目を変更できる。\nまた、同じスクリプト内であれば、グラフ作成の度に設定する必要はなくなる。例えば、グラフにグリッドを表示したい場合、以下のように設定する。\n1  mpl.rcParams[\u0026#34;axes.grid\u0026#34;] = True   参考 matplotlib.style — Matplotlib 3.3.3 documentation\nmatplotlibのstyleを変える - Qiita\n","description":"matplotlibにはスタイルと呼ばれる、グラフの見た目を変更できるプリセットが用意されている。スタイルを活用することで、グラフの見た目を簡単に変更できる。","id":59,"section":"posts","tags":["Python","Matplotlib"],"title":"Matplotlib スタイルによるグラフの見た目の変更","uri":"https://helve2017.github.io/posts/python/matplotlib-object-oriented-style/"},{"content":"はじめに matplotlibライブラリで作成したヒートマップや等高線図のカラーバーを、オブジェクト指向スタイルで調整する。\nオブジェクト指向によるグラフの描画は、複数のグラフをプロットしたときに、どのグラフの描画を調整しているか分かりやすいという利点がある。\n環境    ソフトウェア バージョン     Spyder 3.3.6   Python 3.7.4   matplotlib 3.1.1    本記事では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2  import numpy as np import matplotlib.pyplot as plt   カラーバーの表示 等高線図やヒートマップにカラーバーを表示するには、Figureオブジェクトのcolorbarメソッドを用いる。\n1  Figure.colorbar(mappable, ax=None)   主な引数の説明は以下の通り。\nmappable: ヒートマップを描画するpcolorや、等高線図を描画するcontourから返されるオブジェクトである。\nax: カラーバーを描画するAxesオブジェクトを指定する（任意）。\nヒートマップの例 2つのヒートマップの横に、それぞれカラーバーを表示する。\n1 2 3 4 5 6 7 8 9 10 11 12  x = np.arange(0,10) y = np.arange(0,5) X, Y = np.meshgrid(x, y) Z = np.arange(50).reshape(len(y), -1) fig, ax = plt.subplots(ncols=2) mappable0 = ax[0].pcolor(X, Y, Z, cmap=\u0026#34;Blues\u0026#34;) mappable1 = ax[1].pcolor(X, Y, Z, cmap=\u0026#34;Reds\u0026#34;) fig.colorbar(mappable0, ax=ax[0]) fig.colorbar(mappable1, ax=ax[1]) fig.tight_layout() # これが無いと表示が少し崩れる plt.show()   結果\n等高線図の例 等高線図の横にカラーバーを描画する。\n1 2 3 4 5 6 7 8 9  x = np.arange(0, 10, 0.1) y = np.arange(0, 20, 0.1) X, Y = np.meshgrid(x, y) Z = np.cos(X)+np.cos(Y) fig, ax = plt.subplots() mappable = ax.contour(X, Y, Z, cmap=\u0026#34;Blues\u0026#34;) fig.colorbar(mappable) plt.show()   結果\nカラーバー中の線の濃さがやや分かりづらいので、プロットされた等高線に数字を表示した方が良いかもしれない。\nカラーバーにラベルを追加 以下の手順で、カラーバーにラベルを追加できる。\n Figureオブジェクトのcolorbarメソッドを実行したときに、戻り値のcolorbarオブジェクトを取得する。 colorbarオブジェクトのset_labelメソッドでラベルを設定する。  例\n1 2 3 4 5 6 7 8 9 10  x = np.arange(0,10) y = np.arange(0,5) X, Y = np.meshgrid(x, y) Z = np.arange(50).reshape(len(y), -1) fig, ax = plt.subplots() mappable = ax.pcolor(X, Y, Z, cmap=\u0026#34;Blues\u0026#34;) cbar = fig.colorbar(mappable, ax=ax) cbar.set_label(\u0026#34;Value of Z\u0026#34;) plt.show()   結果\n参考リンク matplotlib.figure.Figure — Matplotlib 3.3.3 documentation\nmatplotlib.pyplot.colorbar — Matplotlib 3.3.3 documentation\n","description":"matplotlibライブラリで作成したヒートマップや等高線図のカラーバーを、オブジェクト指向スタイルで調整する。","id":60,"section":"posts","tags":["Python","Matplotlib"],"title":"Matplotlibのオブジェクト指向なカラーバーの表示","uri":"https://helve2017.github.io/posts/python/matplotlib-object-oriented-colorbar/"},{"content":"はじめに matplotlibライブラリで作成したグラフの軸を、オブジェクト指向スタイルで対数に変更する。\nオブジェクト指向によるグラフの描画は、複数のグラフをプロットしたときに、どのグラフの描画を調整しているか分かりやすいという利点がある。\n環境    ソフトウェア バージョン     Spyder 3.2.8   Python 3.6.5   matplotlib 2.2.2    本記事では、各ライブラリを以下のようにインポートしていることを前提とする。\n1 2  import numpy as np import matplotlib.pyplot as plt   対数軸のプロット x, y軸をそれぞれ対数でプロットするには、Axesオブジェクトのset_xscale, set_yscaleメソッドを用いる。\n1 2  Axes.set_xscale(scale, **kargs) Axes.set_yscale(scale, **kargs)   scaleはプロットの方法であり、str型として以下のいずれかから指定する。\n\u0026quot;linear\u0026quot;, \u0026quot;log\u0026quot;, \u0026quot;symlog\u0026quot;\n（\u0026quot;logit\u0026quot;も指定できるが、公式のリファレンスに詳細が記載されていないため本記事では扱わない）\nまた、**kargsは各scaleの詳細を指定する任意の引数である。\n通常の線形プロット(linear) scale=\u0026quot;linear\u0026quot;とすると、通常の線形プロットになる。\n一般的な対数プロット(log) scale=\u0026quot;log\u0026quot;とすると、一般的な対数プロットになる。オプションは以下の通り。\n basex/basey: x, y軸の対数の「底」。デフォルトの底は10。 nonposx/nonposy: 0以下の値を、\u0026quot;mask\u0026quot;とすると表示せず、\u0026quot;clip\u0026quot;とすると微小な正の数に変換する。 subsx/subsy: 小目盛り (subticks) を振る値を整数のリストで指定する。  例： x軸の対数の底を2とし、y軸の小目盛りを2と5だけにする。また、0要素を除く。\n1 2 3 4 5 6 7 8  x = np.arange(10) # 0, 1, 2, ..., 9の配列 y = np.arange(10) fig, ax = plt.subplots() ax.plot(x, y) ax.set_xscale(\u0026#34;log\u0026#34;, basex=2, nonposx=\u0026#34;mask\u0026#34;) ax.set_yscale(\u0026#34;log\u0026#34;, subsy=[2, 5]) plt.show()   実行結果\n正負両方の対数プロット(symlog) scale=\u0026quot;symlog\u0026quot;とすると、正負両方の数を対数でプロットできる。すなわち、以下の数式のように、負の数を一度正にして対数をとり再びマイナスを付ける。\n$$ \\begin{cases} \\log(x) \u0026amp; (x \u0026gt; 0) \\\\ -\\log(-x) \u0026amp; (x \u0026lt; 0) \\end{cases} $$\nオプションは以下の通り。\n basex/basey: x, y軸の対数の「底」。デフォルトの底は10。 linthreshx/linthreshy: 実数xを与えると、範囲(-x, x)で線形にプロットする。ゼロ周辺における対数の発散を防ぐ。 subsx/subsy: 小目盛り (subticks) を振る値を整数のリストで指定する。  例： y軸を正負ともに対数でプロットする。範囲(-1, 1)を線形にする。\n1 2 3 4 5 6 7 8  x = np.arange(-10, 10) # -10, -9, ..., 10の配列 y = np.arange(-10, 10) fig, ax = plt.subplots() ax.plot(x, y) ax.set_yscale(\u0026#34;symlog\u0026#34;, linthreshy=1) ax.grid() plt.show()   結果\n参考 matplotlib.pyplot.xscale — Matplotlib 3.3.3 documentation\nmatplotlib.axes.Axes.set_xscale — Matplotlib 3.3.3 documentation\n","description":"matplotlibライブラリで作成したグラフの軸を、オブジェクト指向スタイルで対数に変更する。","id":61,"section":"posts","tags":["Python","Matplotlib"],"title":"Matplotlibのオブジェクト指向な対数軸プロット","uri":"https://helve2017.github.io/posts/python/matplotlib-object-oriented-logarithmic-graph/"},{"content":"はじめに PandasはPythonのデータ解析支援用ライブラリである。Pandasの基本データ構造であるSeriesとDataFrameの作成方法について述べる。\n環境    ソフトウェア バージョン     python 3.6.2   pandas 0.20.3    Pandas概要 Pandasではラベルを付与した配列を扱える。また、NumPyと異なり、1つのPandasオブジェクト内に異なるデータ型を保持できる。\n扱える次元数とデータ構造の名称を下表に示す。\n   次元数 データ構造     1 Series   2 DataFrame   3 Panel    ただし、Pandas Ver. 0.20では、Panelの使用は非推奨である（DataFrameのMuiltiIndex で代替できるため）。\n1次元データ構造Seriesの作成 1次元のデータ構造Seriesは、リスト、NumPy配列、辞書型いずれかから作成できる。ラベルはindexで指定する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; import pandas as pd \u0026gt;\u0026gt;\u0026gt; list_data = [1, 2, 3] # リスト型データ \u0026gt;\u0026gt;\u0026gt; Idx = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] # ラベル \u0026gt;\u0026gt;\u0026gt; pd.Series(list_data, index=Idx) # リストからSeriesを作成 a 1 b 2 c 3 dtype: int64 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; pd.Series(list_data) # indexを未指定の場合、ラベルは0始まりの整数 0 1 1 2 2 3 dtype: int64 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; pd.Series(np.array(list_data), index=Idx) # NumPy配列からSeriesを作成 a 1 b 2 c 3 dtype: int64 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; dict_data = {\u0026#34;c\u0026#34;:3, \u0026#34;a\u0026#34;:2, \u0026#34;b\u0026#34;:1} \u0026gt;\u0026gt;\u0026gt; pd.Series(dict_data) # 辞書型から作成 a 2 b 1 c 3 dtype: int64 \u0026gt;\u0026gt;\u0026gt; # 辞書型では要素が順序づけされていなため、インデックスの順でソートされる   また、Seriesはnameと呼ばれる属性を持つことができる。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; A = pd.Series([1, 2, 3], index=[\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;], name=\u0026#34;Number\u0026#34;) # name属性を定義 \u0026gt;\u0026gt;\u0026gt; A a 1 b 2 c 3 Name: Number, dtype: int64 \u0026gt;\u0026gt;\u0026gt; A.name # name属性を取得 \u0026#39;Number\u0026#39;   2次元データ構造DataFrameの作成 2次元のデータ構造DataFrameは、リスト、NumPy配列、辞書型、Pandas.Seriesから作成できる。行のラベルはindex, 列のラベルはcolumnsで指定する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; import pandas as pd \u0026gt;\u0026gt;\u0026gt; list_data = [[1, 2, 3], [4, 5, 6]] # 2次元のリスト型データ \u0026gt;\u0026gt;\u0026gt; Idx = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;] # 行のラベル \u0026gt;\u0026gt;\u0026gt; Col = [\u0026#34;one\u0026#34;, \u0026#34;tow\u0026#34;, \u0026#34;three\u0026#34;] # 列のラベル \u0026gt;\u0026gt;\u0026gt; pd.DataFrame(list_data, index=Idx, columns=Col) # リストからDataFrameを作成 one tow three a 1 2 3 b 4 5 6 \u0026gt;\u0026gt;\u0026gt; pd.DataFrame(list_data) 0 1 2 0 1 2 3 1 4 5 6 \u0026gt;\u0026gt;\u0026gt; # index, columnsを未指定の場合、ラベルは0始まりの整数 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; pd.DataFrame(np.array(list_data), index=Idx, columns=Col) # NumPy配列からDataFrameを作成 one tow three a 1 2 3 b 4 5 6 \u0026gt;\u0026gt;\u0026gt; dict_data = {\u0026#34;one\u0026#34;:[1, 2, 3], ... \u0026#34;two\u0026#34;:[4, 5, 6]} \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; pd.DataFrame(dict_data) # 辞書型から作成 one two 0 1 4 1 2 5 2 3 6 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; s1 = pd.Series([1, 2, 3], index=Col) \u0026gt;\u0026gt;\u0026gt; s2 = pd.Series([4, 5, 6], index=Col) \u0026gt;\u0026gt;\u0026gt; pd.DataFrame([s1, s2], index=Idx) # Pandas.Seriesから作成（その1） one tow three a 1 2 3 b 4 5 6 \u0026gt;\u0026gt;\u0026gt; # SeriesのindexがDataFrameのcolumnsになっていることに注意 \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; s3 = pd.Series([1, 2, 3], index=Col, name=\u0026#34;c\u0026#34;) \u0026gt;\u0026gt;\u0026gt; s4 = pd.Series([4, 5, 6], index=Col, name=\u0026#34;d\u0026#34;) \u0026gt;\u0026gt;\u0026gt; pd.DataFrame([s3, s4]) # Pandas.Seriesから作成（その2） one tow three c 1 2 3 d 4 5 6 \u0026gt;\u0026gt;\u0026gt; # Seriesにnameが存在していれば、DataFrameのindexになる   また、DataFrame自身はname属性を持たない代わりに、indexがname属性を持つ。\n1 2 3 4 5 6 7 8 9  \u0026gt;\u0026gt;\u0026gt; A = pd.DataFrame([[1, 2, 3], [4, 5, 6]], index=[\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;], columns=[\u0026#34;one\u0026#34;, \u0026#34;tow\u0026#34;, \u0026#34;three\u0026#34;]) \u0026gt;\u0026gt;\u0026gt; A.index.name=\u0026#34;Row\u0026#34; \u0026gt;\u0026gt;\u0026gt; A one tow three Row a 1 2 3 b 4 5 6   補足 欠落値を持つデータ データの欠落箇所は、numpy.nanで補う。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; pd.Series([1, np.nan, 3], index=[\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]) a 1.0 b NaN c 3.0 dtype: float64   要素を持たないデータ 引数をとらないことにより、要素を持たないSeries, DataFrameオブジェクトを作成できる。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; pd.Series() Series([], dtype: float64) \u0026gt;\u0026gt;\u0026gt;pd.DataFrame() Empty DataFrame Columns: [] Index: []   データ型 Series, Dataframeのdtypeパラメータにより、データ型を設定できる。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; pd.Series([1, 2, 3], dtype=float) 0 1.0 1 2.0 2 3.0 dtype: float64 \u0026gt;\u0026gt;\u0026gt; pd.Series([1, 2, 3], dtype=int) 0 1 1 2 2 3 dtype: int32   参考 Pandasの公式ドキュメントを参考とした。\nIntro to data structures — pandas 1.1.5 documentation\npandas.Series — pandas 1.1.5 documentation\npandas.DataFrame — pandas 1.1.5 documentation\n","description":"Pandasの基本データ構造であるSeriesとDataFrameの作成方法について述べる。","id":62,"section":"posts","tags":["Python","Pandas"],"title":"PandasのSeriesとDataFrameの作成","uri":"https://helve2017.github.io/posts/python/pandas-data-construction/"},{"content":"はじめに matplotlibライブラリで作成したグラフをオブジェクト指向スタイルで調整する。\nmatplotlibの基本的なオブジェクトとグラフ作成については前の記事を参照。\n環境    ソフトウェア バージョン     spyder 3.2.3   python 3.6.2   matplotlib 2.0.2    本ページでは、matplotlibライブラリとpyplotモジュールを以下のようにインポートしていることを前提とする。\n1 2  import matplotlib as mpl import matplotlib.pyplot as plt   グラフのタイトル グラフ(axesオブジェクト)の上部にタイトルを付ける。\n1  Axes.set_title(label, loc=\u0026#34;center\u0026#34;, fontdict, **kwargs)   引数の型と意味を以下に示す。\nlabel: str型\nグラフのタイトル。\u0026quot;\\n\u0026quot;で改行可能。\nloc: str型、optional\nタイトルの位置を制御する。\n{\u0026ldquo;center\u0026rdquo;, \u0026ldquo;right\u0026rdquo;, \u0026ldquo;left\u0026rdquo;}のいずれかを指定可能。\nfontdict: dict型、optional\n文字の大きさ、太さ、縦揃い位置、横揃い位置を制御する。\nデフォルトの設定は以下の通り。\n1 2 3 4  {\u0026#34;fontsize\u0026#34;: rcParams[\u0026#34;axes.titlesize\u0026#34;], \u0026#34;fontweight\u0026#34;: rcParams[\u0026#34;axes.titleweight\u0026#34;], \u0026#34;verticalalignment\u0026#34;: \u0026#34;baseline\u0026#34;, \u0026#34;horizontalalignment\u0026#34;: loc}   rcParamsは、matplotlibデフォルトのパラメータであり、以下を実行することで確認できる。\n1 2  mpl.rcParams[\u0026#34;axes.titlesize\u0026#34;] mpl.rcParams[\u0026#34;axes.titleweight\u0026#34;]   fontsizeは文字の大きさであり、数値で指定できる。\nまたは、str型として以下のいずれかから指定可能。\n{\u0026ldquo;xx-small\u0026rdquo;, \u0026ldquo;x-small\u0026rdquo;, \u0026ldquo;small\u0026rdquo;. \u0026ldquo;medium\u0026rdquo;, \u0026ldquo;large\u0026rdquo;, \u0026ldquo;x-large\u0026rdquo;, \u0026ldquo;xx-large\u0026rdquo;}\nfontweightは文字の太さであり、0～1000までの数値で指定できる。\nまたは、str型として以下のいずれかから指定可能。\n{\u0026ldquo;ultralight\u0026rdquo;, \u0026ldquo;light\u0026rdquo;, \u0026ldquo;normal\u0026rdquo;, \u0026ldquo;regular\u0026rdquo;, \u0026ldquo;book\u0026rdquo;, \u0026ldquo;medium\u0026rdquo;, \u0026ldquo;roman\u0026rdquo;, \u0026ldquo;semibold\u0026rdquo;, \u0026ldquo;demibold\u0026rdquo;, \u0026ldquo;demi\u0026rdquo;, \u0026ldquo;bold\u0026rdquo;, \u0026ldquo;heavy\u0026rdquo;, \u0026ldquo;extra bold\u0026rdquo;, \u0026ldquo;black\u0026rdquo;}\nhorizontalalignmentは文字の横揃い位置であり、以下のいずれかから指定可能。\n{\u0026ldquo;center\u0026rdquo;, \u0026ldquo;right\u0026rdquo;, \u0026ldquo;left\u0026rdquo;}\n指定しなければ、locと同じ値になる。\nkwargs: optional\nTextクラスで指定できるパラメータ。\n詳細は以下のページを参照。\nmatplotlib.text — Matplotlib 3.3.3 documentation\n例：\n1 2 3 4 5 6 7  fig, ax = plt.subplots() ax.plot([1,2], [3,4]) ax.set_title(\u0026#34;Figure\u0026#39;s \\ntitle\u0026#34;, loc=\u0026#34;left\u0026#34;, fontdict={\u0026#34;fontsize\u0026#34;: 18, \u0026#34;fontweight\u0026#34;: \u0026#34;bold\u0026#34;}) plt.show()   実行結果：\n参考：\nmatplotlib.axes.Axes.set_title — Matplotlib 3.3.3 documentation\n軸のラベル x, y軸にラベルを付けるとき、それぞれset_xlabel, set_ylabelメソッドを使う。\n1 2  Axes.set_xlabel(xlabel, labelpad=None, fontdict, **kwargs) Axes.set_ylabel(ylabel, labelpad=None, fontdict, **kwargs)   引数の型と意味を以下に示す。\nxlabel, ylabel: str型\n軸のラベル。\u0026quot;\\n\u0026quot;で改行可能。\nfontdict: dict型、optional\n文字の大きさ、太さ、縦揃い位置、横揃い位置を制御する。\n詳細はset_titleの項を参照。\nlabelpad: 数値、optional\nラベルと軸の間のスペース。負の数も可。\nkwargs: optional\nTextクラスで指定できるパラメータ。\n参考：\nmatplotlib.axes.Axes.set_xlabel — Matplotlib 3.3.3 documentation\n軸の範囲 軸の範囲を制限するときは、Axesオブジェクトのset_xlim, set_ylimメソッドを使う。\n1 2  Axes.set_xlim(left=None, right=None) Axes.set_ylim(bottom=None, top=None)   引数の型と意味を下表に示す。\n   引数 型 意味     left スカラ x軸の左側   right スカラ x軸の右側   bottom スカラ y軸の下側   top スカラ y軸の上側    set_xlim, set_ylimに2つの引数をキーワードを指定せずに渡すと、順にleft, rightに代入される。\n軸の範囲を片側だけ制限したい場合は、制限したい側のみに引数を渡す。制限しなかった側は、自動で調整される。\nまた、set_xlimの引数の値をleft\u0026gt;right (set_ylimの場合はbottom\u0026gt;top) とすると、軸の正負が反転する。なお、軸の反転は以下のメソッドでも行える。\n1 2  Axes.invert_xaxis() Axes.invert_yaxis()   例： x軸の最大範囲を3として、y軸を反転させる。\n1 2 3 4 5  fig, ax = plt.subplots() ax.plot([1,5], [3,4]) ax.set_xlim(right=3) ax.set_ylim(5, 2) plt.show()   以下のinvert_yaxisメソッドを使ったスクリプトも同じ結果となる。\n1 2 3 4 5 6  fig, ax = plt.subplots() ax.plot([1,5], [3,4]) ax.set_xlim(right=3) ax.set_ylim(2, 5) ax.invert_yaxis() plt.show()   実行結果：\n参考：\nmatplotlib.axes.Axes.set_xlim — Matplotlib 3.3.3 documentation\nmatplotlib.axes.Axes.set_ylim — Matplotlib 3.3.3 documentation\n凡例の表示 グラフに凡例(legend)を付ける。\n1  Axes.legend(*args, **kwargs)   凡例をlegendの引数として、リスト形式で指定可能。\n例1：\n1 2 3 4 5  fig, ax = plt.subplots() ax.plot([1,2], [3,4]) ax.plot([1,2], [4,3]) ax.legend([\u0026#34;Line 1\u0026#34;, \u0026#34;Line 2\u0026#34;]) plt.show()   実行結果1：\nなお、以下のようにラベルが既に設定されている場合は、legendメソッドの引数は不要である。\n例2：\n1 2 3 4 5  fig, ax = plt.subplots() ax.plot([1,2], [3,4], label=\u0026#34;Line 1\u0026#34;) ax.plot([1,2], [4,3], label=\u0026#34;Line 2\u0026#34;) ax.legend() plt.show()   実行結果2：\n実行結果1と同じ。\nその他の主な引数の型と意味を以下に示す。\nloc: str型、optional\n凡例の位置を以下のいずれかから指定可能。デフォルト値は best （プロットと凡例がなるべく重ならないように配置する）。\nただし、プロットするデータが多い場合、best では凡例の位置を探索するのに時間が掛かるため、出来るだけ位置を指定する方がよい。\n          upper left upper center upper right   center left center center right   lower left lower center lower right   best      ncol: int型、optional\n凡例の列数を指定。デフォルトは1.\nfontsize: int型 or str型、optional\n文字の大きさであり、数値で指定できる。\nまたは、str型として以下のいずれかを指定可能。\n{\u0026ldquo;xx-small\u0026rdquo;, \u0026ldquo;x-small\u0026rdquo;, \u0026ldquo;small\u0026rdquo;. \u0026ldquo;medium\u0026rdquo;, \u0026ldquo;large\u0026rdquo;, \u0026ldquo;x-large\u0026rdquo;, \u0026ldquo;xx-large\u0026rdquo;}\nframeon: bool型、optional\n枠の表示。デフォルト値は以下で確認できる。\n1  mpl.rcParams[\u0026#34;legend.frameon\u0026#34;]   framealpha: float型、optional\n凡例の背景の透過度。0～1の範囲で指定し、値が小さいほど透明に近づく。\nデフォルト値は以下で確認できる。\n1  mpl.rcParams[\u0026#34;legend.framealpha\u0026#34;]   facecolor:\n凡例の背景色。デフォルト値は以下で確認できる。\n1  mpl.rcParams[\u0026#34;legend.facecolor\u0026#34;]   edgecolor\n凡例の枠の色。デフォルト値は以下で確認できる。\n1  mpl.rcParams[\u0026#34;legend.edgecolor\u0026#34;]   title: str型\n凡例のタイトル。\n参考：\nmatplotlib.axes.Axes.legend — Matplotlib 3.3.3 documentation\nグラフのグリッド グラフにグリッドを引くときは、Axesオブジェクトのgridメソッドを使う。\n1  Axes.grid(b=None, which=\u0026#39;major\u0026#39;, axis=\u0026#39;both\u0026#39;, **kwargs)   引数の型と意味は以下の通り。\nb: bool型\nグリッドのオン(True)・オフ(False)。\nb=Noneかつkwargsを指定しない場合、グリッドのオン・オフを切り替える。\nb=Noneかつkwargsを指定した場合、グリッドをオンにする。\nwhich: str型\n{\u0026ldquo;major\u0026rdquo;, \u0026ldquo;minor\u0026rdquo;, \u0026ldquo;both\u0026rdquo;}のいずれかを指定する。\nそれぞれ、主目盛 (major tick), 補助目盛 (monor tick), これら両方、においてグリッドを引くかを意味する。\naxis: str型\nグリッドを引く軸を{\u0026ldquo;both\u0026rdquo;, \u0026ldquo;x\u0026rdquo;, \u0026ldquo;y\u0026rdquo;}のいずれかから指定する。\n**kwargs\nLine 2Dオブジェクトであるグリッド線の色等のプロパティを指定する。\nLine 2Dの詳細は次のページを参考。\nmatplotlib.lines.Line2D — Matplotlib 3.3.3 documentation\n参考：\nmatplotlib.axes.Axes.grid — Matplotlib 3.3.3 documentation\nグラフの保存 グラフをファイルとして保存するときは、Figureオブジェクトのsavefigメソッドを用いる。\n1  Figure.savefig(fname, dpi=None, transparent=False)   引数の型と意味は以下の通り。\nfname: str型\nグラフを保存するファイルのディレクトリと名前。\nファイル名のみの場合は、現在のディレクトリに保存される。\nファイル名に拡張子を付けると、ファイルフォーマットは拡張子から自動で決定される。\ndpi: スカラー\n保存するグラフの解像度。オプション。dpiの初期値は以下のコマンドで確認できる。\n1  mpl.rcParams[\u0026#34;savefig.dpi\u0026#34;]   このコマンドで \u0026ldquo;figure\u0026rdquo; が返された場合、保存する画像の解像度はFigureオブジェクトの設定値になる。\nFigureオブジェクトのdpiは、plt.subplots()などによる作成時に指定できる他、オブジェクト作成後もFigure.set_dpi(var)メソッドにより再指定できる。また、Figure.get_dpi()メソッドにより取得できる。\ntransparent: bool型\nTrueならばグラフの背景を透過させる。デフォルト値はFalse。\nただし、画像フォーマットが透過に対応している必要がある（pngなど）。\n参考：\nmatplotlib.figure.Figure — Matplotlib 3.3.3 documentation\n","description":"matplotlibライブラリで作成したグラフをオブジェクト指向スタイルで調整する。","id":63,"section":"posts","tags":["Python","Matplotlib"],"title":"Matplotlibでオブジェクト指向なグラフの調整","uri":"https://helve2017.github.io/posts/python/matplotlib-object-oriented-figure-adjustment/"},{"content":"はじめに matplotlibライブラリを用いて、オブジェクト指向スタイルでグラフを作成する。\n環境    ソフトウェア バージョン     spyder 3.2.3   python 3.6.2   matplotlib 2.0.2    matplotlibのオブジェクト指向 matplotlibにおいて、グラフを作成するための主なクラスはfigureとaxesである。\nfigureオブジェクトは、グラフを表示するためのウィンドウに相当する。axesオブジェクトはグラフそのものである。1つのfigureオブジェクト上に複数のaxesオブジェクトを表示できる。\nまず、pyplotモジュールを次のようにインポートする。\n1  \u0026gt;\u0026gt;\u0026gt; import matplotlib.pyplot as plt   figure, axesオブジェクトの作成方法はいくつかある。\n add_axesメソッドを使う  1 2 3 4  fig = plt.figure() # figureオブジェクトを作成 ax = fig.add_axes((0,0,1,1)) # axesオブジェクトを作成 ax.plot([1,2], [3,4]) # plotメソッドでデータをプロット plt.show() # グラフを表示    add_subplotメソッドを使う  1 2 3 4  fig = plt.figure() ax = fig.add_subplot(111) # axesオブジェクトを作成 ax.plot([1,2], [3,4]) plt.show()    subplotsメソッドを使う  1 2 3  fig, ax = plt.subplots() # figure, axesオブジェクトを作成 ax.plot([1,2], [3,4]) plt.show()   実行すると、いずれも次のグラフが表示される（大きさは異なる場合がある）。\n各関数・メソッドの説明を次節に示す。\nfigure, axesオブジェクトを作成する関数・メソッド plt.figure() plt.figure()は、figureオブジェクトを返す。\n1 2 3 4  plt.figure(num=None, figsize=None, dpi=None, facecolor=None, edgecolor=None, frameon=True, FigureClass=\u0026lt;class \u0026#39;matplotlib.figure.Figure\u0026#39;\u0026gt;,  clear=False, **kwargs)   主な引数の型と意味を下表に示す。\n   引数 型 意味     num int or str figureの番号または名前。指定しなければ順に加算される。   figsize touple of int 図の幅と高さを指定（単位：インチ）   dpi int 解像度   facecolor  背景色   edgecolor  境界の色    例：図の幅・高さをそれぞれ4, 3インチとし、背景を灰色にする。\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; fig = plt.figure(figsize=(4, 3), facecolor=\u0026#34;gray\u0026#34;) \u0026gt;\u0026gt;\u0026gt; ax = fig.add_axes((0,0,1,1)) \u0026gt;\u0026gt;\u0026gt; ax.plot([1,2], [3,4]) \u0026gt;\u0026gt;\u0026gt; plt.show()   figure.add_axes() figure.add_axes()は、figure上に1個のaxesオブジェクトを作成する。\n1  figure.add_axes=(rect, projection, poloar)   主な引数の意味を下表に示す。\n   引数 型 意味     rect list or touple axesの位置・大きさを指定   projection str 投影方法（任意）   polar bool Trueなら極座標表示（任意）    rectは、4つのfloatでaxesの[左端, 下端, 幅, 高さ]を指定する。\nprojection引数には、以下の投影方法を指定できる。\n   引数 意味     \u0026ldquo;aitoff\u0026rdquo; エイトフ図法   \u0026ldquo;hammer\u0026rdquo; ハンメル図法   \u0026ldquo;lambert\u0026rdquo; ランベルト図法   \u0026ldquo;mollweide\u0026rdquo; モルワイデ図法   \u0026ldquo;polar\u0026rdquo; 極座標   \u0026ldquo;rectilinear\u0026rdquo; 心射方位図法    figure.add_subplot() figure.add_subplot()は、figure上に1個のaxesオブジェクトを格子状に作成する。\n1  figure.add_axes=(*args, projection, poloar)   argsは可変長の引数を表し、「3つの整数を持つタプル」または「3桁の整数」である。\nタプルの値を(I, J, K)とすると、I行J列の格子のK番目の位置にaxesを作成する。\nタプル(I, J, K)は、3つの整数をIJKと並べた場合に等しい。\n例：2行1列で2つのグラフを出力する。\n1 2 3 4 5 6  fig = plt.figure() ax1 = fig.add_subplot(211) # 2行1列の1番目 ax1.plot([1,2], [2,3]) ax2 = fig.add_subplot(212) # 2行1列の2番目  ax2.plot([1,2], [3,2]) plt.show()   plt.subplots() plt.subplots()は次の2つのオブジェクトを作成する。\n figureオブジェクト axesオブジェクトの配列（または単体のaxesオブジェクト）  1 2 3  plt.subplots(nrows=1, ncols=1, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw)   主な引数の意味を以下に示す。\nnrows, ncols: int型\nグラフグリッドの行数・列数。\nsharex, sharey: bool or {\u0026ldquo;none\u0026rdquo;, \u0026ldquo;all\u0026rdquo;, \u0026ldquo;row\u0026rdquo;, \u0026ldquo;col\u0026rdquo;}\n複数のグラフのx, y軸の範囲(xlim, ylim)の共有。\n True or \u0026ldquo;all\u0026rdquo;: 全グラフで軸範囲を共有。 False or \u0026ldquo;none\u0026rdquo;: 各グラフの軸範囲は独立。 \u0026ldquo;row\u0026rdquo;: 各行のグラフが軸範囲を共有。 \u0026ldquo;col\u0026rdquo;: 各列のグラフが軸範囲を共有。  squeeze: bool\naxesオブジェクトの返し方を指定。\n Falseの場合、axesオブジェクトを常に2次元配列で返す。 Trueの場合、nrows, ncolsの値によって、axesオブジェクト配列の次元を最小限にする。\n・nrows=ncols=1のとき、直接axesオブジェクトを返す。\n・nrowsとncolsの片方のみ1のとき、axesオブジェクトを1次元配列で返す。\n・nrowsとncolsの両方が2以上のとき、axesオブジェクトを2次元配列で返す。  subplot_kw: dict型\nfigure.add_subplot()のパラメータを指定する。\n**fig_kw :\nplt.figure()のパラメータを指定する。\n例：2行2列のaxesオブジェクトを作成し、x軸の範囲は同じ列のグラフで共通、y軸の範囲は全グラフで共通とする。また、背景色を薄灰色にする(plt.figure()のパラメータ)。\n1 2 3 4 5 6 7 8 9  fig, ax = plt.subplots(ncols=2, nrows=2, sharex=\u0026#34;col\u0026#34;, sharey=\u0026#34;all\u0026#34;, facecolor=\u0026#34;lightgray\u0026#34;) print(ax) ax[0,0].plot([1,2], [0,1]) # 左上 ax[0,1].plot([5,8], [1,2]) # 右上 ax[1,0].plot([1,2], [2,1]) # 左下 ax[1,1].plot([5,8], [2,0]) # 右下 plt.show()   実行結果 変数axはaxesオブジェクトの2x2配列になっている。\n1 2 3 4  [[\u0026lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000E5792E0588\u0026gt; \u0026lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000E57A31D278\u0026gt;] [\u0026lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000E579271BE0\u0026gt; \u0026lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000E57A3DCFD0\u0026gt;]]   参考リンク matplotlib.pyplot.figure — Matplotlib 3.3.3 documentation\nmatplotlib.pyplot.subplot — Matplotlib 3.3.3 documentation\nmatplotlib.pyplot.subplots — Matplotlib 3.3.3 documentation\n","description":"matplotlibライブラリを用いてオブジェクト指向スタイルでグラフを作成する。","id":64,"section":"posts","tags":["Python","Matplotlib"],"title":"Matplotlibでオブジェクト指向なグラフ作成","uri":"https://helve2017.github.io/posts/python/matplotlib-object-oriented-figure-construction/"},{"content":"はじめに Pythonの標準ライブラリmultiprocessingを使って並列計算を行う。\n環境    ソフトウェア バージョン     python 3.7.4    各並列処理間でデータを共有せず並列計算を行う場合 並列化した各処理間でデータを共有せずに並列計算を行う場合、multiprocessingモジュールのPoolクラスを使うだけで良い。\n次のプログラムでは、0から9までの各整数の2乗を計算する。\n1 2 3 4 5 6 7 8 9  import multiprocessing as mp def square(x): return x*x if __name__ == \u0026#34;__main__\u0026#34;: with mp.Pool(processes=2) as pool: result = pool.map(square, range(10)) print(result)   実行結果：\n1  [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]   上記のプログラムを開設する。Poolクラスは\n1  if __name__ == \u0026#34;__main__\u0026#34;:   の中で始める必要がある。\nまた、Poolの引数は、使用するワーカープロセスの数（並列計算プロセス数）である。作成したPoolオブジェクトpoolのmapメソッドに対し、第1引数に関数、第2引数に関数の引数（イテレータ形式）を渡す。\nさらに、計算終了後にPoolオブジェクトを消去する必要がある。with構文を使わない場合、以下のようにcloseメソッドを使う。\n1 2 3  pool = mp.Pool(processes=2) result = pool.map(square, range(10))) pool.close()   参考 multiprocessing \u0026mdash; プロセスベースの並列処理 — Python 3.9.1 ドキュメント\n","description":"Pythonの標準ライブラリmultiprocessingを使って並列計算を行う。","id":65,"section":"posts","tags":["Python"],"title":"Pythonのmultiprocessingを使った並列計算","uri":"https://helve2017.github.io/posts/python/python-multiprocessing/"},{"content":"はじめに BeautifulSoupを使ってXMLを解析(parse)する。\n環境    ソフトウェア バージョン     Python 3.7.4   beautifulsoup4 4.8.0   lxml 4.4.1    インストール 以下を実行して必要なライブラリをインストールする。\n$ pip install beautifulsoup4 $ pip install lxml XMLの構文 この記事では、XMLの構造について以下の名称を用いる。\n1  \u0026lt;要素名 属性=\u0026#34;値\u0026#34;\u0026gt;内容\u0026lt;/要素名\u0026gt;   扱うXMLファイル 書籍データを模擬したXMLファイルを扱う。以下のXMLに\u0026quot;doc.xml\u0026quot;と名前を付けて、作業ディレクトリに置いていることを前提としている。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;data\u0026gt; \u0026lt;book id=\u0026#34;001\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;002\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt;羅生門\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;芥川龍之介\u0026#34;\u0026gt;芥川龍之介\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;003\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt;柿の種\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;寺田寅彦\u0026#34;\u0026gt;寺田寅彦\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;随筆\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/data\u0026gt;   \u0026ldquo;autonym\u0026quot;は「本名」の意味。また、この記事では扱わないが、requestやurllibなどのライブラリを使うと、オンラインのXMLファイルを自動で収集できる。\nXMLファイルのパース 読み込んだXMLファイルオブジェクトをBeautifulSoupでパースする。BeautifulSoupで使用できるパーサを次表に示す。今回はxmlパーサを使用する。\n   パーサ 備考     html.parser 標準ライブラリのパーサ   lxml lxmlライブラリのHTMLパーサ。処理が高速   lxml-xml または xml lxmlライブラリのXMLパーサ。処理が高速   html5lib HTML5に対応    以下のようにBeautifulSoupをインポートして、XMLファイルとパーサを引数に指定する。BeautifulSoupオブジェクトのsoupをptint文で出力すると、XMLが表示される。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026gt;\u0026gt;\u0026gt; from bs4 import BeautifulSoup \u0026gt;\u0026gt;\u0026gt; with open(\u0026#34;doc.xml\u0026#34;) as doc: ... soup = BeautifulSoup(doc, \u0026#34;xml\u0026#34;) # 第2引数でパーサを指定 \u0026gt;\u0026gt;\u0026gt; print(soup) \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;data\u0026gt; \u0026lt;book id=\u0026#34;001\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;002\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt;羅生門\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;芥川龍之介\u0026#34;\u0026gt;芥川龍之介\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;003\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt;柿の種\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;寺田寅彦\u0026#34;\u0026gt;寺田寅彦\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;随筆\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/data\u0026gt;   XMLが文字化けする場合はopen時のencodingを見直す。prettifyメソッドを使うと整形されたXMLが表示される。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  \u0026gt;\u0026gt;\u0026gt; print(soup.prettify()) \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;data\u0026gt; \u0026lt;book id=\u0026#34;001\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt; Alice in Wonderland \u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt; Lewis Carroll \u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt; 小説 \u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;002\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt; 羅生門 \u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;芥川龍之介\u0026#34;\u0026gt; 芥川龍之介 \u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt; 小説 \u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026#34;003\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt; 柿の種 \u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;寺田寅彦\u0026#34;\u0026gt; 寺田寅彦 \u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt; 随筆 \u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/data\u0026gt;   パースしたXMLの探索 要素の検索 以下のメソッドをXML内の要素の探索に利用できる。\n   メソッド 備考     find() 要素名または属性で検索し、該当する最初の要素を返す   find_all() 要素名または属性で検索し、該当する全ての要素を返す    使用例は次の通り。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026gt;\u0026gt;\u0026gt; soup.find(\u0026#34;book\u0026#34;) # 最初の\u0026#34;book\u0026#34;要素 \u0026lt;book id=\u0026#34;001\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026gt;\u0026gt;\u0026gt; soup.book # \u0026#34;.\u0026#34;+\u0026#34;要素でも、同じ結果になる \u0026lt;book id=\u0026#34;001\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026gt;\u0026gt;\u0026gt; soup.find(language=\u0026#34;Japanese\u0026#34;) # language属性がJapaneseである最初の要素 \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt;羅生門\u0026lt;/title\u0026gt; \u0026gt;\u0026gt;\u0026gt; soup.find_all(\u0026#34;author\u0026#34;) # 全てのauthor要素 [\u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt;, \u0026lt;author autonym=\u0026#34;芥川龍之介\u0026#34;\u0026gt;芥川龍之介\u0026lt;/author\u0026gt;, \u0026lt;author autonym=\u0026#34;寺田寅彦\u0026#34;\u0026gt;寺田寅彦\u0026lt;/author\u0026gt;] \u0026gt;\u0026gt;\u0026gt; soup.find_all(language=\u0026#34;Japanese\u0026#34;) # language属性がJapaneseである全ての要素 [\u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt;羅生門\u0026lt;/title\u0026gt;, \u0026lt;title language=\u0026#34;Japanese\u0026#34;\u0026gt;柿の種\u0026lt;/title\u0026gt;]   属性と値の取得 属性から値を取得する場合は、[ ]で属性を指定する。全ての属性と値を取得する場合は、attrsメソッドを使う。\n1 2 3 4 5 6 7  \u0026gt;\u0026gt;\u0026gt; title001 = soup.book.title \u0026gt;\u0026gt;\u0026gt; print(title001) \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026gt;\u0026gt;\u0026gt; title001[\u0026#34;language\u0026#34;] # 属性を指定 \u0026#39;English\u0026#39; \u0026gt;\u0026gt;\u0026gt; title001.attrs # 属性と値を辞書型で表示 {\u0026#39;language\u0026#39;: \u0026#39;English\u0026#39;}   内容の取得 内容を持つ直上の要素まで移動し、stringメソッドを使う。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; title001 = soup.book.title \u0026gt;\u0026gt;\u0026gt; print(title001) \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026gt;\u0026gt;\u0026gt; title001.string # 内容を取得 \u0026#34;Alice in Wonderland\u0026#34;   要素間の移動    属性 備考     next_sibling 同じ階層の次の要素に移動   previous_sibling 同じ階層の前の要素に移動   parent 上の階層の要素に移動    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026gt;\u0026gt;\u0026gt; book001 = soup.book \u0026gt;\u0026gt;\u0026gt; print(book001) \u0026lt;book id=\u0026#34;001\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt; \u0026gt;\u0026gt;\u0026gt; author001 = book001.author \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt; \u0026gt;\u0026gt;\u0026gt; author001.next_sibling # 改行(\\n)も要素に含まれる \u0026#39;\\n\u0026#39; \u0026gt;\u0026gt;\u0026gt; author001.next_sibling.next_sibling # 次の要素 \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026gt;\u0026gt;\u0026gt; author001.previous_sibling.previous_sibling # 前の要素 \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026gt;\u0026gt;\u0026gt; author001.parent # 上の要素 \u0026lt;book id=\u0026#34;001\u0026#34;\u0026gt; \u0026lt;title language=\u0026#34;English\u0026#34;\u0026gt;Alice in Wonderland\u0026lt;/title\u0026gt; \u0026lt;author autonym=\u0026#34;Charles Lutwidge Dodgson\u0026#34;\u0026gt;Lewis Carroll\u0026lt;/author\u0026gt; \u0026lt;genre\u0026gt;小説\u0026lt;/genre\u0026gt; \u0026lt;/book\u0026gt;   参考リンク Beautiful Soup Documentation — Beautiful Soup 4.9.0 documentation\n","description":"BeautifulSoupを使ってXMLを解析(parse)する。","id":66,"section":"posts","tags":["Python","BeautifulSoup"],"title":"BeautifulSoupを使ったXMLの解析","uri":"https://helve2017.github.io/posts/python/beautifulsoup-xml-parse/"},{"content":"はじめに NumPyで利用できる統計の関数について。\n環境    ソフトウェア バージョン     NumPy 1.19    最大・最小 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; a = np.array([[1, 2, 3], [4, 5, 6]]) \u0026gt;\u0026gt;\u0026gt; np.amax(a) # 全要素の最大値 6 \u0026gt;\u0026gt;\u0026gt; np.amax(a, axis=0) # 列方向の最大値 array([4, 5, 6]) \u0026gt;\u0026gt;\u0026gt; np.amax(a, axis=1) # 行方向の最大値 array([3, 6]) \u0026gt;\u0026gt;\u0026gt; np.amax(a, axis=1, keepdims=True) # 元の配列構造を維持 array([[3], [6]]) \u0026gt;\u0026gt;\u0026gt; np.amin(a) # 全要素の最小値 1 \u0026gt;\u0026gt;\u0026gt; np.argmax(a) # 最大要素のインデックスを返す \u0026gt;\u0026gt;\u0026gt; # 配列は1次元に変換 (flatten) される 5 \u0026gt;\u0026gt;\u0026gt; np.argmax(a, axis=0) # 列方向の最大要素インデックス array([1, 1, 1], dtype=int64) \u0026gt;\u0026gt;\u0026gt; np.argmin(a) # 最小要素のインデックスを返す 0 \u0026gt;\u0026gt;\u0026gt; np.ptp(a) # 最大値-最小値 (Peak To Peak) 5 \u0026gt;\u0026gt;\u0026gt; np.ptp(a, axis=0) # 列方向の最大値-最小値 array([3, 3, 3])   平均と分散 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1, 2, 3], [4, 5, 6]]) \u0026gt;\u0026gt;\u0026gt; np.median(a) # 全要素の中央値 3.5 \u0026gt;\u0026gt;\u0026gt; np.median(a, axis=0) # 列方向の中央値 array([ 2.5, 3.5, 4.5]) \u0026gt;\u0026gt;\u0026gt; np.average(a) # 全要素の平均値 3.5 \u0026gt;\u0026gt;\u0026gt; np.average(a, axis=0) # 列方向の平均値 array([ 2.5, 3.5, 4.5]) \u0026gt;\u0026gt;\u0026gt; np.average([1, 2, 3], weights=[2.5, 1.5, 0.5]) # 重みづけ平均 \u0026gt;\u0026gt;\u0026gt; # (2.5*1 + 1.5*2 + 0.5*3) / (2.5+1.5+0.5) 1.5555555555555556 \u0026gt;\u0026gt;\u0026gt; np.mean(a) # 全要素の平均値(axisオプションはあるが、weightsオプションはない) 3.5 \u0026gt;\u0026gt;\u0026gt; np.std(a) # 標準偏差 (axisオプションあり) 1.707825127659933 \u0026gt;\u0026gt;\u0026gt; np.std(a, ddof=1) # 不偏標準偏差 (標本数-ddofで標準偏差を計算。ddof=0がデフォルト） 1.8708286933869707 \u0026gt;\u0026gt;\u0026gt; np.var(a) # 標本分散 (axisオプションあり) 2.9166666666666665 \u0026gt;\u0026gt;\u0026gt; np.var(a, ddof=1) # 不偏分散 (標本数-ddofで分散を計算。ddof=0がデフォルト） 3.5   相関係数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026gt;\u0026gt;\u0026gt; a = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) \u0026gt;\u0026gt;\u0026gt; b = np.array([1, 0, 4, 2, 6, 3, 5, 9, 8, 7]) \u0026gt;\u0026gt;\u0026gt; c = np.array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0]) \u0026gt;\u0026gt;\u0026gt; x = np.vstack([a, b, c]) \u0026gt;\u0026gt;\u0026gt; np.corrcoef(x) # 相関係数行列 \u0026gt;\u0026gt;\u0026gt; # [0, 1]要素：aとbの相関係数 \u0026gt;\u0026gt;\u0026gt; # [0, 2]要素：aとcの相関係数 \u0026gt;\u0026gt;\u0026gt; # [1, 2]要素：bとcの相関係数 array([[ 1. , 0.85454545, -1. ], [ 0.85454545, 1. , -0.85454545], [-1. , -0.85454545, 1. ]]) \u0026gt;\u0026gt;\u0026gt; np.corrcoef(a, b) # 2つの1次元配列を引数にとっても良い array([[ 1. , 0.85454545], [ 0.85454545, 1. ]]) \u0026gt;\u0026gt;\u0026gt; np.cov(x) # 共分散行列 (ddof=1がデフォルト） array([[ 9.16666667, 7.83333333, -9.16666667], [ 7.83333333, 9.16666667, -7.83333333], [-9.16666667, -7.83333333, 9.16666667]])   参考リンク Statistics — NumPy v1.19 Manual\n","description":"NumPyで利用できる統計の関数について。","id":67,"section":"posts","tags":["Python","NumPy"],"title":"NumPyで使える統計の関数","uri":"https://helve2017.github.io/posts/python/numpy-statistics-function/"},{"content":"はじめに NumPyで利用できる数学の関数について。\nmathライブラリの数学の関数は、一般にスカラー値にしか適用できない。一方、NumPyの数学の関数は、スカラー値に加え、リストやnumpy.arrayオブジェクトにも適用できる。\n環境    ソフトウェア バージョン     NumPy 1.19    三角関数・逆三角関数 角度の単位はラジアン。\n   関数 記法 説明     sin np.sin(a)    cos np.cos(a)    tan np.tan(a)    arcsin np.arcsin(a)    arccos np.arccos(a)    arctan np.arctan(a) 戻り値の範囲は[-pi/2, pi/2]   arctan2 np.arctan2(a, b) a/bのarctanを返す。戻り値の範囲は[-pi, pi]    1 2 3 4 5 6 7 8 9 10 11  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; a = np.array([0, np.pi/6, np.pi/3, np.pi/2]) # np.piは円周率 \u0026gt;\u0026gt;\u0026gt; b = np.sin(a) \u0026gt;\u0026gt;\u0026gt; b array([ 0. , 0.5 , 0.8660254, 1. ]) \u0026gt;\u0026gt;\u0026gt; np.arcsin(b) array([ 0. , 0.52359878, 1.04719755, 1.57079633]) \u0026gt;\u0026gt;\u0026gt; np.deg2rad([0, 90, 180]) # degからradへ変換 array([ 0. , 1.57079633, 3.14159265]) \u0026gt;\u0026gt;\u0026gt; np.rad2deg([0, np.pi/2, np.pi]) # radからdegへ変換 array([ 0., 90., 180.])   三角関数・逆三角関数のグラフは以下の通り。\n以下のコードで描画した。\n\r\rクリックで展開\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  import numpy as np import matplotlib.pyplot as plt x1 = np.arange(-2*np.pi, 2*np.pi, 0.01) fig, ax = plt.subplots() ax.plot(x1, np.sin(x1), label=\u0026#34;sin(x)\u0026#34;) ax.plot(x1, np.cos(x1), label=\u0026#34;cos(x)\u0026#34;) ax.plot(x1, np.tan(x1), label=\u0026#34;tan(x)\u0026#34;) ax.set_ylim(-2, 2) ax.set_xlabel(\u0026#34;x\u0026#34;) ax.grid(); ax.legend() plt.show() x2 = np.arange(-1, 1, 0.01) fig, ax = plt.subplots() ax.plot(x2, np.arcsin(x2), label=\u0026#34;arcsin(x)\u0026#34;) ax.plot(x2, np.arccos(x2), label=\u0026#34;arccos(x)\u0026#34;) ax.plot(x2, np.arctan(x2), label=\u0026#34;arctan(x)\u0026#34;) ax.set_ylim(-2, 4) ax.set_xlabel(\u0026#34;x\u0026#34;) ax.grid(); ax.legend() plt.show() a = np.arange(-10, 10, 0.01) b1, b2 = 1, -1 fig, ax = plt.subplots() ax.plot(a, np.arctan2(a, b1), label=\u0026#34;arctan2(a, 1)\u0026#34;) ax.plot(a, np.arctan2(a, b2), label=\u0026#34;arctan2(a, -1)\u0026#34;) ax.set_ylim(-4, 4) ax.set_xlabel(\u0026#34;a\u0026#34;) ax.grid(); ax.legend() plt.show()   \r\r 双曲線関数    関数 記法     sinh np.sinh(a)   cosh np.cosh(a)   tanh np.tanh(a)   arcsinh np.arcsinh(a)   arccosh np.arccosh(a)   arctanh np.arctanh(a)    端数処理     記法 説明     四捨五入 np.around(a, decimals=0) 10^(-decimals)の1つ下の位を四捨五入   四捨五入 np.round_(a, decimals=0) aroundと同じ   0方向への丸め np.fix(a)    負方向への丸め（切捨て） np.floor(a)    正方向への丸め（切上げ） np.ceil(a)    0方向への丸め np.trunc(a)     1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt;\u0026gt;\u0026gt; np.around(123.456, decimals=0) # 0.1の位を四捨五入 123.0 \u0026gt;\u0026gt;\u0026gt; np.around(123.456, decimals=1) # 0.01の位を四捨五入 123.5 \u0026gt;\u0026gt;\u0026gt; np.around(123.456, decimals=-2) # 10の位を四捨五入 100.0 \u0026gt;\u0026gt;\u0026gt; np.fix([0.7, 3.2, -0.7, -3.2]) # 0方向への丸め array([ 0., 3., -0., -3.]) \u0026gt;\u0026gt;\u0026gt; np.floor([0.7, 3.2, -0.7, -3.2]) # 負方向への丸め array([ 0., 3., -1., -4.]) \u0026gt;\u0026gt;\u0026gt; np.ceil([0.7, 3.2, -0.7, -3.2]) # 正方向への丸め array([ 1., 4., -0., -3.]) \u0026gt;\u0026gt;\u0026gt; np.trunc([0.7, 3.2, -0.7, -3.2]) # 0方向への丸め array([ 0., 3., -0., -3.])   和・積・差分 1つの配列に含まれる要素の和・積・差分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1, 2], [3, 4]]) \u0026gt;\u0026gt;\u0026gt; np.sum(a) # 全要素の和 10 \u0026gt;\u0026gt;\u0026gt; np.sum(a, axis=0) # 列方向の和 array([4, 6]) \u0026gt;\u0026gt;\u0026gt; np.sum(a, axis=1) # 行方向の和 array([3, 7]) \u0026gt;\u0026gt;\u0026gt; np.prod(a) # 全要素の積 24 \u0026gt;\u0026gt;\u0026gt; np.prod(a, axis=0) # 列方向の積 array([3, 8]) \u0026gt;\u0026gt;\u0026gt; np.prod(a, axis=1) # 行方向の積 array([ 2, 12]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[1, 2, 4, 8], [3, 5, 9, 7]]) \u0026gt;\u0026gt;\u0026gt; np.diff(b) # 最大の軸方向(axis=1)の差分 array([[ 1, 2, 4], [ 2, 4, -2]]) \u0026gt;\u0026gt;\u0026gt; np.diff(b, axis=0) # 列方向の差分 array([[ 2, 3, 5, -1]]) \u0026gt;\u0026gt;\u0026gt; np.diff(b, n=2) # n: 差分をとる回数( =np.diff(np.diff(b)) ) array([[ 1, 2], [ 2, -6]])   指数関数・対数関数 1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; np.exp([0, 1]) # 指数関数 array([ 1. , 2.71828183]) \u0026gt;\u0026gt;\u0026gt; np.log([1, np.e]) # 自然対数 array([ 0., 1.]) \u0026gt;\u0026gt;\u0026gt; np.log10([1, 10, 100]) # 常用対数 array([ 0., 1., 2.])   その他 1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt;\u0026gt;\u0026gt; np.sqrt([1, 4, 9]) # 平方根 array([ 1., 2., 3.]) \u0026gt;\u0026gt;\u0026gt; np.cbrt([1, 8, 27]) # 立方根（三乗根） array([ 1., 2., 3.]) \u0026gt;\u0026gt;\u0026gt; np.square([1, 2, 3]) # 二乗 array([1, 4, 9], dtype=int32) \u0026gt;\u0026gt;\u0026gt; np.absolute([-3, -1, 1, 3]) # 絶対値 array([3, 1, 1, 3]) \u0026gt;\u0026gt;\u0026gt; np.sign([-3, -1, 1, 3]) # 符号 array([-1, -1, 1, 1]) \u0026gt;\u0026gt;\u0026gt; np.maximum([-3, -1, 1, 3], [4, 2, -2, -4]) # 各要素の最大値 array([4, 2, 1, 3]) \u0026gt;\u0026gt;\u0026gt; np.minimum([-3, -1, 1, 3], [4, 2, -2, -4]) # 各要素の最小値 array([-3, -1, -2, -4])   1つの配列の最大値・最小値を求める場合は、np.max, np.min関数を使う。\n参考リンク Mathematical functions — NumPy v1.19 Manual\n","description":"NumPyで利用できる数学の関数について。","id":68,"section":"posts","tags":["Python","NumPy"],"title":"NumPyで使える数学の関数","uri":"https://helve2017.github.io/posts/python/numpy-math-function/"},{"content":"はじめに NumPy配列の四則演算と線形代数学の演算について。\n環境    ソフトウェア バージョン     NumPy 1.19    基本的な四則演算 NumPy配列同士の四則演算は、Pythonにおける通常の四則演算と同様に行える。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; a = np.array([[1,2],[3,4]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[5,6],[7,8]]) \u0026gt;\u0026gt;\u0026gt; a+b # 足し算 array([[ 6, 8], [10, 12]]) \u0026gt;\u0026gt;\u0026gt; b-a # 引き算 array([[4, 4], [4, 4]]) \u0026gt;\u0026gt;\u0026gt; a*b # 要素ごとの掛け算 array([[ 5, 12], [21, 32]]) \u0026gt;\u0026gt;\u0026gt; b/a # 要素ごとの割り算 array([[ 5. , 3. ], [ 2.33333333, 2. ]]) \u0026gt;\u0026gt;\u0026gt; b%a # 要素ごとの剰余 array([[0, 0], [1, 0]], dtype=int32) \u0026gt;\u0026gt;\u0026gt; a**2 # 要素ごとの累乗 array([[ 1, 4], [ 9, 16]], dtype=int32)   線形代数学の演算 簡単な内積や外積の計算ならば、 NumPyデフォルトのメソッドで計算できるが、 ベクトルのノルムや連立方程式の解を求める場合は、 線形代数学(Linear algebra)のライブラリlinalgを使う。\nこの記事ではlinalgを以下のようにインポートする。\n1  \u0026gt;\u0026gt;\u0026gt; from numpy import linalg as LA   内積・外積 2つの行列同士の内積を計算する場合、2つの方法がある。 1つ目は配列のdot()メソッドを用いる方法、 2つ目はNumPyのnp.dot()関数として使う方法である。\n1 2 3 4 5 6 7 8 9  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1,2],[3,4]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[5,6],[7,8]]) \u0026gt;\u0026gt;\u0026gt; c = np.array([9, 10]) \u0026gt;\u0026gt;\u0026gt; a.dot(b) # 行列の内積(その1) array([[19, 22], [43, 50]]) \u0026gt;\u0026gt;\u0026gt; np.dot(a, b) # 行列の内積(その2) array([[19, 22], [43, 50]])   3つ以上の行列同士の内積を計算する場合、LA.multi_dot()関数を用いる。 また、1つの行列の内積を何度もとる場合は、LA.matrix_power()関数を用いる。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; LA.multi_dot([a,b,c]) # 複数の配列の内積 array([391, 887]) \u0026gt;\u0026gt;\u0026gt; LA.matrix_power(a, 3) # 行列の内積の階乗(=LA.multi_dot([a,a,a])) array([[ 37, 54], [ 81, 118]])   2つの行列同士の外積を計算する場合、np.cross()関数を用いる。　1 2 3 4  \u0026gt;\u0026gt;\u0026gt; d = np.array([1, 2, 3]) \u0026gt;\u0026gt;\u0026gt; e = np.array([4, 5, 6]) \u0026gt;\u0026gt;\u0026gt; np.cross(d, e) # ベクトルの外積 array([-3, 6, -3])   ノルム・ランク・行列式 ベクトルのノルムを計算する場合、LA.norm()関数を用いる。 また、行列のランク（階数）を計算する場合はLA.matrix_rank()関数、 行列式を計算する場合はLA.det()関数をそれぞれ用いる。\n1 2 3 4 5 6 7 8  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1,2],[3,4]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([1,2,3]) \u0026gt;\u0026gt;\u0026gt; LA.norm(b) # ベクトルのノルム 3.7416573867739413 \u0026gt;\u0026gt;\u0026gt; LA.matrix_rank(a) # 行列のランク（階数） 2 \u0026gt;\u0026gt;\u0026gt; LA.det(a) # 行列式 (1*4-2*3) -2.0000000000000004   転置 行列の転置を計算する場合、元の行列のtransepose()メソッドまたは、 Tメソッドを用いる。\n1 2 3 4 5 6 7  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1,2],[3,4]]) \u0026gt;\u0026gt;\u0026gt; a.transpose() # 行列の転置（その1） array([[1, 3], [2, 4]]) \u0026gt;\u0026gt;\u0026gt; a.T # 行列の転置（その2） array([[1, 3], [2, 4]])   逆行列 行列を計算する場合、LA.inv()関数を用いる。\n1 2 3 4  \u0026gt;\u0026gt;\u0026gt; b = np.array([[1,2],[3,4]]) \u0026gt;\u0026gt;\u0026gt; LA.inv(b) # 逆行列 array([[-2. , 1. ], [ 1.5, -0.5]])   連立方程式の解 配列で定義された連立方程式を解く場合、LA.solve()関数を用いる。\n1 2 3 4 5 6 7  \u0026gt;\u0026gt;\u0026gt; # 次の連立方程式を解く \u0026gt;\u0026gt;\u0026gt; # 3x + y = 9 \u0026gt;\u0026gt;\u0026gt; # x + 2y = 8 \u0026gt;\u0026gt;\u0026gt; a = np.array([[3,1], [1,2]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([9,8]) \u0026gt;\u0026gt;\u0026gt; LA.solve(a, b) array([ 2., 3.])   固有値・固有ベクトル 1 2 3 4 5 6 7  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1,2],[3,4]]) \u0026gt;\u0026gt;\u0026gt; w, v=LA.eig(a) # w: 行列の固有値、v: 固有ベクトル（正規化済み） \u0026gt;\u0026gt;\u0026gt; w array([-0.37228132, 5.37228132]) \u0026gt;\u0026gt;\u0026gt; v # 固有ベクトルv[i]は、固有値w[i]に対応する array([[-0.82456484, -0.41597356], [ 0.56576746, -0.90937671]])   特異値分解 1 2 3 4 5 6 7 8 9 10 11  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1, 2, 3], [4, 5, 6]]) # m x n行列のとき \u0026gt;\u0026gt;\u0026gt; U, s, V = np.linalg.svd(a) # 特異値分解 \u0026gt;\u0026gt;\u0026gt; U # U: m x mの直行行列 array([[-0.3863177 , -0.92236578], [-0.92236578, 0.3863177 ]]) \u0026gt;\u0026gt;\u0026gt; s # s: 特異値 array([ 9.508032 , 0.77286964]) \u0026gt;\u0026gt;\u0026gt; V # V: n x nの直行行列 array([[-0.42866713, -0.56630692, -0.7039467 ], [ 0.80596391, 0.11238241, -0.58119908], [ 0.40824829, -0.81649658, 0.40824829]])   参考リンク Linear algebra (numpy.linalg) — NumPy v1.19 Manual\n","description":"NumPy配列の四則演算と線形代数学の演算について。","id":69,"section":"posts","tags":["Python","NumPy"],"title":"NumPy配列の演算","uri":"https://helve2017.github.io/posts/python/numpy-array-calculation/"},{"content":"はじめに NumPy配列のコピーや次元の結合、結合・分割、ソートについて。\n環境    ソフトウェア バージョン     NumPy 1.19    配列のコピー =でコピーすると、コピー元とコピー先で同じオブジェクトを参照するため、\nどちらかを操作するともう片方も変更される (Shallow copy)。\n一方、copyメソッドでコピーすると、コピー先で新たにオブジェクトを作成するため、\nどちらかを操作しても、もう片方には反映されない (Deep copy)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; a = np.array([1,2,3]) \u0026gt;\u0026gt;\u0026gt; b=a # Shallow copy \u0026gt;\u0026gt;\u0026gt; b[0]=4 \u0026gt;\u0026gt;\u0026gt; b array([4, 2, 3]) \u0026gt;\u0026gt;\u0026gt; a array([4, 2, 3]) # aも変更される \u0026gt;\u0026gt;\u0026gt; c=a.copy() # Deep copy \u0026gt;\u0026gt;\u0026gt; c[0]=5 \u0026gt;\u0026gt;\u0026gt; c array([5, 2, 3]) \u0026gt;\u0026gt;\u0026gt; a array([4, 2, 3]) # aは変更されない   サイズ・次元の変更 reshapeを使うと、指定したサイズに変形された配列が返される。 ただし、元の配列のサイズは変更されない。 行数または列数の片方のみを指定するときは、 指定しない次元の要素数を-1とすると、自動で変形してくれる。\nまた、flattenを使うと、2次元配列を1次元配列に変換できる。 こちらも元の配列のサイズは変更されない。\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026gt;\u0026gt;\u0026gt; a = np.array([[1,2,3], ... [4,5,6]]) # 2x3行列 \u0026gt;\u0026gt;\u0026gt; a.reshape([3,2]) # 3x2行列に変形。ビューを返す。 array([[1, 2], [3, 4], [5, 6]]) \u0026gt;\u0026gt;\u0026gt; a.reshape([3,-1]) # サイズを指定しない次元を-1とすると、自動的に変形してくれる array([[1, 2], [3, 4], [5, 6]]) \u0026gt;\u0026gt;\u0026gt; a.flatten() # 1次元配列を作成 array([1, 2, 3, 4, 5, 6])   1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; a.flatten() # 1次元配列に変換 array([1, 2, 3, 4, 5, 6]) \u0026gt;\u0026gt;\u0026gt; a # aのサイズは変わらない array([[1, 2, 3], [4, 5, 6]])   結合 2つのNumPy配列を1つのNumPy配列に結合する。\n   関数 記法 説明     vstack np.vstack([a,b]) 縦(0軸)方向に結合   hstack np.hstack([a,b]) 横(1軸)方向に結合   dstack np.dstack([a,b]) 深さ(2軸)方向に結合   concatenate np.concatenate([a,b], axis=0) 指定した軸方向に結合    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026gt;\u0026gt;\u0026gt; a = np.array([[0,1], ... [2,3]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[4,5], ... [6,7]]) \u0026gt;\u0026gt;\u0026gt; np.hstack([a,b]) array([[0, 1, 4, 5], [2, 3, 6, 7]]) \u0026gt;\u0026gt;\u0026gt; np.vstack([a,b]) array([[0, 1], [2, 3], [4, 5], [6, 7]]) \u0026gt;\u0026gt;\u0026gt; np.concatenate([a,b],axis=0) array([[0, 1], [2, 3], [4, 5], [6, 7]]) \u0026gt;\u0026gt;\u0026gt; np.concatenate([a,b],axis=1) array([[0, 1, 4, 5], [2, 3, 6, 7]])   分割 NumPy配列を分割する。分割された配列はリスト形式で返される。\n   関数 記法 説明     vsplit np.vsplit(a,n) 縦(0軸)方向に結合・分割   hsplit np.hsplit(a,n) 横(1軸)方向に結合・分割   dsplit np.dsplit(a,n) 深さ(2軸)方向に結合・分割   split np.split(a, axis=0) 指定した軸方向に結合・分割    nは、整数またはリストである。 nが整数の場合、配列はn個に均等分割される。 そのため、nは分割したい軸方向の配列の要素数の約数でなければならない。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026gt;\u0026gt;\u0026gt; a=np.arange(16.0).reshape(4, 4) \u0026gt;\u0026gt;\u0026gt; a array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [ 12., 13., 14., 15.]]) \u0026gt;\u0026gt;\u0026gt; np.vsplit(a,2) # 2つに均等分割 [array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.]]), array([[ 8., 9., 10., 11.], [ 12., 13., 14., 15.]])] \u0026gt;\u0026gt;\u0026gt; np.vsplit(a,4) # 4つに均等分割 [array([[ 0., 1., 2., 3.]]), array([[ 4., 5., 6., 7.]]), array([[ 8., 9., 10., 11.]]), array([[ 12., 13., 14., 15.]])]   また、nをリストにすることで、分割する位置を指定できる。 リストは昇順にソートされた整数からなる。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; np.vsplit(a,[3]) # 3行目で分割 [array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]]), array([[ 12., 13., 14., 15.]])] \u0026gt;\u0026gt;\u0026gt; np.vsplit(a,[1,2]) # 1, 2行目で分割 [array([[ 0., 1., 2., 3.]]), array([[ 4., 5., 6., 7.]]), array([[ 8., 9., 10., 11.], [ 12., 13., 14., 15.]])]   ソート 配列をソートするには、sort関数を使う。 ただし、昇順のソートしかできないため、降順にソートした結果が欲しい場合はスライスなどを使う必要がある。\n1次元配列の場合。\n1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; a = np.array([1,3,5,2,4]) # 1次元配列の場合 \u0026gt;\u0026gt;\u0026gt; np.sort(a) # 昇順にソート array([1, 2, 3, 4, 5]) \u0026gt;\u0026gt;\u0026gt; np.sort(a)[::-1] # 降順にソートする場合は、スライスを使う array([5, 4, 3, 2, 1])   2次元配列の場合。 必要に応じてソートする次元を指定する。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; b=np.array([[1,3,5], # 2次元配列の場合 [6,4,2]]) \u0026gt;\u0026gt;\u0026gt; np.sort(b) # デフォルトでは最大次元の軸に沿ってソート array([[1, 3, 5], [2, 4, 6]]) \u0026gt;\u0026gt;\u0026gt; np.sort(b, axis=0) # axisでソートする軸を指定 array([[1, 3, 2], [6, 4, 5]]) \u0026gt;\u0026gt;\u0026gt; np.sort(b, axis=None) # axis=Noneで1次元配列にして返す array([1, 2, 3, 4, 5, 6])   参考リンク Array manipulation routines — NumPy v1.19 Manual\nQuickstart tutorial — NumPy v1.19 Manual\n","description":"NumPy配列のコピーや次元の結合、結合・分割、ソートについて。","id":70,"section":"posts","tags":["Python","NumPy"],"title":"NumPy配列の操作","uri":"https://helve2017.github.io/posts/python/numpy-array-manipulation/"},{"content":"はじめに 作成したNumPy配列の要素などを確認する。\n環境    ソフトウェア バージョン     NumPy 1.19    配列の属性 作成した配列の次元数を確認する場合、 ndim属性を参照する。\nまた、配列の要素数を確認する場合、 size属性を参照する。\n配列の各次元の要素数を確認する場合、 shape属性を参照すると、タプル形式で要素数が返されれる。\n1 2 3 4 5 6 7 8  \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; a = np.array([[1,2,3],[4,5,6]]) # 2x3行列 \u0026gt;\u0026gt;\u0026gt; a.ndim # 次元 2 \u0026gt;\u0026gt;\u0026gt; a.size # 要素数 6 \u0026gt;\u0026gt;\u0026gt; a.shape # 各次元の要素数 (2, 3)   要素へのアクセス 1次元配列の場合 1次元配列の要素を取り出す場合、 配列の後ろに[]を付け、取り出したい要素の順番を数値で指定する。\n要素を1個だけ取り出すときは、[]内に数値を1個指定する。 ただし、配列の最初の要素は0から始まることに注意。\n1 2 3  \u0026gt;\u0026gt;\u0026gt; b = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) \u0026gt;\u0026gt;\u0026gt; b[1] # 1番目 1   連続した複数の要素を取り出すときは、2つの数字を:（コロン）でつなぐと、 最初の数字で指定した要素から、2番めの数字で指定した1つ手前の要素までが返される。\n2番目の数字を指定しない場合、最初の数字で指定した要素から、最後の要素までが返される。 また、1番目の数字を指定しない場合、最初の要素から、2番目の数字で指定した要素までが返される。\n1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; b[1:7] # 1番目から7番目まで array([1, 2, 3, 4, 5, 6]) \u0026gt;\u0026gt;\u0026gt; b[3:] # 3番目以降 array([3, 4, 5, 6, 7, 8, 9]) \u0026gt;\u0026gt;\u0026gt; b[:3] # 3番目まで array([0, 1, 2])   複数の要素を一定の間隔（2つ飛ばしなど）で抜き出すときは、 3つの数字を:でつなぐ。1番めの数字は始まりの要素、 2番目の数字は終わりの要素、3番目の数字は要素をいくつ飛ばすかを表す。\n1 2  \u0026gt;\u0026gt;\u0026gt; b[1:7:2] # 1番目から7番目まで2つ飛ばしで array([1, 3, 5])   配列の末尾を起点として要素の位置を指定する場合、数値にマイナスを付ける。\n1 2  \u0026gt;\u0026gt;\u0026gt; b[-2] # 末尾から2番目 8   配列の複数の要素を全て指定して取り出す場合には、 リストで要素の位置を指定する。\n1 2  \u0026gt;\u0026gt;\u0026gt; b[[0,5,7]] # リストで複数のインデックスを指定 array([0, 5, 7])   2次元配列の場合 2次元配列の場合、行の要素と、列の要素をカンマ,で区切って指定する。 カンマを使わない場合、どの行を取り出すかが指定され、列方向の要素は全て返される。\n各行・各列の要素の指定方法は、1次元配列の場合と同じである。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026gt;\u0026gt;\u0026gt; c = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]]) \u0026gt;\u0026gt;\u0026gt; c array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) \u0026gt;\u0026gt;\u0026gt; c[1,1] # (1, 1)要素 6 \u0026gt;\u0026gt;\u0026gt; c[0:2] # 0～1行目 array([[1, 2, 3, 4], [5, 6, 7, 8]]) \u0026gt;\u0026gt;\u0026gt; c[:, 0:3] # 0～2列目 array([[ 1, 2, 3], [ 5, 6, 7], [ 9, 10, 11]]) \u0026gt;\u0026gt;\u0026gt; c[0:2,1:3] # 0～1行目かつ1～2列目 array([[2, 3], [6, 7]])   参考リンク The N-dimensional array (ndarray) — NumPy v1.19 Manual\nIndexing — NumPy v1.19 Manual\n","description":"作成したNumPy配列の要素などを確認する。","id":71,"section":"posts","tags":["Python","NumPy"],"title":"NumPy配列の確認","uri":"https://helve2017.github.io/posts/python/numpy-array-check/"},{"content":"はじめに NumPyを使って基本的な配列や線形代数学でよく使われる配列を生成する。\n環境    ソフトウェア バージョン     NumPy 1.19    基本的な配列の作成 NumPyは、ベクトルや行列の計算を効率良く行うためのモジュールである。\n初めに、以下のコマンドを入力してNumPyを取り込む。\nas以下に npと入力すると、NumPyをnpと短縮して呼び出せる。\n1  \u0026gt;\u0026gt;\u0026gt; import numpy as np   配列の中身を自分で指定して作成する場合、 np.array()メソッドを用いる。\nnp.array()は、引数にPythonのリストをとる。\nリストを重ねる（ネストする）ことで、2次元や3次元の配列を作成できる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt;\u0026gt;\u0026gt; a = np.array([1,2,3]) # 1次元配列 \u0026gt;\u0026gt;\u0026gt; a array([1, 2, 3]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[1,2,3],[4,5,6]]) # 2次元配列 \u0026gt;\u0026gt;\u0026gt; b array([[1, 2, 3], [4, 5, 6]]) \u0026gt;\u0026gt;\u0026gt; c = np.array([[[1,2],[3,4]],[[5,6],[7,8]]]) # 3次元配列 \u0026gt;\u0026gt;\u0026gt; c array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])   線形代数学でよく使われる配列の生成 全要素が0の配列 全要素が0の配列を作成する場合、np.zeros()メソッドや np.zeros_like()メソッドを用いる。\nnp.zeros()メソッドの場合、引数に整数をとると、 その整数の数だけ0要素を持つ1次元の配列が作られる。 また、引数に整数のリストをとると、2次元以上の0配列が作られる。\n一方、np.zeros_like()メソッドの場合、 引数に他のNumPy配列をとり、その配列と同じ形の0配列が作られる。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; np.zeros(3) # 1次元の配列 array([ 0., 0., 0.]) \u0026gt;\u0026gt;\u0026gt; np.zeros([2,3]) # 2次元の配列 array([[ 0., 0., 0.], [ 0., 0., 0.]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[1, 2, 3], ... [4, 5, 6]]) \u0026gt;\u0026gt;\u0026gt; np.zeros_like(b) # 他の配列と同じサイズの配列 array([[0, 0, 0], [0, 0, 0]])   全要素が1の配列 全要素が1の配列を作成する場合、np.ones()メソッドや np.ones_like()メソッドを用いる。\n配列の作成方法は、それぞれnp.zeros(), np.zeros_like()メソッドに同じ。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; np.ones(3) # 1次元の配列 array([ 1., 1., 1.]) \u0026gt;\u0026gt;\u0026gt; np.ones([2,3]) # 2次元の配列 array([[ 1., 1., 1.], [ 1., 1., 1.]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[1, 2, 3], ... [4, 5, 6]]) \u0026gt;\u0026gt;\u0026gt; np.ones_like(b) # 他の配列と同じサイズの配列 array([[1, 1, 1], [1, 1, 1]])   全要素が同じ値の配列 全要素が同じ値の配列を作成する場合、np.full()メソッドや np.full_like()メソッドを用いる。\nnp.full()メソッドは引数を2つとり、 第1引数で配列の形を、第2引数で配列の値を指定する。 2次元以上の配列を作成したい場合、第1引数がリストにする。\nまた、np.full_like()メソッドは、 第1引数に他のNumPy配列、第2引数に値をとる。 第1引数の配列と同じ形かつ、全要素が第2引数と同じ値の配列が作成される。\n1 2 3 4 5 6 7 8 9 10  \u0026gt;\u0026gt;\u0026gt; np.full(3, 10) # 1次元の配列 array([10, 10, 10]) \u0026gt;\u0026gt;\u0026gt; np.full([2,2], 10) # 2次元の配列 array([[ 10., 10.], [ 10., 10.]]) \u0026gt;\u0026gt;\u0026gt; b = np.array([[1, 2, 3], ... [4, 5, 6]]) \u0026gt;\u0026gt;\u0026gt; np.full_like(b, 10) # 他の配列と同じサイズの配列 array([[10, 10, 10], [10, 10, 10]])   単位行列など 単位行列を作成する場合、np.identity()メソッドまたは np.eye()メソッドを用いる。\nnp.identity()メソッドの場合、 引数として与えた整数の大きさの単位行列が作成される。\nまた、np.eye()メソッドの場合、 引数に整数を1つだけ与えると、np.identity()と同様に単位行列が作成される。 一方、引数をnp.eye(n, m)のように2つ与えると、主対角成分が1のn×m行列が作成される。 さらに、引数kで値が1となる対角を指定できる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026gt;\u0026gt;\u0026gt; np.identity(3) # 単位行列 array([[ 1., 0., 0.], [ 0., 1., 0.], [ 0., 0., 1.]]) \u0026gt;\u0026gt;\u0026gt; np.eye(3) # 単位行列(引数が1個の場合) array([[ 1., 0., 0.], [ 0., 1., 0.], [ 0., 0., 1.]]) \u0026gt;\u0026gt;\u0026gt; np.eye(2, 3) # 主対角が1, それ以外が0の3x2行列 array([[ 1., 0., 0.], [ 0., 1., 0.]]) \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; 1となる対角をkで指定（k\u0026gt;0は主対角より上、k\u0026lt;0は主対角より下） \u0026gt;\u0026gt;\u0026gt; np.eye(4, 5, k=1) array([[ 0., 1., 0., 0., 0.], [ 0., 0., 1., 0., 0.], [ 0., 0., 0., 1., 0.], [ 0., 0., 0., 0., 1.]])   三角行列など 三角行列は、主対角より「上」または「下」の成分が全て0である正方行列である。\nnp.tri()メソッドを用いると、下三角行列を作成できる。 引数に整数を1つ与えると、その整数の大きさの正方行列になる。 引数にnp.tri(n, m)のように整数を2つ与えると、 主対角より上が0となるn×m行列が作成される。 また、引数kでどの対角から上が0となるか指定できる。\n1 2 3 4 5 6 7 8 9 10 11 12  \u0026gt;\u0026gt;\u0026gt; np.tri(3) array([[ 1., 0., 0.], [ 1., 1., 0.], [ 1., 1., 1.]]) \u0026gt;\u0026gt;\u0026gt; np.tri(3,5) array([[ 1., 0., 0., 0., 0.], [ 1., 1., 0., 0., 0.], [ 1., 1., 1., 0., 0.]]) \u0026gt;\u0026gt;\u0026gt; np.tri(3,5,k=-1) # k\u0026gt;0は主対角より上の対角、k\u0026lt;0は主対角より下の対角 array([[ 0., 0., 0., 0., 0.], [ 1., 0., 0., 0., 0.], [ 1., 1., 0., 0., 0.]])   また、他の配列に対して、三角部分の要素を0とした配列を得るためには、 np.tril()メソッドまたは np.triu()メソッドを用いる。 それぞれ、引数にとった行列の上三角部分と下三角部分を0とした行列を返す。 また、引数kで0とする対角を指定できる。\n1 2 3 4 5 6 7 8 9 10 11 12 13  \u0026gt;\u0026gt;\u0026gt; b = np.array([[1,2,3],[4,5,6]]) \u0026gt;\u0026gt;\u0026gt; b array([[1, 2, 3], [4, 5, 6]]) \u0026gt;\u0026gt;\u0026gt; np.tril(b) # 行列の下三角部分 array([[1, 0, 0], [4, 5, 0]]) \u0026gt;\u0026gt;\u0026gt; np.tril(b, k=-1) # kで0とする対角を指定（デフォルトはk=0: 主対角） array([[0, 0, 0], [4, 0, 0]]) \u0026gt;\u0026gt;\u0026gt; np.triu(b) # 行列の上三角部分 array([[1, 2, 3], [0, 5, 6]])   その他の特殊な配列の作成 線形に等間隔な1次元配列 1 2 3 4 5 6  \u0026gt;\u0026gt;\u0026gt; np.arange(1,10) # 区間[1, 10)の整数 array([1, 2, 3, 4, 5, 6, 7, 8, 9]) \u0026gt;\u0026gt;\u0026gt; np.arange(1,10,2) # 区間[1, 10)の整数を2刻みで array([1, 3, 5, 7, 9]) \u0026gt;\u0026gt;\u0026gt; np.linspace(2,3,5) # 線形に等間隔な区間[2, 3]の数を5個 array([ 2. , 2.25, 2.5 , 2.75, 3. ])   対数的に等間隔な1次元配列 1 2 3 4 5  \u0026gt;\u0026gt;\u0026gt; np.logspace(1, 2, 5) # 10^1から10^2まで対数的に等間隔な5個の配列 array([ 10. , 17.7827941 , 31.6227766 , 56.23413252, 100. ]) \u0026gt;\u0026gt;\u0026gt; np.logspace(1, 5, 5, base=2) # baseで対数の底を指定 array([ 2., 4., 8., 16., 32.])   ランダムな要素を持つ配列 numpy.randomモジュールを使用する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026gt;\u0026gt;\u0026gt; np.random.seed(0) \u0026gt;\u0026gt;\u0026gt; # シード値(非負の整数)を設定すると、常に一定順序で乱数列が発生 \u0026gt;\u0026gt;\u0026gt; np.random.rand(2,3) # 区間[0, 1)で一様分布 array([[0.5488135 , 0.71518937, 0.60276338], [0.54488318, 0.4236548 , 0.64589411]]) \u0026gt;\u0026gt;\u0026gt; np.random.randn(2, 3) # 正規分布（平均0, 分散1） array([[ 0.95008842, -0.15135721, -0.10321885], [ 0.4105985 , 0.14404357, 1.45427351]]) \u0026gt;\u0026gt;\u0026gt; np.random.randint(10) # 区間[0, 10)で均等分布の整数（引数1つの場合） 8 \u0026gt;\u0026gt;\u0026gt; np.random.randint(5, 10) # 区間[5, 10)で均等分布の整数（引数2つの場合） 6 \u0026gt;\u0026gt;\u0026gt; np.random.randint(5, 10, size=(2, 4)) # sizeオプションで配列サイズを指定 array([[6, 5, 6, 9], [8, 5, 8, 5]])   参考リンク Array creation — NumPy v1.19 Manual\nRandom sampling (numpy.random) — NumPy v1.19 Manual\n","description":"NumPyを使って基本的な配列や線形代数学でよく使われる配列を生成する。","id":72,"section":"posts","tags":["Python","NumPy"],"title":"NumPyによる配列の作成","uri":"https://helve2017.github.io/posts/python/numpy-array-construction/"},{"content":"時系列データベースInfluxDBのクエリ文について、データの期間の指定や集約処理など、基本的な構文をまとめた。\nはじめに InfluxDBは時系列データの扱いに特化したデータベースである。概要は以下の記事を参照。\n時系列データベースInfluxDB入門\nInfluxDBではデータを取得するために、SQLに似た独自のクエリ文を採用している。クエリ文では、取得するデータの期間を指定したり、移動平均や最大値を計算する処理などの処理を行うことができる。本記事では、クエリ文の基本的な構文をまとめた。\nまた、本記事ではPythonのAPIを使っているが、他の言語やCLIで扱う場合もクエリの構文自体は変わらない。\n本記事の環境は以下の通り。\n Linux Mint 19.3 (Cinnamon) InfluxDB 1.8.0  また、Pythonのバージョンは以下の通り。\n    バージョン     Python 3.7.6   NumPy 1.18.1   Pandas 1.0.1   Influxdb-python 5.2.2    以降では、ライブラリを以下のようにインポートすることを前提とする。\n1 2 3  import numpy as np import pandas as pd import influxdb   使用するデータ まず、以下のPythonコードを実行し、テスト用のデータをInfluxDBに書き込む。\n1 2 3 4 5 6 7  client = influxdb.DataFrameClient() client.create_database(\u0026#34;test\u0026#34;) array = np.arange(240).reshape(-1, 2) index = pd.date_range(pd.Timestamp(\u0026#34;2020-05-01 00:00:00\u0026#34;), pd.Timestamp(\u0026#34;2020-05-05 23:00:00\u0026#34;), freq=\u0026#34;1H\u0026#34;) df = pd.DataFrame(array, index=index, columns=[\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;]) client.write_points(df, \u0026#34;meas1\u0026#34;, database=\u0026#34;test\u0026#34;)   このコードでは、testという名前のデータベースを作成し、meas1という名前のmeasurementでデータを書き込む。\nデータdfは以下に示すように、120行×2列の配列で、時刻は2020年5月1日0時〜5月5日23時まで1時間周期（120時間）とする。field keyは、\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;である。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026gt;\u0026gt;\u0026gt; print(df) A B 2020-05-01 00:00:00 0 1 2020-05-01 01:00:00 2 3 2020-05-01 02:00:00 4 5 2020-05-01 03:00:00 6 7 2020-05-01 04:00:00 8 9 ... ... ... 2020-05-05 19:00:00 230 231 2020-05-05 20:00:00 232 233 2020-05-05 21:00:00 234 235 2020-05-05 22:00:00 236 237 2020-05-05 23:00:00 238 239 [120 rows x 2 columns]   基本構文 最も基本となるクエリ文は、以下のようにSELECT \u0026lt;field名\u0026gt;とFROM \u0026lt;measurement名\u0026gt;の2つからなる。\n1  SELECT \u0026lt;field名\u0026gt; FROM \u0026lt;measurement名\u0026gt;   公式リファレンスでは、それぞれSELECT節 (clause), FROM節と呼んでいる。上記のクエリによって、指定したmeasurementのfieldのデータを全て取得する。\n例：meas1のA のデータを全て取得する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026gt;\u0026gt;\u0026gt; res = client.query(\u0026#34;SELECT A FROM meas1\u0026#34;, database=\u0026#34;test\u0026#34;) \u0026gt;\u0026gt;\u0026gt; list(res.values())[0] A 2020-05-01 00:00:00+00:00 0 2020-05-01 01:00:00+00:00 2 2020-05-01 02:00:00+00:00 4 2020-05-01 03:00:00+00:00 6 2020-05-01 04:00:00+00:00 8 ... ... 2020-05-05 19:00:00+00:00 230 2020-05-05 20:00:00+00:00 232 2020-05-05 21:00:00+00:00 234 2020-05-05 22:00:00+00:00 236 2020-05-05 23:00:00+00:00 238 [120 rows x 1 columns]   ここで、list(res.values())[0]としたのは、PythonのAPIの仕様（queryメソッドの戻り値が辞書）のためである。\nまた、複数のfield名を得るには、カンマ,で区切って指定する。\n1  SELECT \u0026lt;field名\u0026gt;, \u0026lt;field名\u0026gt; FROM \u0026lt;measurement名\u0026gt;   全てのfield名を得るには、アスタリスク*を用いる。\n1  SELECT * FROM \u0026lt;measurement名\u0026gt;   集約処理をする SELECT節のfield名に関数を追加することによって、移動平均や最大値をとるなどの集約処理を行える。集約処理を行う時間幅は、GROUP BY節で指定する。\n1  SELECT \u0026lt;関数名\u0026gt;(\u0026lt;field名\u0026gt;) FROM \u0026lt;measurement名\u0026gt; GROUP BY time(\u0026lt;時間幅\u0026gt;)   主な関数を下表に示す。\n   関数名 意味     MEAN 平均   MEDIAN 中央値   SUM 合計   FIRST 最初の値   LAST 最後の値   MAX 最大値   MIN 最小値   MOVING_AVERAGE 移動平均    ただし、MOVING_AVERAGEは\u0026lt;field名\u0026gt;の後に、第2引数として移動平均をとるデータ数が必須。\nその他の関数は以下を参照。\nInfluxQL functions InfluxDB OSS 1.8 Documentation\nまた、時間幅は5分ならば5m, 3日ならば3dのように指定する。時刻を表す記号は下表の通り。\n   記号 意味     u, µ microseconds   ms milliseconds   s seconds   m minutes   h hours   d days   w weeks    例：field A, Bのデータを6時間ごとに平均をとる（データフレームのカラムがmean, mean_1になっていることに注意）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026gt;\u0026gt;\u0026gt; q1 = \u0026#34;SELECT MEAN(A), MEAN(B) FROM meas1 GROUP BY time(6h)\u0026#34; \u0026gt;\u0026gt;\u0026gt; res = client.query(q1, database=\u0026#34;test\u0026#34;) \u0026gt;\u0026gt;\u0026gt; list(res.values())[0] mean mean_1 2020-05-01 00:00:00+00:00 5 6 2020-05-01 06:00:00+00:00 17 18 2020-05-01 12:00:00+00:00 29 30 2020-05-01 18:00:00+00:00 41 42 2020-05-02 00:00:00+00:00 53 54 2020-05-02 06:00:00+00:00 65 66 2020-05-02 12:00:00+00:00 77 78 2020-05-02 18:00:00+00:00 89 90 2020-05-03 00:00:00+00:00 101 102 2020-05-03 06:00:00+00:00 110 111   時間範囲を指定する データの時間範囲を指定するには、FROM節の後に条件を指定するWHERE節を追加する。\n1  SELECT \u0026lt;field名\u0026gt; FROM \u0026lt;measurement名\u0026gt; WHERE \u0026lt;条件\u0026gt;   例えば、2020年5月1日以降のデータを指定する場合は、以下のようにtimeと等号・不等号を用いる。\n1  WHERE time \u0026gt;= \u0026#39;2020-05-01T00:00:00Z\u0026#39;   InfluxDBが対応する時刻の形式は、RFC3339またはUNIX時刻である。\nRFC3339は、次のような時刻の表示形式である。\n'YYYY-MM-DDTHH:MM:SS.nnnnnnnnnZ'\rただし、秒未満の部分 (.nnnnnnnnn) は任意。\nまた、UNIX時刻とは1970年1月1日午前0時0分0秒からの経過時刻である。InfluxDBのデフォルトの設定では、UNIX時刻をナノ秒単位で指定する。\n例：UTC時刻で2020年5月1日0時0分0秒000000000をナノ秒単位のUNIX時刻で表すと、1588291200000000000である。\nまた、\u0026gt;=の他に下表の演算子が使える。\n   演算子 意味     = 等しい   \u0026lt;\u0026gt;, != 等しくない   \u0026gt; より大きい（後の）   \u0026gt;= 以上の（以降の）   \u0026lt; より小さい（前の）   \u0026lt;= 以下の（以前の）    さらに、複数の条件を指定する場合はAND, ORを用いる。\nただし、現在のバージョン(v1.8)では絶対時刻のORはサポートされていない（相対時刻については後述）。\nInfluxDB frequently asked questions InfluxDB OSS 1.8 Documentation\nSupport disparate time intervals and more advanced time in WHERE clauses · Issue #7530 · influxdata_influxdb\n例：field Aの2020年5月2日のデータだけを取得する場合\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  \u0026gt;\u0026gt;\u0026gt; query = \u0026#34;SELECT A, B FROM meas1\u0026#34; \u0026gt;\u0026gt;\u0026gt; query += \u0026#34; WHERE time \u0026gt;= \u0026#39;2020-05-02T00:00:00Z\u0026#39;\u0026#34; \u0026gt;\u0026gt;\u0026gt; query += \u0026#34; AND time \u0026lt; \u0026#39;2020-05-03T00:00:00Z\u0026#39;\u0026#34; \u0026gt;\u0026gt;\u0026gt; res = client.query(query, database=\u0026#34;test\u0026#34;) \u0026gt;\u0026gt;\u0026gt; list(res.values())[0] A B 2020-05-02 00:00:00+00:00 48 49 2020-05-02 01:00:00+00:00 50 51 2020-05-02 02:00:00+00:00 52 53 2020-05-02 03:00:00+00:00 54 55 2020-05-02 04:00:00+00:00 56 57 2020-05-02 05:00:00+00:00 58 59 2020-05-02 06:00:00+00:00 60 61 2020-05-02 07:00:00+00:00 62 63 2020-05-02 08:00:00+00:00 64 65 2020-05-02 09:00:00+00:00 66 67 2020-05-02 10:00:00+00:00 68 69 2020-05-02 11:00:00+00:00 70 71 2020-05-02 12:00:00+00:00 72 73 2020-05-02 13:00:00+00:00 74 75 2020-05-02 14:00:00+00:00 76 77 2020-05-02 15:00:00+00:00 78 79 2020-05-02 16:00:00+00:00 80 81 2020-05-02 17:00:00+00:00 82 83 2020-05-02 18:00:00+00:00 84 85 2020-05-02 19:00:00+00:00 86 87 2020-05-02 20:00:00+00:00 88 89 2020-05-02 21:00:00+00:00 90 91 2020-05-02 22:00:00+00:00 92 93 2020-05-02 23:00:00+00:00 94 95   なお、現在時刻（クエリ文を処理した時刻）を指定するには、now()とする。これを相対時刻という。\n例：2020年4月1日から現在までのデータを取得する場合\n1  WHERE time \u0026gt;= \u0026#39;2020-04-01T00:00:00Z\u0026#39; AND time \u0026lt;= now()   また、以下のようにクエリ文中で時刻の計算もできる。\n例：10分前から現在までのデータを取得する場合\n1  WHERE time \u0026gt; now() - 10m   タイムゾーンを指定する 取得データのタイムスタンプにタイムゾーンを設定するためには、tz節を追加する。\ntz節では、タイムゾーンをシングルクォーテーション'で囲んで指定する。得られるデータの時刻は、WHERE節の時刻 (UTC) と同じであり、あくまでもタイムスタンプのタイムゾーンが変換されているだけである。\n例：UTC時刻で5月2日のデータを取得し、日本標準時のタイムスタンプに変換する。\nタイムスタンプが+09:00となっている。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u0026gt;\u0026gt;\u0026gt; query = \u0026#34;SELECT A, B FROM meas1 \u0026#34; \u0026gt;\u0026gt;\u0026gt; query += \u0026#34; WHERE time \u0026gt;= \u0026#39;2020-05-02T00:00:00Z\u0026#39;\u0026#34; \u0026gt;\u0026gt;\u0026gt; query += \u0026#34; AND time \u0026lt; \u0026#39;2020-05-03T00:00:00Z\u0026#39;\u0026#34; \u0026gt;\u0026gt;\u0026gt; query += \u0026#34; tz(\u0026#39;Asia/Tokyo\u0026#39;)\u0026#34; \u0026gt;\u0026gt;\u0026gt; res = client.query(query, database=\u0026#34;test\u0026#34;) \u0026gt;\u0026gt;\u0026gt; list(res.values())[0] A B 2020-05-02 09:00:00+09:00 48 49 2020-05-02 10:00:00+09:00 50 51 2020-05-02 11:00:00+09:00 52 53 2020-05-02 12:00:00+09:00 54 55 2020-05-02 13:00:00+09:00 56 57 2020-05-02 14:00:00+09:00 58 59 2020-05-02 15:00:00+09:00 60 61 2020-05-02 16:00:00+09:00 62 63 2020-05-02 17:00:00+09:00 64 65 2020-05-02 18:00:00+09:00 66 67 2020-05-02 19:00:00+09:00 68 69 2020-05-02 20:00:00+09:00 70 71 2020-05-02 21:00:00+09:00 72 73 2020-05-02 22:00:00+09:00 74 75 2020-05-02 23:00:00+09:00 76 77 2020-05-03 00:00:00+09:00 78 79 2020-05-03 01:00:00+09:00 80 81 2020-05-03 02:00:00+09:00 82 83 2020-05-03 03:00:00+09:00 84 85 2020-05-03 04:00:00+09:00 86 87 2020-05-03 05:00:00+09:00 88 89 2020-05-03 06:00:00+09:00 90 91 2020-05-03 07:00:00+09:00 92 93 2020-05-03 08:00:00+09:00 94 95   複数のクエリ文を同時に与える 複数のクエリ文を同時に処理するには、次のようにセミコロン;でつなぐ。\n1  SELECT A FROM meas1; SELECT B FROM meas1   参考 Explore data using InfluxQL | InfluxData Documentation\nInfluxDB インストール - 簡単な使い方 - Qiita\n時系列データベースInfluxDB入門\nPythonとPandasでInfluxDBを操作する\n","description":"時系列データベースInfluxDBのクエリ文について、データの期間の指定や集約処理など基本的な構文をまとめた。","id":73,"section":"posts","tags":["InfluxDB","Pandas"],"title":"時系列データベースInfluxDBのクエリ文","uri":"https://helve2017.github.io/posts/database/influxdb-query-syntax/"},{"content":"はじめに PythonとPandasを使って、時系列データベースInfluxDBを操作する方法についてまとめた。\nInfluxDBは時系列データの扱いに特化したデータベースである。概要は以下の記事を参照。\n時系列データベースInfluxDB入門\nPythonでInfluxDBを操作するには、influx-pythonというライブラリを使う。このライブラリは、InfluxDBを開発したinfluxdata社が公開しているものである。influx-pythonを使うと、PandasのDataFrameでInfluxDBとデータを授受できる。\n環境は以下の通り。\n Linux Mint 19.3 (Cinnamon) InfluxDB 1.8.0  また、Pythonのバージョンは以下の通り。\n    バージョン     Python 3.7.6   NumPy 1.18.1   Pandas 1.0.1   Influxdb-python 5.2.2    ライブラリのインストール PythonからInfluxDBを操作するライブラリinflux-pythonをインストールする。\ncondaの場合：\nconda install -c pdrops influxdb\rpipの場合：\npip install influxdb\r以降では、ライブラリを以下のようにインポートすることを前提とする。\n1 2 3  import numpy as np import pandas as pd import influxdb   influx-pythonの基本 influx-pythonでInfluxDBを操作するために、次の2つのクラスが用意されている。\n InfluxDBClient: JSONを使う DataFrameClient: PandasのDataFrameを使う  本記事では、DataFrameClientを扱う。\nDataFrameClientクラス DataFrameClientクラスの主な引数は以下の通り。\n1 2  influxdb.DataFrameClient(host=u\u0026#39;localhost\u0026#39;, port=8086, username=u\u0026#39;root\u0026#39;, password=u\u0026#39;root\u0026#39;, database=None)   hostはアクセス先のInfluxDBがあるPCのIPアドレスである。同じPCの場合はデフォルト値のlocalhostでよい。\nportはInfluxDBのポート番号である。8086はInfluxDBのデフォルトのポート番号である。\nusername, passwordはInfluxDBにアクセスするためのユーザ名、パスワードである。\u0026lsquo;root\u0026rsquo;はInfluxDBのデフォルト値と同じである。\ndatabaseは接続先のデータベース名である。後ほどメソッド実行時に指定できるので、DataFrameClientオブジェクト作成時に指定する必要はない。\nDataFrameClientクラスの主なメソッドは次の通り。\n   メソッド名 説明     create_database(\u0026lt;データベース名\u0026gt;) データベースを作成する   get_list_database() データベース一覧を取得する   get_list_measurements() measurement一覧を取得する   drop_database(\u0026lt;データベース名\u0026gt;) データベースを削除する   drop_measurement(\u0026lt;measurement名\u0026gt;) measurementを削除する   write_points() DataFrameを書き込む   query() データを取得する    write_points()とquery()については、以降で詳しく述べる。\nInfluxDBへの接続 DataFrameClientクラスを使って、InfluxDBへ接続する。まず、DataFrameClientオブジェクトを作成し、pd_testという名前のデータベースを作成する。\n1 2  client = influxdb.DataFrameClient() client.create_database(\u0026#34;pd_test\u0026#34;)   データベースを既に作成している場合は、以下のようにしても良い。\n1  client = influxdb.DataFrameClient(database=\u0026#34;pd_test\u0026#34;)   DataFrameをInfluxDBに書き込む PandasのDataFrameをInfluxDBに書き込むには、write_pointsメソッドを用いる。\n1  DataFrameClient.write_points(dataframe, measurement,database=None)   引数の説明は次の通り。\n dataframe: PandasのDataFrame measurement: データを追加するmeasurement（表の名前） database: データベース名。  ここで、DataFrameClientオブジェクトにデータベースが設定されていない場合、databaseは必須である。databaseを指定しないと、write_pointsメソッド実行時に以下のエラーが出る。\n1  nfluxDBClientError: 400: {\u0026#34;error\u0026#34;:\u0026#34;database is required\u0026#34;}   一方、DataFrameClientオブジェクトにデータベースが設定されており、かつwrite_pointsメソッドで指定しない場合、オブジェクトに設定されたデータベースにデータが追加される。\n例として、PandasのDataFrameを、先ほど作成したpd_testデータベースに追加する。DataFrameは、10行×2列の大きさで、2020年4月1日から1日周期でインデックスを振っている。ここで、measurement名はmeas1とした。\n1 2 3 4 5  array = np.arange(20).reshape(-1, 2) index = pd.date_range(pd.Timestamp(\u0026#34;20200401\u0026#34;), freq=\u0026#34;1D\u0026#34;, periods=10) df = pd.DataFrame(array, index=index, columns=[\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;]) client.write_points(df, \u0026#34;meas1\u0026#34;, database=\u0026#34;pd_test\u0026#34;)   DataFrameをInfluxDBから取得する InfluxDBからデータを取得するには、queryメソッドを用いる。\n1  DataFrameClient.query(query, database=None)   引数の説明は以下の通り。\n query: InfluxDBのクエリ文。 database: データベース名。  クエリ文の構文の詳細については、別記事で説明予定。\nここで、DataFrameClientオブジェクトにデータベースが設定されていない場合、databaseは必須である。一方、DataFrameClientオブジェクトにデータベースが設定されており、かつwrite_pointsメソッドで指定しない場合、オブジェクトに設定されたデータベースにデータが追加される。\nまた、queryメソッドの戻り値は辞書型（正確にはdefaultdict）であり、キーがmeasurement, 値がデータフレームになる。\n例として、先程write_pointsメソッドで書き込んだデータを取得する。\n1 2 3  q1 = \u0026#34;SELECT * FROM meas1\u0026#34; res = client.query(q1, database=\u0026#34;pd_test\u0026#34;) print(res)   ここで、クエリ文\nSELECT * FROM meas1\rは、measurement meas1の全てのfieldを取得することを表す。\n実行結果\nqueryメソッドの戻り値resは辞書型であり、キーがmeasurement meas1, 値がDataFrameとなる。また、DataFrameのindexはDateTimeIndex, columnsはInfluxDBのfieldとなる。\n1 2 3 4 5 6 7 8 9 10 11  defaultdict(\u0026lt;class \u0026#39;list\u0026#39;\u0026gt;, {\u0026#39;meas1\u0026#39;: A B 2020-04-01 00:00:00+00:00 0 1 2020-04-02 00:00:00+00:00 2 3 2020-04-03 00:00:00+00:00 4 5 2020-04-04 00:00:00+00:00 6 7 2020-04-05 00:00:00+00:00 8 9 2020-04-06 00:00:00+00:00 10 11 2020-04-07 00:00:00+00:00 12 13 2020-04-08 00:00:00+00:00 14 15 2020-04-09 00:00:00+00:00 16 17 2020-04-10 00:00:00+00:00 18 19})   なお、DataFrameを直接取得する場合には、\ndf = list(res.values())[0]\rなどのようにする。\n参考 Welcome to InfluxDB’s documentation! — InfluxDB 5.3.1 documentation\n時系列データベースInfluxDB入門\n","description":"PythonとPandasを使って、時系列データベースInfluxDBを操作する方法についてまとめた。","id":74,"section":"posts","tags":["InfluxDB","Pandas"],"title":"PythonとPandasでInfluxDBを操作する","uri":"https://helve2017.github.io/posts/database/influxdb-pandas/"},{"content":"はじめに 時系列データベースInfluxDBのインストール方法と、コマンドを用いた基本的な使い方について解説する。\n本記事で検証した環境は以下の通り。\n Linux Mint 19.3 (Cinnamon) InfluxDB 1.8.0  InfluxDBはLinuxだけでなくwindowsやMac OS Xでも利用可能である。\nInfuxDBの基本 InfluxDBは時系列データの扱いに特化したデータベースである。InfluxDBでは、時系列データの移動平均をとるなどの処理をクエリ文で指定することができる。一方、MongoDBなどのドキュメント指向型データベースと比較すると、非構造化データを扱うことは困難である。\nまた、InfluxDBはGrafanaというダッシュボード（ブラウザ上などでデータを可視化するツール）とも連携が可能である。\nさらに、InfluxDBにはPythonのライブラリも用意されており、PandasのDataFrame形式でInfluxDBとデータを容易にやり取りできる。\nInfuxDBのインストール方法 記事執筆時点(2020年4月18日)で、InfluxDBの最新の安定バージョンは1.8.0, 最新のベータ版は2.0である。本記事では1.8.0をインストールする。Debian系のOS (Linux Mint, Ubuntuなど）では、以下のコマンドでインストールする。\nwget https://dl.influxdata.com/influxdb/releases/influxdb_1.8.0_amd64.deb\rsudo dpkg -i influxdb_1.8.0_amd64.deb\rその他のOSのインストール方法は以下のページを参照。\nhttps://portal.influxdata.com/downloads/\nInfluxDBのデータ構造 InfluxDBのデータ構造について述べる。InfluxDBでは、基本的に時系列データのみを扱い、全てのデータは時刻の情報（タイムスタンプ）を持つ。\nデータ構造の最上位にはdatabaseがある。その下にmeasurementがあり、一番下には1つの時系列データを表すfieldがある。fieldのキー（ラベル）をfield_keyと呼ぶ。\n例として、以下の気象データを考える（値はダミー）。temperatureとwind_speedがfield_keyに相当し、表の名前がmeasurementに相当する。このような表をいくつも束ねたものがdatabaseになる。database自体も複数定義することが可能である。\n   時刻 temperature wind_speed     2020-04-25 00:00:00 10.2 3.2   2020-04-25 01:00:00 9.8 4.5   2020-04-25 02:00:00 9.0 2.7    なお、measurementの下には、field_keyの他にデータのメタ情報を表すtag_keyもあるが、本記事では扱わない。\nCLIからInfluxDBを使う InfluxDBの起動 InfluxDBを起動するには、influxコマンドを実行する。起動すると、プロンプトが\u0026gt;に変わる。\n$ influx\rConnected to http://localhost:8086 version 1.8.0\rInfluxDB shell version: 1.8.0\r\u0026gt;\rinfluxDBを終了するには、exitコマンドを実行する。\nデータベースの作成・アクセス データベースを作成するには、CREATE DATABASE \u0026lt;データベース名\u0026gt;とする。\n例：db1という名前のデータベースを作る。\n\u0026gt; CREATE DATABASE db1\rなお、本記事ではInfuxDBの公式リファレンスに準じて、InfluxDBのコマンドを大文字で表記するが、基本的に小文字でも動作する(create database db1)。\n現在作成されているデータベース一覧を確認するには、SHOW DATABASEとする。\n\u0026gt; SHOW DATABASE\rname: databases\rname\r----\r_internal\rdb1\rデータベースにアクセスするには、USE \u0026lt;データベース名\u0026gt;とする。\n\u0026gt; USE db1\rUsing database db1\r時系列データの書き込み データベースにCLIからデータを追加するには、line protocolを使って1行ずつ書き込むことができる。line protocolのフォーマットは以下のようになる。\nINSERT \u0026lt;measurement\u0026gt; \u0026lt;field_key\u0026gt;=\u0026lt;field_values\u0026gt; [\u0026lt;timestamp\u0026gt;]\rtimestampは任意であり、UNIX時刻（ナノ秒単位の整数）で指定する。timestampを指定しない場合は、データを書き込んだ時刻が自動的に付与される。\n例：先程の気象データをweatherというmeasurementに書き込む。\n\u0026gt; INSERT weather temperature=10.2 1587772800000000000\r\u0026gt; INSERT weather wind_speed=3.2 1587772800000000000\r\u0026gt; INSERT weather temperature=9.8 1587776400000000000\r\u0026gt; INSERT weather wind_speed=4.5 1587776400000000000\r時系列データの取得 database内のmeasurement一覧を取得するには、以下のコマンドを実行する。\n\u0026gt; SHOW measurements\rname: measurements\rname\r----\rweather\r書き込んだデータを取得するには、クエリ文を用いる。最も簡単なクエリ文のフォーマットは次のようになる。\nSELECT \u0026lt;field_key\u0026gt; FROM \u0026lt;measurement\u0026gt;\r例：\n\u0026gt; SELECT temperature FROM weather\rname: weather\rtime temperature\r---- -----------\r1587772800000000000 10.2\r1587776400000000000 9.8\rまた、\u0026lt;field_key\u0026gt;にワイルドカード*を指定することで、全てのfieldを取得できる。\n\u0026gt; SELECT * FROM weather\rname: weather\rtime temperature wind_speed\r---- ----------- ----------\r1587772800000000000 10.2 3.2\r1587776400000000000 9.8 4.5\rさらに、クエリ文に条件を付加することによって、指定した期間のデータのみ抽出したり、移動平均などの集約処理を掛けることも可能である。これらは別の記事で説明予定。\nデータの削除 あるfield_keyに含まれるデータを全て削除するには、以下のコマンドを実行する。\nDROP \u0026lt;field_key\u0026gt; FROM \u0026lt;measurement名\u0026gt;\rmeasurementを削除するには、以下のコマンドを実行する。\nDROP MEASUREMENT \u0026lt;measurement名\u0026gt;\rdatabaseを削除するには、以下のコマンドを実行する。\nDROP DATABASE \u0026lt;データベース名\u0026gt;\r参考 InfluxDBの公式リファレンス\nInfluxDB OSS 1.8 Documentation\n","description":"時系列データベースInfluxDBのインストール方法と、コマンドを用いた基本的な使い方について解説する。","id":75,"section":"posts","tags":["InfluxDB"],"title":"時系列データベースInfluxDB入門","uri":"https://helve2017.github.io/posts/database/infludb-introduction/"},{"content":"はじめに Plotlyは、マウス等でインタラクティブに動かすことができるグラフを生成するPythonのライブラリである。\nこのようなグラフをブログなどのWebページに埋め込む方法の一つとして、Plotlyの開発チームが運営するサービス (Chart Studio Cloud) に登録して、埋め込み用のリンクを生成する方法がある。\n無料のプランでも、グラフを25個まで作成できる（2019/05/01現在）。\nPlotlyのグラフ Plotlyのグラフのサンプルを以下に示す。\n（線上にマウスカーソルを置いたり、凡例をクリックしてみて下さい）\n\rChart Studio Cloudへの登録 以下のページから、Chart Studio Cloudへ登録する（メールアドレスが必要）。\nChart Studio Cloud\nProfessional, Personal, Student, Communityの4プランの内、Communityのみ無料で利用できる。\nCommunityでも25グラフまで作成できるので、ここではひとまずCommunityを選択する。\n\u0026ldquo;SING UP\u0026quot;をクリックして、メールアドレスやユーザ名を登録する。\n登録が終わると、以下のようなグラフ編集画面になる。\nチャートの作成 ここでは、折れ線グラフを作ってみる。\n編集画面の表に、以下のスクリーンショットのように数値を入力する。\n数値を全選択後に右クリックし、\u0026ldquo;Create traces from selection\u0026quot;をクリックする。\nすると以下のポップアップが表れるので、上段右から2番目の\u0026quot;Straight Line\u0026quot;を選択する。\n選択すると、変種画面の右下に以下のようなグラフが生成される。\nグラフの埋め込み 編集画面左下の\u0026quot;Share\u0026quot;ボタンを押すと、次のようなポップアップが表示されるので、Plotのプルダウンを\u0026quot;Public\u0026quot;とし、\u0026ldquo;Save\u0026quot;を押す。\nただし、\u0026ldquo;Public\u0026quot;にすると誰でもグラフを閲覧できてしまうので注意。\nポップアップが閉じるので、再度\u0026quot;Share\u0026quot;ボタンを押す。\nすると、今度は\u0026quot;Embed\u0026quot;というタブが表れているので、これを開くと、埋め込み用のリンクが表示されている。\n埋め込み用リンクは\u0026quot;iframe\u0026quot;と\u0026quot;html\u0026quot;の2種類あるが、表示内容は同じである。\n\u0026ldquo;iframe\u0026quot;の場合、widthとheightのパラメータでグラフの大きさを変更できる。\n\u0026ldquo;html\u0026quot;の場合、widthのパラメータでグラフの大きさを変更できる。\n埋め込んだ結果は上記のサンプルの通り。\n参考 このページではChart Studio Cloudの機能のみ使ったが、Pythonのスクリプトを書いて凝ったグラフを作りたい場合には、以下を参考にされたい。\n描画ライブラリPlotlyの使い方を徹底解説 | Python - 韜晦日記\nPlotlyでレポート・論文に使えるグラフを描こう - かみのメモ\n","description":"Chart Studio Cloudに登録し、Plotlyのグラフをブログ等のWebページに埋め込む方法を説明する。","id":76,"section":"posts","tags":["Python","Plotly"],"title":"Plotlyのインタラクティブなグラフをブログ等に埋め込む","uri":"https://helve2017.github.io/posts/python/plotly-embedding/"}]